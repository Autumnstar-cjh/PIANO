{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "25bb1acb-d746-421a-b836-0de18bf2c716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from neuralop.models.fno import TFNO\n",
    "from neuralop.models.fno import TFNO3d\n",
    "from neuralop.training.trainer import Trainer\n",
    "from neuralop.utils import count_model_params\n",
    "from neuralop.losses.data_losses import LpLoss, H1Loss\n",
    "import pdb\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "from astropy.io import fits\n",
    "from torch.utils.data.dataset import Subset\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.transforms.functional import normalize\n",
    "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "import h5py\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "device0 = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device1 = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device0)\n",
    "#print(device1)\n",
    "\n",
    "from functools import partialmethod\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from neuralop.layers.spectral_convolution import SpectralConv\n",
    "from neuralop.layers.padding import DomainPadding\n",
    "from neuralop.layers.fno_block import FNOBlocks\n",
    "from neuralop.layers.mlp import MLP\n",
    "from neuralop.models.base_model import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76f62935-4f49-4f88-b61e-a27e0adf6eba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 1, 3, 257, 513])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        hdf5_file_paths, \n",
    "        x_lengths, \n",
    "        y_lengths, \n",
    "        z_lengths, \n",
    "        excel_path\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hdf5_file_paths (list): List of paths to the HDF5 files [Bx_file, By_file, Bz_file].\n",
    "            x_lengths, y_lengths, z_lengths (np.ndarray): Arrays of lengths (1D).\n",
    "            excel_path (str): Path to the Excel file containing NOAA AR, date, and type.\n",
    "        \"\"\"\n",
    "        # 1) Store HDF5 file paths and open the files\n",
    "        self.hdf5_file_paths = hdf5_file_paths\n",
    "        self.hdf5_files = [h5py.File(path, 'r') for path in self.hdf5_file_paths]\n",
    "        \n",
    "        # 2) Store lengths\n",
    "        self.x_lengths = x_lengths\n",
    "        self.y_lengths = y_lengths\n",
    "        self.z_lengths = z_lengths\n",
    "        \n",
    "        # 3) Read Excel file to get the NOAA AR, date, and type\n",
    "        df = pd.read_excel(excel_path)\n",
    "        \n",
    "        # Make sure the rows in 'df' match the exact order of samples in HDF5\n",
    "        # If you need to sort the DataFrame, do it here, e.g.:\n",
    "        # df = df.sort_values(by='date')  # or by 'NOAA AR', etc.\n",
    "        # df = df.reset_index(drop=True)\n",
    "\n",
    "        # Just store the raw type strings:\n",
    "        self.type_labels_str = df['type'].astype(str).values\n",
    "        \n",
    "        # 4) Assume all HDF5 files have the same number of samples\n",
    "        self.dataset_length = len(self.hdf5_files[0])\n",
    "        \n",
    "        # 5) Calculate means and stds for normalization\n",
    "        self.x_mean = np.mean(self.x_lengths)\n",
    "        self.x_std = np.std(self.x_lengths)\n",
    "\n",
    "        self.y_mean = np.mean(self.y_lengths)\n",
    "        self.y_std = np.std(self.y_lengths)\n",
    "\n",
    "        self.z_mean = np.mean(self.z_lengths)\n",
    "        self.z_std = np.std(self.z_lengths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # ---------------------\n",
    "        # 1) Read input arrays\n",
    "        # ---------------------\n",
    "        input_data_x = torch.from_numpy(\n",
    "            self.hdf5_files[0][f'sample_{idx}/input'][:]\n",
    "        ).float()\n",
    "        input_data_y = torch.from_numpy(\n",
    "            self.hdf5_files[1][f'sample_{idx}/input'][:]\n",
    "        ).float()\n",
    "        input_data_z = torch.from_numpy(\n",
    "            self.hdf5_files[2][f'sample_{idx}/input'][:]\n",
    "        ).float()\n",
    "\n",
    "        # ----------------------\n",
    "        # 2) Read output arrays\n",
    "        # ----------------------\n",
    "        output_data_x = torch.from_numpy(\n",
    "            self.hdf5_files[0][f'sample_{idx}/output'][:]\n",
    "        ).float()\n",
    "        output_data_y = torch.from_numpy(\n",
    "            self.hdf5_files[1][f'sample_{idx}/output'][:]\n",
    "        ).float()\n",
    "        output_data_z = torch.from_numpy(\n",
    "            self.hdf5_files[2][f'sample_{idx}/output'][:]\n",
    "        ).float()\n",
    "\n",
    "        # ------------------------------------\n",
    "        # 3) Select some subset of output data\n",
    "        # ------------------------------------\n",
    "        selected_output_data_x = output_data_x[:25]\n",
    "        selected_output_data_y = output_data_y[:25]\n",
    "        selected_output_data_z = output_data_z[:25]\n",
    "\n",
    "        # ------------------------------------\n",
    "        # 4) Stack inputs into multi-channel\n",
    "        # ------------------------------------\n",
    "        input_data = torch.stack(\n",
    "            (input_data_x, input_data_y, input_data_z), dim=0\n",
    "        ).unsqueeze(0)\n",
    "\n",
    "        # ------------------------------------\n",
    "        # 5) Stack selected outputs\n",
    "        # ------------------------------------\n",
    "        output_data = torch.stack(\n",
    "            (selected_output_data_x, selected_output_data_y, selected_output_data_z), \n",
    "            dim=1\n",
    "        )\n",
    "\n",
    "        # ------------------------------------\n",
    "        # 6) Normalize lengths\n",
    "        # ------------------------------------\n",
    "        x_length_normalized = (self.x_lengths[idx] - self.x_mean) / self.x_std\n",
    "        y_length_normalized = (self.y_lengths[idx] - self.y_mean) / self.y_std\n",
    "        z_length_normalized = (self.z_lengths[idx] - self.z_mean) / self.z_std\n",
    "        \n",
    "        length_tensor = torch.tensor(\n",
    "            [x_length_normalized, y_length_normalized, z_length_normalized],\n",
    "            dtype=torch.float32\n",
    "        ).unsqueeze(0)\n",
    "\n",
    "        # ------------------------------------\n",
    "        # 7) Get the string label from Excel\n",
    "        # ------------------------------------\n",
    "        type_label_str = self.type_labels_str[idx]\n",
    "        # This remains a Python string. If you only need to read it\n",
    "        # later for grouping or analysis, you can just store it in the sample dict. \n",
    "        # (If you need it as a tensor, you can store it as an object \n",
    "        #  but note that PyTorch won't do much with it for training.)\n",
    "\n",
    "        sample = {\n",
    "            'input': input_data,      # shape: (1, 3, H, W) or similar\n",
    "            'output': output_data,    # shape: (N, 3) depending on your slicing\n",
    "            'lengths': length_tensor, # shape: (1, 3)\n",
    "            'type_label_str': type_label_str,  # e.g. 'β' or 'βγ'\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# HDF5 file paths\n",
    "input1 = \"NLFFF_data/NLFFF_Bx_rmns_100.h5\"\n",
    "input2 = \"NLFFF_data/NLFFF_By_rmns_100.h5\"\n",
    "input3 = \"NLFFF_data/NLFFF_Bz_rmns_10.h5\"\n",
    "\n",
    "# NumPy length arrays\n",
    "x_lengths = np.load(\"NLFFF_data/x_height.npy\")\n",
    "y_lengths = np.load(\"NLFFF_data/y_height.npy\")\n",
    "z_lengths = np.load(\"NLFFF_data/z_height.npy\")\n",
    "\n",
    "# Excel path\n",
    "excel_path = \"NLFFF_data/NLFFF_datatype.xlsx\"\n",
    "\n",
    "# Initialize dataset\n",
    "dataset = CustomDataset(\n",
    "    [input1, input2, input3],\n",
    "    x_lengths,\n",
    "    y_lengths,\n",
    "    z_lengths,\n",
    "    excel_path\n",
    ")\n",
    "\n",
    "train_size = 143\n",
    "test_size = 27\n",
    "\n",
    "train_dataset = Subset(dataset, range(train_size))\n",
    "test_dataset = Subset(dataset, range(train_size, train_size + test_size))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=8, persistent_workers=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=8, persistent_workers=False)\n",
    "\n",
    "for batch in train_loader:\n",
    "    inputs = batch['input']\n",
    "    outputs = batch['output']\n",
    "    lengths = batch['lengths']\n",
    "    type_strings = batch['type_label_str']\n",
    "\n",
    "print(inputs.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7b53021-63da-4cd2-8943-7804075b6165",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PhysicsInformedLoss(nn.Module):\n",
    "    def __init__(self, weight=0.35, alpha=1.0, beta=1.0, gamma=1.0):\n",
    "        super(PhysicsInformedLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.alpha = alpha  \n",
    "        self.beta = beta    \n",
    "        self.gamma = gamma  \n",
    "\n",
    "    def forward(self, output, target): \n",
    "        divergence_loss = self.compute_divergence_loss(output)\n",
    "\n",
    "        force_free_loss = self.compute_force_free_loss(output)\n",
    "\n",
    "        total_loss = self.weight * ((self.beta * divergence_loss) + \\\n",
    "                     (self.gamma * force_free_loss))\n",
    "        return total_loss\n",
    "\n",
    "    def compute_divergence_loss(self, output):\n",
    "        batch_size, depth, components, height, width = output.shape\n",
    "        B = output.permute(0, 2, 1, 3, 4)  # B: [batch_size, 3, depth, height, width]\n",
    "        channels = components\n",
    "\n",
    "        device = output.device\n",
    "\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "        kernel_dx = kernel_dx.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(channels, 1, 1, 1, 1)\n",
    "\n",
    "        dB_dx = F.conv3d(B, kernel_dx, padding=(0, 0, 1), groups=channels)\n",
    "        dB_dy = F.conv3d(B, kernel_dy, padding=(0, 1, 0), groups=channels)\n",
    "        dB_dz = F.conv3d(B, kernel_dz, padding=(1, 0, 0), groups=channels)\n",
    "\n",
    "        # dB_x/dx\n",
    "        dB_x_dx = dB_dx[:, 0, :, :, :]\n",
    "        # dB_y/dy\n",
    "        dB_y_dy = dB_dy[:, 1, :, :, :]\n",
    "        # dB_z/dz\n",
    "        dB_z_dz = dB_dz[:, 2, :, :, :]\n",
    "\n",
    "\n",
    "        divergence = dB_x_dx + dB_y_dy + dB_z_dz\n",
    "        divergence_loss = torch.mean(divergence ** 2)\n",
    "\n",
    "        return divergence_loss\n",
    "\n",
    "    def compute_force_free_loss(self, output):\n",
    "        batch_size, depth, components, height, width = output.shape\n",
    "        B = output.permute(0, 2, 1, 3, 4)  # B: [batch_size, 3, depth, height, width]\n",
    "        channels = components  \n",
    "\n",
    "        device = output.device\n",
    "\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "\n",
    "        kernel_dx = kernel_dx.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(channels, 1, 1, 1, 1)\n",
    "\n",
    "        dB_dx = F.conv3d(B, kernel_dx, padding=(0, 0, 1), groups=channels)\n",
    "        dB_dy = F.conv3d(B, kernel_dy, padding=(0, 1, 0), groups=channels)\n",
    "        dB_dz = F.conv3d(B, kernel_dz, padding=(1, 0, 0), groups=channels)\n",
    "\n",
    "        dB_x_dy = dB_dy[:, 0, :, :, :]\n",
    "        dB_x_dz = dB_dz[:, 0, :, :, :]\n",
    "\n",
    "        dB_y_dx = dB_dx[:, 1, :, :, :]\n",
    "        dB_y_dz = dB_dz[:, 1, :, :, :]\n",
    "\n",
    "        dB_z_dx = dB_dx[:, 2, :, :, :]\n",
    "        dB_z_dy = dB_dy[:, 2, :, :, :]\n",
    "\n",
    "        rot_x = dB_z_dy - dB_y_dz\n",
    "        rot_y = dB_x_dz - dB_z_dx\n",
    "        rot_z = dB_y_dx - dB_x_dy\n",
    "\n",
    "        j = torch.stack([rot_x, rot_y, rot_z], dim=1)\n",
    "        jxb = torch.cross(j, B, dim=1)\n",
    "        B_magnitude_squared = torch.sum(B ** 2, dim=1, keepdim=True) + 1e-7\n",
    "        force_free_loss = torch.mean(torch.sum(jxb ** 2, dim=1) / B_magnitude_squared.squeeze(1))\n",
    "\n",
    "        return force_free_loss\n",
    "\n",
    "\n",
    "class ECA3DLayer(nn.Module):\n",
    "    def __init__(self, channel, k_size=3):\n",
    "        super(ECA3DLayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, channels, seq_len, height, width]\n",
    "        \n",
    "        # Global average pooling across seq_len, height, width\n",
    "        y = self.avg_pool(x)  # Shape: [batch_size, channels, 1, 1, 1]\n",
    "\n",
    "        # Apply 1D convolution across the channel dimension\n",
    "        y = self.conv(y.squeeze(-1).squeeze(-1).transpose(-1, -2))  # Shape: [batch_size, 1, channels]\n",
    "        y = y.transpose(-1, -2).unsqueeze(-1).unsqueeze(-1)  # Shape: [batch_size, channels, 1, 1, 1]\n",
    "\n",
    "        # Apply attention to input\n",
    "        return x * self.sigmoid(y).expand_as(x)\n",
    "\n",
    "class DilatedConvYWithECA(nn.Module):\n",
    "    def __init__(self, channels, dilation_y=2, k_size=3):\n",
    "        super(DilatedConvYWithECA, self).__init__()\n",
    "        self.conv = nn.Conv3d(\n",
    "            in_channels=channels,\n",
    "            out_channels=channels,\n",
    "            kernel_size=(1, 3, 1),  \n",
    "            padding=(0, dilation_y, 0),  \n",
    "            dilation=(1, dilation_y, 1),\n",
    "            bias=False\n",
    "        )\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        # ECA Attention layer\n",
    "        self.eca = ECA3DLayer(channel=channels, k_size=k_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply dilated convolution\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Apply ECA attention\n",
    "        x = self.eca(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# CustomFNO Model with ECA-Net applied to lengths_lifted\n",
    "class CustomFNO(BaseModel, name='CustomFNO'):\n",
    "    def __init__(self, n_modes, hidden_channels, in_channels=3, out_channels=1,\n",
    "                 lifting_channels=256, projection_channels=256, n_layers=4,\n",
    "                 output_scaling_factor=None, max_n_modes=None,\n",
    "                 fno_block_precision=\"full\", use_mlp=False, mlp_dropout=0,\n",
    "                 mlp_expansion=0.5, non_linearity=F.gelu, stabilizer=None,\n",
    "                 norm=None, preactivation=False, fno_skip=\"linear\",\n",
    "                 mlp_skip=\"soft-gating\", separable=False, factorization=None,\n",
    "                 rank=1.0, joint_factorization=False, fixed_rank_modes=False,\n",
    "                 implementation=\"factorized\", decomposition_kwargs=dict(),\n",
    "                 domain_padding=None, domain_padding_mode=\"one-sided\",\n",
    "                 fft_norm=\"forward\", SpectralConv=SpectralConv,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.n_dim = len(n_modes)\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Define the lifting layers for two inputs\n",
    "        self.lifting1 = MLP(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            hidden_channels=lifting_channels,\n",
    "            n_layers=2,\n",
    "            n_dim=self.n_dim,\n",
    "        )\n",
    "        \n",
    "        self.lifting_y = MLP(\n",
    "            in_channels=3,  \n",
    "            out_channels=hidden_channels,\n",
    "            hidden_channels=lifting_channels,\n",
    "            n_layers=2,\n",
    "            n_dim=1,\n",
    "        )\n",
    "\n",
    "        # Define the ECA-Net block for lengths_lifted\n",
    "        self.DilatedConvYWithECA = DilatedConvYWithECA(hidden_channels, dilation_y=2)\n",
    "\n",
    "        # Define the FNO blocks\n",
    "        self.fno_blocks = FNOBlocks(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            n_modes=n_modes,\n",
    "            output_scaling_factor=output_scaling_factor,\n",
    "            use_mlp=use_mlp,\n",
    "            mlp_dropout=mlp_dropout,\n",
    "            mlp_expansion=mlp_expansion,\n",
    "            non_linearity=non_linearity,\n",
    "            stabilizer=stabilizer,\n",
    "            norm=norm,\n",
    "            preactivation=preactivation,\n",
    "            fno_skip=fno_skip,\n",
    "            mlp_skip=mlp_skip,\n",
    "            max_n_modes=max_n_modes,\n",
    "            fno_block_precision=fno_block_precision,\n",
    "            rank=rank,\n",
    "            fft_norm=fft_norm,\n",
    "            fixed_rank_modes=fixed_rank_modes,\n",
    "            implementation=implementation,\n",
    "            separable=separable,\n",
    "            factorization=factorization,\n",
    "            decomposition_kwargs=decomposition_kwargs,\n",
    "            joint_factorization=joint_factorization,\n",
    "            SpectralConv=SpectralConv,\n",
    "            n_layers=n_layers,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # Define the projection layer\n",
    "        self.projection = MLP(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=out_channels,\n",
    "            hidden_channels=projection_channels,\n",
    "            n_layers=2,\n",
    "            n_dim=self.n_dim,\n",
    "            non_linearity=non_linearity,\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, lengths):\n",
    "        \"\"\"Forward pass for the Custom FNO model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x1 : tensor\n",
    "            Input tensor of shape [batch_size, 1, 3, 257, 513]\n",
    "        lengths : tensor\n",
    "            Tensor containing the normalized lengths of shape [batch_size, 1, 3]\n",
    "        \"\"\"\n",
    "        x_orig = x1.clone()\n",
    "        \n",
    "        # Apply lifting to the input\n",
    "        x1 = self.lifting1(x1)  # Result shape: [batch_size, hidden_channels, 3, 257, 513]\n",
    "\n",
    "        # Reshape lengths for processing\n",
    "        lengths = lengths.view(-1, 3, 1)  # Shape [batch_size, 3, 1] for processing\n",
    "\n",
    "        # Process lengths through lifting\n",
    "        lengths_lifted = self.lifting_y(lengths)  # Result shape: [batch_size, hidden_channels, 3]\n",
    "        \n",
    "        # Reshape lengths_lifted to match the spatial dimensions of x1\n",
    "        lengths_lifted = lengths_lifted.unsqueeze(-1).unsqueeze(-1)  # Shape: [batch_size, hidden_channels, 3, 1, 1]\n",
    "\n",
    "        # Apply ECA-Net block to lengths_lifted before adding to x1\n",
    "        lengths_lifted = self.DilatedConvYWithECA(lengths_lifted)\n",
    "\n",
    "        # Apply lengths_lifted to x1 (add)\n",
    "        x1 = x1 + lengths_lifted\n",
    "\n",
    "        # Apply FNO blocks\n",
    "        for layer_idx in range(self.n_layers):\n",
    "            x1 = self.fno_blocks(x1, layer_idx)\n",
    "\n",
    "        # Apply projection layer\n",
    "        x1 = self.projection(x1)\n",
    "\n",
    "        x1[:, 0, :, :, :] = x_orig[:, 0, :, :, :]\n",
    "\n",
    "        return x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b21e8e-0322-4102-8577-7282014ef71d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model has 40383772 parameters.\n",
      "CustomFNO(\n",
      "  (lifting1): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv3d(1, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (1): Conv3d(256, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "    )\n",
      "  )\n",
      "  (lifting_y): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv1d(3, 256, kernel_size=(1,), stride=(1,))\n",
      "      (1): Conv1d(256, 32, kernel_size=(1,), stride=(1,))\n",
      "    )\n",
      "  )\n",
      "  (DilatedConvYWithECA): DilatedConvYWithECA(\n",
      "    (conv): Conv3d(32, 32, kernel_size=(1, 3, 1), stride=(1, 1, 1), padding=(0, 2, 0), dilation=(1, 2, 1), bias=False)\n",
      "    (activation): ReLU()\n",
      "    (eca): ECA3DLayer(\n",
      "      (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "      (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "      (sigmoid): Sigmoid()\n",
      "    )\n",
      "  )\n",
      "  (fno_blocks): FNOBlocks(\n",
      "    (convs): SpectralConv(\n",
      "      (weight): ModuleList(\n",
      "        (0-5): 6 x ComplexTuckerTensor(shape=(32, 32, 32, 32, 17), rank=(23, 23, 23, 23, 12))\n",
      "      )\n",
      "    )\n",
      "    (fno_skips): ModuleList(\n",
      "      (0-5): 6 x Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "    )\n",
      "    (mlp): ModuleList(\n",
      "      (0-5): 6 x MLP(\n",
      "        (fcs): ModuleList(\n",
      "          (0): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "          (1): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (mlp_skips): ModuleList(\n",
      "      (0-5): 6 x SoftGating()\n",
      "    )\n",
      "  )\n",
      "  (projection): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv3d(32, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "      (1): Conv3d(256, 25, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jc2687/.local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = CustomFNO(n_modes = (32, 32, 32), in_channels=1, out_channels=25, n_layers = 6,\n",
    "               hidden_channels=32, use_mlp=True, factorization='tucker', rank=0.2)\n",
    "model = model.to(device0)\n",
    "\n",
    "n_params = count_model_params(model)\n",
    "print(f'\\nYour model has {n_params} parameters.')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=1, verbose=True)\n",
    "\n",
    "h1loss = H1Loss(d=2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e71eef4-7a9c-4ba0-8172-72de62716b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def l2_loss(pred, target):\n",
    "    return F.mse_loss(pred, target, reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "391856a6-948e-428c-bd54-eddd24744a7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1/150:  53%|█████▎    | 8/15 [01:09<01:00,  8.64s/it, loss_Bx=9.93, loss_By=10, loss_Bz=9.67, physics_loss=0.0179]\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/IPython/core/async_helpers.py:128\u001b[39m, in \u001b[36m_pseudo_sync_runner\u001b[39m\u001b[34m(coro)\u001b[39m\n\u001b[32m    120\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    121\u001b[39m \u001b[33;03mA runner that does not really allow async execution, and just advance the coroutine.\u001b[39;00m\n\u001b[32m    122\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    125\u001b[39m \u001b[33;03mCredit to Nathaniel Smith\u001b[39;00m\n\u001b[32m    126\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    127\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m     coro.send(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc.value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3384\u001b[39m, in \u001b[36mInteractiveShell.run_cell_async\u001b[39m\u001b[34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[39m\n\u001b[32m   3380\u001b[39m exec_count = \u001b[38;5;28mself\u001b[39m.execution_count\n\u001b[32m   3381\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m result.error_in_exec:\n\u001b[32m   3382\u001b[39m     \u001b[38;5;66;03m# Store formatted traceback and error details\u001b[39;00m\n\u001b[32m   3383\u001b[39m     \u001b[38;5;28mself\u001b[39m.history_manager.exceptions[exec_count] = (\n\u001b[32m-> \u001b[39m\u001b[32m3384\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_format_exception_for_storage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m.\u001b[49m\u001b[43merror_in_exec\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3385\u001b[39m     )\n\u001b[32m   3387\u001b[39m \u001b[38;5;66;03m# Each cell is a *single* input, regardless of how many lines it has\u001b[39;00m\n\u001b[32m   3388\u001b[39m \u001b[38;5;28mself\u001b[39m.execution_count += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/IPython/core/interactiveshell.py:3438\u001b[39m, in \u001b[36mInteractiveShell._format_exception_for_storage\u001b[39m\u001b[34m(self, exception, filename, running_compiled_code)\u001b[39m\n\u001b[32m   3435\u001b[39m         stb = evalue._render_traceback_()\n\u001b[32m   3436\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3437\u001b[39m         \u001b[38;5;66;03m# Otherwise, use InteractiveTB to format the traceback.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m3438\u001b[39m         stb = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mInteractiveTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3439\u001b[39m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\n\u001b[32m   3440\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3441\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   3442\u001b[39m     \u001b[38;5;66;03m# In case formatting fails, fallback to Python's built-in formatting.\u001b[39;00m\n\u001b[32m   3443\u001b[39m     stb = traceback.format_exception(etype, evalue, tb)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/IPython/core/ultratb.py:1182\u001b[39m, in \u001b[36mAutoFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1180\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1181\u001b[39m     \u001b[38;5;28mself\u001b[39m.tb = etb\n\u001b[32m-> \u001b[39m\u001b[32m1182\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1183\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1184\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/IPython/core/ultratb.py:1053\u001b[39m, in \u001b[36mFormattedTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m   1050\u001b[39m mode = \u001b[38;5;28mself\u001b[39m.mode\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.verbose_modes:\n\u001b[32m   1052\u001b[39m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1053\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1054\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[32m   1055\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1056\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m mode == \u001b[33m\"\u001b[39m\u001b[33mDocs\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   1057\u001b[39m     \u001b[38;5;66;03m# return DocTB\u001b[39;00m\n\u001b[32m   1058\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m DocTB(\n\u001b[32m   1059\u001b[39m         theme_name=\u001b[38;5;28mself\u001b[39m._theme_name,\n\u001b[32m   1060\u001b[39m         call_pdb=\u001b[38;5;28mself\u001b[39m.call_pdb,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1068\u001b[39m         etype, evalue, etb, tb_offset, \u001b[32m1\u001b[39m\n\u001b[32m   1069\u001b[39m     )  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/IPython/core/ultratb.py:861\u001b[39m, in \u001b[36mVerboseTB.structured_traceback\u001b[39m\u001b[34m(self, etype, evalue, etb, tb_offset, context)\u001b[39m\n\u001b[32m    852\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructured_traceback\u001b[39m(\n\u001b[32m    853\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    854\u001b[39m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    858\u001b[39m     context: \u001b[38;5;28mint\u001b[39m = \u001b[32m5\u001b[39m,\n\u001b[32m    859\u001b[39m ) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    860\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m     formatted_exceptions: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m        \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    865\u001b[39m     termsize = \u001b[38;5;28mmin\u001b[39m(\u001b[32m75\u001b[39m, get_terminal_size()[\u001b[32m0\u001b[39m])\n\u001b[32m    866\u001b[39m     theme = theme_table[\u001b[38;5;28mself\u001b[39m._theme_name]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/IPython/core/ultratb.py:773\u001b[39m, in \u001b[36mVerboseTB.format_exception_as_a_whole\u001b[39m\u001b[34m(self, etype, evalue, etb, context, tb_offset)\u001b[39m\n\u001b[32m    763\u001b[39m         frames.append(\n\u001b[32m    764\u001b[39m             theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    765\u001b[39m                 [\n\u001b[32m   (...)\u001b[39m\u001b[32m    770\u001b[39m             )\n\u001b[32m    771\u001b[39m         )\n\u001b[32m    772\u001b[39m         skipped = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m773\u001b[39m     frames.append(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_record\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    774\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m skipped:\n\u001b[32m    775\u001b[39m     frames.append(\n\u001b[32m    776\u001b[39m         theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m    777\u001b[39m             [\n\u001b[32m   (...)\u001b[39m\u001b[32m    782\u001b[39m         )\n\u001b[32m    783\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/IPython/core/ultratb.py:651\u001b[39m, in \u001b[36mVerboseTB.format_record\u001b[39m\u001b[34m(self, frame_info)\u001b[39m\n\u001b[32m    648\u001b[39m result += \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m call \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    649\u001b[39m result += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcall\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    650\u001b[39m result += theme_table[\u001b[38;5;28mself\u001b[39m._theme_name].format(\n\u001b[32m--> \u001b[39m\u001b[32m651\u001b[39m     \u001b[43m_format_traceback_lines\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtheme_table\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_theme_name\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlvals_toks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m )\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/IPython/core/tbtools.py:99\u001b[39m, in \u001b[36m_format_traceback_lines\u001b[39m\u001b[34m(lines, theme, has_colors, lvals_toks)\u001b[39m\n\u001b[32m     96\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     98\u001b[39m lineno = stack_line.lineno\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m line = \u001b[43mstack_line\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpygmented\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhas_colors\u001b[49m\u001b[43m)\u001b[49m.rstrip(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m) + \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m stack_line.is_current:\n\u001b[32m    101\u001b[39m     \u001b[38;5;66;03m# This is the line with the error\u001b[39;00m\n\u001b[32m    102\u001b[39m     pad = numbers_width - \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mstr\u001b[39m(lineno))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/stack_data/core.py:391\u001b[39m, in \u001b[36mLine.render\u001b[39m\u001b[34m(self, markers, strip_leading_indent, pygmented, escape_html)\u001b[39m\n\u001b[32m    389\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m pygmented \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.frame_info.scope:\n\u001b[32m    390\u001b[39m     assert_(\u001b[38;5;129;01mnot\u001b[39;00m markers, \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot use pygmented with markers\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m391\u001b[39m     start_line, lines = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mframe_info\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_pygmented_scope_lines\u001b[49m\n\u001b[32m    392\u001b[39m     result = lines[\u001b[38;5;28mself\u001b[39m.lineno - start_line]\n\u001b[32m    393\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m strip_leading_indent:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/stack_data/utils.py:145\u001b[39m, in \u001b[36mcached_property.cached_property_wrapper\u001b[39m\u001b[34m(self, obj, _cls)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m145\u001b[39m value = obj.\u001b[34m__dict__\u001b[39m[\u001b[38;5;28mself\u001b[39m.func.\u001b[34m__name__\u001b[39m] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    146\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/stack_data/core.py:824\u001b[39m, in \u001b[36mFrameInfo._pygmented_scope_lines\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    821\u001b[39m     ranges = []\n\u001b[32m    823\u001b[39m code = atext.get_text(scope)\n\u001b[32m--> \u001b[39m\u001b[32m824\u001b[39m lines = \u001b[43m_pygmented_with_ranges\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    826\u001b[39m start_line = \u001b[38;5;28mself\u001b[39m.source.line_range(scope)[\u001b[32m0\u001b[39m]\n\u001b[32m    828\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m start_line, lines\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/stack_data/utils.py:166\u001b[39m, in \u001b[36m_pygmented_with_ranges\u001b[39m\u001b[34m(formatter, code, ranges)\u001b[39m\n\u001b[32m    164\u001b[39m lexer = MyLexer(stripnl=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    165\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m166\u001b[39m     highlighted = \u001b[43mpygments\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhighlight\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m    168\u001b[39m     \u001b[38;5;66;03m# When pygments fails, prefer code without highlighting over crashing\u001b[39;00m\n\u001b[32m    169\u001b[39m     highlighted = code\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/pygments/__init__.py:82\u001b[39m, in \u001b[36mhighlight\u001b[39m\u001b[34m(code, lexer, formatter, outfile)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mhighlight\u001b[39m(code, lexer, formatter, outfile=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     78\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     79\u001b[39m \u001b[33;03m    This is the most high-level highlighting function. It combines `lex` and\u001b[39;00m\n\u001b[32m     80\u001b[39m \u001b[33;03m    `format` in one function.\u001b[39;00m\n\u001b[32m     81\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m82\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlexer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/pygments/__init__.py:64\u001b[39m, in \u001b[36mformat\u001b[39m\u001b[34m(tokens, formatter, outfile)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m outfile:\n\u001b[32m     63\u001b[39m     realoutfile = \u001b[38;5;28mgetattr\u001b[39m(formatter, \u001b[33m'\u001b[39m\u001b[33mencoding\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m BytesIO() \u001b[38;5;129;01mor\u001b[39;00m StringIO()\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m     \u001b[43mformatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrealoutfile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m realoutfile.getvalue()\n\u001b[32m     66\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/pygments/formatters/terminal256.py:250\u001b[39m, in \u001b[36mTerminal256Formatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mformat\u001b[39m(\u001b[38;5;28mself\u001b[39m, tokensource, outfile):\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormatter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokensource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/pygments/formatter.py:124\u001b[39m, in \u001b[36mFormatter.format\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.encoding:\n\u001b[32m    122\u001b[39m     \u001b[38;5;66;03m# wrap the outfile in a StreamWriter\u001b[39;00m\n\u001b[32m    123\u001b[39m     outfile = codecs.lookup(\u001b[38;5;28mself\u001b[39m.encoding)[\u001b[32m3\u001b[39m](outfile)\n\u001b[32m--> \u001b[39m\u001b[32m124\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_unencoded\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokensource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/pygments/formatters/terminal256.py:256\u001b[39m, in \u001b[36mTerminal256Formatter.format_unencoded\u001b[39m\u001b[34m(self, tokensource, outfile)\u001b[39m\n\u001b[32m    253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.linenos:\n\u001b[32m    254\u001b[39m     \u001b[38;5;28mself\u001b[39m._write_lineno(outfile)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mttype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtokensource\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    257\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnot_found\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    258\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwhile\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mttype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mnot_found\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/stack_data/utils.py:158\u001b[39m, in \u001b[36m_pygmented_with_ranges.<locals>.MyLexer.get_tokens\u001b[39m\u001b[34m(self, text)\u001b[39m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_tokens\u001b[39m(\u001b[38;5;28mself\u001b[39m, text):\n\u001b[32m    157\u001b[39m     length = \u001b[32m0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mttype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43many\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mlength\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mranges\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m            \u001b[49m\u001b[43mttype\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mttype\u001b[49m\u001b[43m.\u001b[49m\u001b[43mExecutingNode\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/pygments/lexer.py:270\u001b[39m, in \u001b[36mLexer.get_tokens.<locals>.streamer\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstreamer\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_tokens_unprocessed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.conda/envs/rtmag/lib/python3.11/site-packages/pygments/lexer.py:712\u001b[39m, in \u001b[36mRegexLexer.get_tokens_unprocessed\u001b[39m\u001b[34m(self, text, stack)\u001b[39m\n\u001b[32m    710\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[32m1\u001b[39m:\n\u001b[32m    711\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m rexmatch, action, new_state \u001b[38;5;129;01min\u001b[39;00m statetokens:\n\u001b[32m--> \u001b[39m\u001b[32m712\u001b[39m         m = \u001b[43mrexmatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    713\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m m:\n\u001b[32m    714\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "num_epochs = 150\n",
    "print_frequency = 40\n",
    "save_checkpoint_start_epoch = 50\n",
    "save_checkpoint_interval = 10\n",
    "checkpoint_dir = \"result/NLFFF_Cube2Step/step1\"\n",
    "results_file = os.path.join(checkpoint_dir, \"result.csv\")\n",
    "physics_loss_fn = PhysicsInformedLoss(weight=0.35, alpha=1.0, beta=1, gamma=1)\n",
    "\n",
    "# 准备CSV文件\n",
    "with open(results_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['epoch', 'comp', 'r2', 'relative_error', 'mse', 'mae', 'psnr', 'ssim'])\n",
    "\n",
    "train_losses_Bx = []\n",
    "train_losses_By = []\n",
    "train_losses_Bz = []\n",
    "test_losses_Bx = []\n",
    "test_losses_By = []\n",
    "test_losses_Bz = []\n",
    "physics_losses = []\n",
    "epoch_durations = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss_Bx = 0.0\n",
    "    epoch_loss_By = 0.0\n",
    "    epoch_loss_Bz = 0.0\n",
    "    epoch_physics_loss = 0.0\n",
    "\n",
    "    train_loader_tqdm = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Train Epoch {epoch+1}/{num_epochs}')\n",
    "    for batch_idx, sample in train_loader_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "        data, target = sample['input'].to(device0), sample['output'].to(device0)\n",
    "        lengths = sample['lengths'].to(device0)  \n",
    "\n",
    "        output = model(data, lengths)\n",
    "\n",
    "        loss_Bx = h1loss(output[:, :, 0, :, :], target[:, :, 0, :, :]).mean()\n",
    "        loss_By = h1loss(output[:, :, 1, :, :], target[:, :, 1, :, :]).mean()\n",
    "        loss_Bz = h1loss(output[:, :, 2, :, :], target[:, :, 2, :, :]).mean()\n",
    "\n",
    "        physics_loss = physics_loss_fn(output, target)\n",
    "            \n",
    "        total_loss = loss_Bx + loss_By + loss_Bz + physics_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss_Bx += loss_Bx.item()\n",
    "        epoch_loss_By += loss_By.item()\n",
    "        epoch_loss_Bz += loss_Bz.item()\n",
    "        epoch_physics_loss += physics_loss.item()\n",
    "\n",
    "        if batch_idx % print_frequency == 0:\n",
    "            train_loader_tqdm.set_postfix(\n",
    "                loss_Bx=loss_Bx.item(),\n",
    "                loss_By=loss_By.item(),\n",
    "                loss_Bz=loss_Bz.item(),\n",
    "                physics_loss=physics_loss.item()\n",
    "            )\n",
    "\n",
    "    avg_loss_Bx = epoch_loss_Bx / len(train_loader)\n",
    "    avg_loss_By = epoch_loss_By / len(train_loader)\n",
    "    avg_loss_Bz = epoch_loss_Bz / len(train_loader)\n",
    "    avg_physics_loss = epoch_physics_loss / len(train_loader)\n",
    "\n",
    "    train_losses_Bx.append(avg_loss_Bx)\n",
    "    train_losses_By.append(avg_loss_By)\n",
    "    train_losses_Bz.append(avg_loss_Bz)\n",
    "    physics_losses.append(avg_physics_loss)\n",
    "\n",
    "    model.eval()\n",
    "    epoch_r2_Bx = []\n",
    "    epoch_r2_By = []\n",
    "    epoch_r2_Bz = []\n",
    "    test_loader_tqdm = tqdm(test_loader, total=len(test_loader), desc=f'Test Epoch {epoch+1}/{num_epochs}')\n",
    "    with torch.no_grad():\n",
    "        for sample in test_loader_tqdm:\n",
    "            x = sample['input'].to(device0)\n",
    "            lengths = sample['lengths'].to(device0)  \n",
    "            target = sample['output'].cpu().numpy()\n",
    "            output = model(x, lengths).cpu().numpy()\n",
    "\n",
    "            for true_sample, pred_sample in zip(target, output):\n",
    "                r2_Bx = r2_score(true_sample[:, 0].flatten(), pred_sample[:, 0].flatten())\n",
    "                r2_By = r2_score(true_sample[:, 1].flatten(), pred_sample[:, 1].flatten())\n",
    "                r2_Bz = r2_score(true_sample[:, 2].flatten(), pred_sample[:, 2].flatten())\n",
    "\n",
    "                epoch_r2_Bx.append(r2_Bx)\n",
    "                epoch_r2_By.append(r2_By)\n",
    "                epoch_r2_Bz.append(r2_Bz)\n",
    "\n",
    "    avg_r2_Bx = np.mean(epoch_r2_Bx)\n",
    "    avg_r2_By = np.mean(epoch_r2_By)\n",
    "    avg_r2_Bz = np.mean(epoch_r2_Bz)\n",
    "\n",
    "    test_losses_Bx.append(avg_r2_Bx)\n",
    "    test_losses_By.append(avg_r2_By)\n",
    "    test_losses_Bz.append(avg_r2_Bz)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    epoch_durations.append(epoch_duration)\n",
    "\n",
    "    avg_train_loss_combined = (avg_loss_Bx + avg_loss_By + avg_loss_Bz + avg_physics_loss) / 3\n",
    "    scheduler.step(avg_train_loss_combined)\n",
    "\n",
    "    avg_epoch_duration = np.mean(epoch_durations)\n",
    "    remaining_epochs = num_epochs - (epoch + 1)\n",
    "    remaining_time = remaining_epochs * avg_epoch_duration\n",
    "    hours, rem = divmod(remaining_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}, Duration: {epoch_duration:.2f}s, '\n",
    "          f'Train Loss - Bx: {avg_loss_Bx:.4f}, By: {avg_loss_By:.4f}, Bz: {avg_loss_Bz:.4f}, Physics Loss: {avg_physics_loss:.4f}, '\n",
    "          f'Test R2 - Bx: {avg_r2_Bx:.4f}, By: {avg_r2_By:.4f}, Bz: {avg_r2_Bz:.4f}')\n",
    "\n",
    "    print(f'Estimated Remaining Time: {int(hours)}h {int(minutes)}m {int(seconds)}s')\n",
    "\n",
    "    if (epoch + 1) >= save_checkpoint_start_epoch and (epoch + 1) % save_checkpoint_interval == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pt\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}: {checkpoint_path}\")\n",
    "\n",
    "        min_val = float('inf')\n",
    "        max_val = float('-inf')\n",
    "        for sample in test_loader:\n",
    "            y_true_batch = sample['output'].numpy()\n",
    "            batch_min = y_true_batch.min()\n",
    "            batch_max = y_true_batch.max()\n",
    "            min_val = min(min_val, batch_min)\n",
    "            max_val = max(max_val, batch_max)\n",
    "        data_range = max_val - min_val\n",
    "        print(f\"[INFO] data_range = {data_range} (max_val={max_val}, min_val={min_val})\")\n",
    "\n",
    "        type_performance = {}\n",
    "\n",
    "        sample_r2_scores = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_relative_errors = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_mses = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_maes = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_psnr_values = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_ssim_values = {'bx': [], 'by': [], 'bz': []}\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for sample in test_loader:\n",
    "                x = sample['input'].to(device0)\n",
    "                lengths = sample['lengths'].to(device0)  \n",
    "                y_true_batch = sample['output'].cpu().numpy()\n",
    "                y_pred_batch = model(x, lengths).cpu().numpy()\n",
    "\n",
    "                for true_sample, pred_sample in zip(y_true_batch, y_pred_batch):\n",
    "                    for i, comp in enumerate(['bx', 'by', 'bz']):\n",
    "                        true_sample_component = true_sample[:, i]\n",
    "                        pred_sample_component = pred_sample[:, i]\n",
    "\n",
    "                        true_sample_flat = true_sample_component.flatten()\n",
    "                        pred_sample_flat = pred_sample_component.flatten()\n",
    "\n",
    "                        r2 = r2_score(true_sample_flat, pred_sample_flat)\n",
    "                        sample_r2_scores[comp].append(r2)\n",
    "\n",
    "                        absolute_error = np.linalg.norm(true_sample_flat - pred_sample_flat, 1)\n",
    "                        relative_error = absolute_error / np.linalg.norm(true_sample_flat, 1)\n",
    "                        sample_relative_errors[comp].append(relative_error)\n",
    "\n",
    "                        mse = mean_squared_error(true_sample_flat, pred_sample_flat)\n",
    "                        sample_mses[comp].append(mse)\n",
    "\n",
    "                        mae = mean_absolute_error(true_sample_flat, pred_sample_flat)\n",
    "                        sample_maes[comp].append(mae)\n",
    "\n",
    "                        psnr_value = psnr(true_sample_component, pred_sample_component, data_range=data_range)\n",
    "                        sample_psnr_values[comp].append(psnr_value)\n",
    "\n",
    "                        ssim_value = ssim(true_sample_component, pred_sample_component, data_range=data_range)\n",
    "                        sample_ssim_values[comp].append(ssim_value)\n",
    "                        \n",
    "        with open(results_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for comp in ['bx', 'by', 'bz']:\n",
    "                writer.writerow([epoch+1, comp,\n",
    "                                 np.mean(sample_r2_scores[comp]),\n",
    "                                 np.mean(sample_relative_errors[comp]),\n",
    "                                 np.mean(sample_mses[comp]),\n",
    "                                 np.mean(sample_maes[comp]),\n",
    "                                 np.mean(sample_psnr_values[comp]),\n",
    "                                 np.mean(sample_ssim_values[comp])])\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for sample in test_loader:\n",
    "                x = sample['input'].to(device0)\n",
    "                lengths = sample['lengths'].to(device0)  \n",
    "                y_true_batch = sample['output'].cpu().numpy()\n",
    "                y_pred_batch = model(x, lengths).cpu().numpy()\n",
    "\n",
    "                type_labels = sample['type_label_str']  \n",
    "\n",
    "                for true_sample, pred_sample, t_str in zip(y_true_batch, y_pred_batch, type_labels):\n",
    "                    if t_str not in type_performance:\n",
    "                        type_performance[t_str] = {\n",
    "                            'bx': {'r2': [], 'mse': [], 'mae': [], 'psnr': [], 'ssim': [], 'rel_err': []},\n",
    "                            'by': {'r2': [], 'mse': [], 'mae': [], 'psnr': [], 'ssim': [], 'rel_err': []},\n",
    "                            'bz': {'r2': [], 'mse': [], 'mae': [], 'psnr': [], 'ssim': [], 'rel_err': []},\n",
    "                        }\n",
    "\n",
    "                    for i, comp in enumerate(['bx', 'by', 'bz']):\n",
    "                        true_comp = true_sample[:, i].flatten()\n",
    "                        pred_comp = pred_sample[:, i].flatten()\n",
    "                        r2_val = r2_score(true_comp, pred_comp)\n",
    "\n",
    "                        abs_err = np.linalg.norm(true_comp - pred_comp, 1)\n",
    "                        rel_err = abs_err / np.linalg.norm(true_comp, 1)\n",
    "\n",
    "                        mse_val = mean_squared_error(true_comp, pred_comp)\n",
    "\n",
    "                        mae_val = mean_absolute_error(true_comp, pred_comp)\n",
    "\n",
    "                        psnr_val = psnr(true_comp, pred_comp, data_range=data_range)\n",
    "                        ssim_val = ssim(\n",
    "                            true_comp,\n",
    "                            pred_comp,\n",
    "                            data_range=data_range\n",
    "                        )\n",
    "\n",
    "                        metrics = type_performance[t_str][comp]\n",
    "                        metrics['r2'].append(r2_val)\n",
    "                        metrics['rel_err'].append(rel_err)\n",
    "                        metrics['mse'].append(mse_val)\n",
    "                        metrics['mae'].append(mae_val)\n",
    "                        metrics['psnr'].append(psnr_val)\n",
    "                        metrics['ssim'].append(ssim_val)\n",
    "                        \n",
    "        avg_type_performance = {}\n",
    "        for t_str, comp_dict in type_performance.items():\n",
    "            avg_type_performance[t_str] = {}\n",
    "            for comp in ['bx', 'by', 'bz']:\n",
    "                avg_type_performance[t_str][comp] = {\n",
    "                    'r2':    np.mean(comp_dict[comp]['r2']),\n",
    "                    'mse':   np.mean(comp_dict[comp]['mse']),\n",
    "                    'mae':   np.mean(comp_dict[comp]['mae']),\n",
    "                    'psnr':  np.mean(comp_dict[comp]['psnr']),\n",
    "                    'ssim':  np.mean(comp_dict[comp]['ssim']),\n",
    "                    'rel_err': np.mean(comp_dict[comp]['rel_err']),\n",
    "                }\n",
    "\n",
    "        all_types = sorted(avg_type_performance.keys())\n",
    "        comps = ['bx', 'by', 'bz']\n",
    "        \n",
    "        scores_by_comp = []\n",
    "        for comp in comps:\n",
    "            comp_scores = [avg_type_performance[t][comp]['r2'] for t in all_types]\n",
    "            scores_by_comp.append(comp_scores)\n",
    "        scores_by_comp = np.array(scores_by_comp)  # shape: (3, n_types)\n",
    "\n",
    "        plt.figure(figsize=(10,6))\n",
    "        bar_width = 0.25\n",
    "        x = np.arange(len(all_types))\n",
    "\n",
    "        for i, comp in enumerate(comps):\n",
    "            plt.bar(\n",
    "                x + i*bar_width, \n",
    "                scores_by_comp[i], \n",
    "                width=bar_width, \n",
    "                label=comp.upper()\n",
    "            )\n",
    "\n",
    "        plt.xticks(x + bar_width, all_types, rotation=45)\n",
    "        plt.ylabel('R2 Score')\n",
    "        \n",
    "\n",
    "        ax = plt.gca()\n",
    "\n",
    "        ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.4f'))\n",
    "\n",
    "        plt.title(f'Comparison of R2 by Type (Epoch {epoch+1})')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plot_path = os.path.join(checkpoint_dir, f\"R2_bar_chart_epoch_{epoch+1}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Grouped Bar Chart saved: {plot_path}\")\n",
    "\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses_Bx.npy'), np.array(train_losses_Bx))\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses_By.npy'), np.array(train_losses_By))\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses_Bz.npy'), np.array(train_losses_Bz))\n",
    "np.save(os.path.join(checkpoint_dir, 'physics_losses.npy'), np.array(physics_losses))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses_Bx.npy'), np.array(test_losses_Bx))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses_By.npy'), np.array(test_losses_By))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses_Bz.npy'), np.array(test_losses_Bz))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses_Bx, label='Training Loss Bx', color='red')\n",
    "plt.plot(train_losses_By, label='Training Loss By', color='green')\n",
    "plt.plot(train_losses_Bz, label='Training Loss Bz', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses for Bx, By, Bz')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(test_losses_Bx, label='Testing R2 Bx', color='red')\n",
    "plt.plot(test_losses_By, label='Testing R2 By', color='green')\n",
    "plt.plot(test_losses_Bz, label='Testing R2 Bz', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.title('Testing R2 Scores for Bx, By, Bz')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9f3dae-a438-4b02-810a-26fff7cd45a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1975136/477854042.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"result/NLFFF_Cube2Step/step1/checkpoint_epoch_150.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomFNO(\n",
       "  (lifting1): MLP(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Conv3d(1, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (1): Conv3d(256, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (lifting_y): MLP(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Conv1d(3, 256, kernel_size=(1,), stride=(1,))\n",
       "      (1): Conv1d(256, 32, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (DilatedConvYWithECA): DilatedConvYWithECA(\n",
       "    (conv): Conv3d(32, 32, kernel_size=(1, 3, 1), stride=(1, 1, 1), padding=(0, 2, 0), dilation=(1, 2, 1), bias=False)\n",
       "    (activation): ReLU()\n",
       "    (eca): ECA3DLayer(\n",
       "      (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       "      (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (fno_blocks): FNOBlocks(\n",
       "    (convs): SpectralConv(\n",
       "      (weight): ModuleList(\n",
       "        (0-5): 6 x ComplexTuckerTensor(shape=(32, 32, 32, 32, 17), rank=(23, 23, 23, 23, 12))\n",
       "      )\n",
       "    )\n",
       "    (fno_skips): ModuleList(\n",
       "      (0-5): 6 x Conv3d(32, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (mlp): ModuleList(\n",
       "      (0-5): 6 x MLP(\n",
       "        (fcs): ModuleList(\n",
       "          (0): Conv3d(32, 16, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): Conv3d(16, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mlp_skips): ModuleList(\n",
       "      (0-5): 6 x SoftGating()\n",
       "    )\n",
       "  )\n",
       "  (projection): MLP(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Conv3d(32, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (1): Conv3d(256, 25, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"result/NLFFF_Cube2Step/step1/checkpoint_epoch_150.pt\"))\n",
    "model.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "46bd3aa6-515f-42c7-958f-dfaa55838aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Bx shape: (143, 25, 257, 513)\n",
      "All By shape: (143, 25, 257, 513)\n",
      "All Bz shape: (143, 25, 257, 513)\n",
      "All target By shape: (143, 25, 257, 513)\n",
      "All Test Bx shape: (170, 25, 257, 513)\n",
      "All Test By shape: (170, 25, 257, 513)\n",
      "All Test Bz shape: (170, 25, 257, 513)\n",
      "All Test target By shape: (170, 25, 257, 513)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "all_output_Bx = []\n",
    "all_output_By = []\n",
    "all_output_Bz = []\n",
    "all_target_Bx = []\n",
    "all_target_By = []\n",
    "all_target_Bz = []\n",
    "\n",
    "for sample in train_loader:\n",
    "    input_data = sample['input'].to(device0)  \n",
    "    lengths = sample['lengths'].to(device0)  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data, lengths)\n",
    "\n",
    "    output_Bx = output[:, :, 0, :, :].cpu().numpy() \n",
    "    output_By = output[:, :, 1, :, :].cpu().numpy()\n",
    "    output_Bz = output[:, :, 2, :, :].cpu().numpy()  \n",
    "\n",
    "    target_Bx = sample['output'][:, :, 0, :, :].cpu().numpy()  \n",
    "    target_By = sample['output'][:, :, 1, :, :].cpu().numpy()  \n",
    "    target_Bz = sample['output'][:, :, 2, :, :].cpu().numpy() \n",
    "\n",
    "    all_output_Bx.append(output_Bx)\n",
    "    all_output_By.append(output_By)\n",
    "    all_output_Bz.append(output_Bz)\n",
    "\n",
    "    all_target_Bx.append(target_Bx)\n",
    "    all_target_By.append(target_By)\n",
    "    all_target_Bz.append(target_Bz)\n",
    "\n",
    "all_output_Bx = np.concatenate(all_output_Bx, axis=0)\n",
    "all_output_By = np.concatenate(all_output_By, axis=0)\n",
    "all_output_Bz = np.concatenate(all_output_Bz, axis=0)\n",
    "all_target_Bx = np.concatenate(all_target_Bx, axis=0)\n",
    "all_target_By = np.concatenate(all_target_By, axis=0)\n",
    "all_target_Bz = np.concatenate(all_target_Bz, axis=0)\n",
    "\n",
    "print(f'All Bx shape: {all_output_Bx.shape}')\n",
    "print(f'All By shape: {all_output_By.shape}')\n",
    "print(f'All Bz shape: {all_output_Bz.shape}')\n",
    "print(f'All target By shape: {all_target_By.shape}')\n",
    "\n",
    "all_test_output_Bx = []\n",
    "all_test_output_By = []\n",
    "all_test_output_Bz = []\n",
    "all_test_target_Bx = []\n",
    "all_test_target_By = []\n",
    "all_test_target_Bz = []\n",
    "\n",
    "\n",
    "for sample in test_loader:\n",
    "\n",
    "    input_data = sample['input'].to(device0) \n",
    "    lengths = sample['lengths'].to(device0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data, lengths)\n",
    "\n",
    "    output_Bx = output[:, :, 0, :, :].cpu().numpy()\n",
    "    output_By = output[:, :, 1, :, :].cpu().numpy()\n",
    "    output_Bz = output[:, :, 2, :, :].cpu().numpy()  \n",
    "\n",
    "    target_Bx = sample['output'][:, :, 0, :, :].cpu().numpy()  \n",
    "    target_By = sample['output'][:, :, 1, :, :].cpu().numpy()  \n",
    "    target_Bz = sample['output'][:, :, 2, :, :].cpu().numpy()  \n",
    "\n",
    "    all_test_output_Bx.append(output_Bx)\n",
    "    all_test_output_By.append(output_By)\n",
    "    all_test_output_Bz.append(output_Bz)\n",
    "    all_test_target_Bx.append(target_Bx)\n",
    "    all_test_target_By.append(target_By)\n",
    "    all_test_target_Bz.append(target_Bz)\n",
    "\n",
    "all_test_output_Bx = np.concatenate(all_test_output_Bx, axis=0)\n",
    "all_test_output_By = np.concatenate(all_test_output_By, axis=0)\n",
    "all_test_output_Bz = np.concatenate(all_test_output_Bz, axis=0)\n",
    "all_test_target_Bx = np.concatenate(all_test_target_Bx, axis=0)\n",
    "all_test_target_By = np.concatenate(all_test_target_By, axis=0)\n",
    "all_test_target_Bz = np.concatenate(all_test_target_Bz, axis=0)\n",
    "\n",
    "combined_output_Bx = np.concatenate((all_output_Bx, all_test_output_Bx), axis=0)\n",
    "combined_output_By = np.concatenate((all_output_By, all_test_output_By), axis=0)\n",
    "combined_output_Bz = np.concatenate((all_output_Bz, all_test_output_Bz), axis=0)\n",
    "\n",
    "combined_target_Bx = np.concatenate((all_target_Bx, all_test_target_Bx), axis=0)\n",
    "combined_target_By = np.concatenate((all_target_By, all_test_target_By), axis=0)\n",
    "combined_target_Bz = np.concatenate((all_target_Bz, all_test_target_Bz), axis=0)\n",
    "\n",
    "print(f'All Test Bx shape: {combined_output_Bx.shape}')\n",
    "print(f'All Test By shape: {combined_output_By.shape}')\n",
    "print(f'All Test Bz shape: {combined_output_Bz.shape}')\n",
    "\n",
    "print(f'All Test target By shape: {combined_target_By.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ae85aac2-8602-462d-882e-2056e1476ae7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 25, 3, 257, 513])\n",
      "torch.Size([10, 1, 3])\n",
      "torch.Size([10, 25, 3, 257, 513])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class NewCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        Bx_data, By_data, Bz_data, \n",
    "        Bx_targets, By_targets, Bz_targets, \n",
    "        x_lengths, y_lengths, z_lengths,\n",
    "        type_labels=None\n",
    "    ):\n",
    "        \n",
    "        self.Bx_data = Bx_data\n",
    "        self.By_data = By_data\n",
    "        self.Bz_data = Bz_data\n",
    "\n",
    "        self.Bx_targets = Bx_targets\n",
    "        self.By_targets = By_targets\n",
    "        self.Bz_targets = Bz_targets\n",
    "        \n",
    "        self.x_lengths = x_lengths\n",
    "        self.y_lengths = y_lengths\n",
    "        self.z_lengths = z_lengths\n",
    "\n",
    "        self.x_mean = np.mean(self.x_lengths)\n",
    "        self.x_std = np.std(self.x_lengths)\n",
    "\n",
    "        self.y_mean = np.mean(self.y_lengths)\n",
    "        self.y_std = np.std(self.y_lengths)\n",
    "\n",
    "        self.z_mean = np.mean(self.z_lengths)\n",
    "        self.z_std = np.std(self.z_lengths)\n",
    "\n",
    "        self.type_labels = type_labels  \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.Bx_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        input_Bx = self.Bx_data[idx]  \n",
    "        input_By = self.By_data[idx]\n",
    "        input_Bz = self.Bz_data[idx]  \n",
    "\n",
    "        input_data = torch.stack((input_Bx, input_By, input_Bz), dim=1)  \n",
    "\n",
    "        target_Bx = self.Bx_targets[idx]\n",
    "        target_By = self.By_targets[idx]\n",
    "        target_Bz = self.Bz_targets[idx]\n",
    "\n",
    "        target_data = torch.stack((target_Bx, target_By, target_Bz), dim=1)\n",
    "\n",
    "        x_length = self.x_lengths[idx]\n",
    "        y_length = self.y_lengths[idx]\n",
    "        z_length = self.z_lengths[idx]\n",
    "\n",
    "        x_length_normalized = (x_length - self.x_mean) / self.x_std\n",
    "        y_length_normalized = (y_length - self.y_mean) / self.y_std\n",
    "        z_length_normalized = (z_length - self.z_mean) / self.z_std\n",
    "\n",
    "        length_tensor = torch.tensor(\n",
    "            [x_length_normalized, y_length_normalized, z_length_normalized],\n",
    "            dtype=torch.float32\n",
    "        ).unsqueeze(0)\n",
    "\n",
    "        type_label = None\n",
    "        if self.type_labels is not None:\n",
    "            type_label = self.type_labels[idx]\n",
    "        \n",
    "        sample = {\n",
    "            'input': input_data,           \n",
    "            'lengths': length_tensor,\n",
    "            'target': target_data\n",
    "        }\n",
    "\n",
    "        if type_label is not None:\n",
    "            sample['type_label'] = type_label  \n",
    "\n",
    "        return sample\n",
    "\n",
    "x_lengths = np.load(\"NLFFF_data/x_height.npy\")\n",
    "y_lengths = np.load(\"NLFFF_data/y_height.npy\")\n",
    "z_lengths = np.load(\"NLFFF_data/z_height.npy\")\n",
    "\n",
    "combined_output_Bx = torch.tensor(combined_output_Bx).float()\n",
    "combined_output_By = torch.tensor(combined_output_By).float()\n",
    "combined_output_Bz = torch.tensor(combined_output_Bz).float()\n",
    "\n",
    "combined_target_Bx = torch.tensor(combined_target_Bx).float()\n",
    "combined_target_By = torch.tensor(combined_target_By).float()\n",
    "combined_target_Bz = torch.tensor(combined_target_Bz).float()\n",
    "\n",
    "df = pd.read_excel(\"NLFFF_data/NLFFF_datatype.xlsx\")\n",
    "type_labels_from_excel = df[\"type\"].values\n",
    "\n",
    "dataset = NewCustomDataset(combined_output_Bx, combined_output_By, combined_output_Bz, combined_target_Bx, combined_target_By, combined_target_Bz, x_lengths, y_lengths, z_lengths, type_labels_from_excel)\n",
    "\n",
    "train_size = 143\n",
    "test_size = 27\n",
    "\n",
    "train_indices = list(range(train_size))\n",
    "test_indices = list(range(train_size, train_size + test_size))\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=8, persistent_workers=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=8, persistent_workers=False)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch['input'].shape)  \n",
    "    print(batch['lengths'].shape)\n",
    "    print(batch['target'].shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "940a3852-2c3c-4efb-800a-4cf2b2c498e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class PhysicsInformedLoss(nn.Module):\n",
    "    def __init__(self, \n",
    "                 weight=1.0, \n",
    "                 beta=1.0,    \n",
    "                 alpha=1.0,   \n",
    "                 gamma=1.0,   \n",
    "                 delta=1.0,   \n",
    "                 ):\n",
    "        \n",
    "        super(PhysicsInformedLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.beta = beta       \n",
    "        self.gamma = gamma    \n",
    "        self.delta = delta     \n",
    "        self.alpha = alpha     \n",
    "\n",
    "    def forward(self, output, target):\n",
    "\n",
    "        divergence_loss = self.compute_divergence_loss(output)\n",
    "        force_free_loss = self.compute_force_free_loss(output)\n",
    "        grad_diff_loss = self.compute_gradient_difference(output, target)\n",
    "        free_energy_loss = self.compute_free_energy_loss(output, target)\n",
    "\n",
    "        total_loss = self.weight * (\n",
    "            self.beta * divergence_loss +\n",
    "            self.gamma * force_free_loss +\n",
    "            self.alpha * free_energy_loss\n",
    "        )\n",
    "        return total_loss\n",
    "\n",
    "    def compute_divergence_loss(self, output):\n",
    "    \n",
    "        batch_size, depth, components, height, width = output.shape\n",
    "        B = output.permute(0, 2, 1, 3, 4)  # [batch_size, 3, depth, height, width]\n",
    "        channels = components  \n",
    "\n",
    "        device = output.device\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "\n",
    "        kernel_dx = kernel_dx.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(channels, 1, 1, 1, 1)\n",
    "\n",
    "        dB_dx = F.conv3d(B, kernel_dx, padding=(0, 0, 1), groups=channels)\n",
    "        dB_dy = F.conv3d(B, kernel_dy, padding=(0, 1, 0), groups=channels)\n",
    "        dB_dz = F.conv3d(B, kernel_dz, padding=(1, 0, 0), groups=channels)\n",
    "\n",
    "        dB_x_dx = dB_dx[:, 0, :, :, :]\n",
    "        dB_y_dy = dB_dy[:, 1, :, :, :]\n",
    "        dB_z_dz = dB_dz[:, 2, :, :, :]\n",
    "\n",
    "        divergence = dB_x_dx + dB_y_dy + dB_z_dz\n",
    "        divergence_loss = torch.mean(divergence ** 2)\n",
    "\n",
    "        return divergence_loss\n",
    "\n",
    "    def compute_force_free_loss(self, output):\n",
    "        # output: [batch_size, z, 3, y, x]\n",
    "        batch_size, depth, components, height, width = output.shape\n",
    "        B = output.permute(0, 2, 1, 3, 4)  # [batch_size, 3, depth, height, width]\n",
    "        channels = components\n",
    "\n",
    "        device = output.device\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "\n",
    "        kernel_dx = kernel_dx.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(channels, 1, 1, 1, 1)\n",
    "\n",
    "        dB_dx = F.conv3d(B, kernel_dx, padding=(0, 0, 1), groups=channels)\n",
    "        dB_dy = F.conv3d(B, kernel_dy, padding=(0, 1, 0), groups=channels)\n",
    "        dB_dz = F.conv3d(B, kernel_dz, padding=(1, 0, 0), groups=channels)\n",
    "\n",
    "        dB_x_dy = dB_dy[:, 0, :, :, :]\n",
    "        dB_x_dz = dB_dz[:, 0, :, :, :]\n",
    "        dB_y_dx = dB_dx[:, 1, :, :, :]\n",
    "        dB_y_dz = dB_dz[:, 1, :, :, :]\n",
    "        dB_z_dx = dB_dx[:, 2, :, :, :]\n",
    "        dB_z_dy = dB_dy[:, 2, :, :, :]\n",
    "\n",
    "        rot_x = dB_z_dy - dB_y_dz\n",
    "        rot_y = dB_x_dz - dB_z_dx\n",
    "        rot_z = dB_y_dx - dB_x_dy\n",
    "\n",
    "        j = torch.stack([rot_x, rot_y, rot_z], dim=1)\n",
    "\n",
    "        jxb = torch.cross(j, B, dim=1)\n",
    "\n",
    "        B_magnitude_squared = torch.sum(B ** 2, dim=1, keepdim=True) + 1e-7\n",
    "\n",
    "        force_free_loss = torch.mean(torch.sum(jxb ** 2, dim=1) / B_magnitude_squared.squeeze(1))\n",
    "        return force_free_loss\n",
    "\n",
    "    def compute_gradient_difference(self, output, target):\n",
    "        if target.shape != output.shape:\n",
    "            return torch.tensor(0.0, device=output.device)\n",
    "\n",
    "        batch_size, depth, components, height, width = output.shape\n",
    "        B_pred = output.permute(0, 2, 1, 3, 4)   # [batch_size, 3, depth, height, width]\n",
    "        B_true = target.permute(0, 2, 1, 3, 4)\n",
    "        channels = components\n",
    "\n",
    "        device = output.device\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "\n",
    "        kernel_dx = kernel_dx.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(channels, 1, 1, 1, 1)\n",
    "\n",
    "        dBp_dx = F.conv3d(B_pred, kernel_dx, padding=(0, 0, 1), groups=channels)\n",
    "        dBp_dy = F.conv3d(B_pred, kernel_dy, padding=(0, 1, 0), groups=channels)\n",
    "        dBp_dz = F.conv3d(B_pred, kernel_dz, padding=(1, 0, 0), groups=channels)\n",
    "\n",
    "        dBt_dx = F.conv3d(B_true, kernel_dx, padding=(0, 0, 1), groups=channels)\n",
    "        dBt_dy = F.conv3d(B_true, kernel_dy, padding=(0, 1, 0), groups=channels)\n",
    "        dBt_dz = F.conv3d(B_true, kernel_dz, padding=(1, 0, 0), groups=channels)\n",
    "\n",
    "        grad_diff = (dBp_dx - dBt_dx)**2 + \\\n",
    "                    (dBp_dy - dBt_dy)**2 + \\\n",
    "                    (dBp_dz - dBt_dz)**2\n",
    "\n",
    "        loss_val = torch.mean(grad_diff)\n",
    "        return loss_val\n",
    "\n",
    "    def compute_free_energy_loss(self, output, target):\n",
    "    \n",
    "        if output.shape != target.shape:\n",
    "            return torch.tensor(0.0, device=output.device)\n",
    "\n",
    "        B_pred = output.permute(0, 2, 1, 3, 4)\n",
    "        B_true = target.permute(0, 2, 1, 3, 4)\n",
    "\n",
    "        B_diff = B_pred - B_true \n",
    "\n",
    "        B_diff_sq = (B_diff ** 2).sum(dim=(1,2,3,4))     \n",
    "        E_diff = B_diff_sq / (8.0 * math.pi)          \n",
    "\n",
    "        free_energy_loss = torch.mean(E_diff)/1e5\n",
    "\n",
    "        return free_energy_loss\n",
    "\n",
    "class singlePhysicsInformedDivergence_Loss(nn.Module):\n",
    "    def __init__(self, weight=1.0, alpha=1.0, beta=1.0, gamma=1.0):\n",
    "        super(singlePhysicsInformedDivergence_Loss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.alpha = alpha  \n",
    "        self.beta = beta    \n",
    "        self.gamma = gamma  \n",
    "\n",
    "    def forward(self, output, target): \n",
    "        loss = self.compute_single_slice_physics_loss(output)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def compute_single_slice_physics_loss(self, output_slice):\n",
    "\n",
    "        batch_size, components, height, width = output_slice.shape\n",
    "        #print(output_slice.shape)\n",
    "        B = output_slice.unsqueeze(2)\n",
    "        device = output_slice.device\n",
    "\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "\n",
    "        kernel_dx = kernel_dx.repeat(components, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(components, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(components, 1, 1, 1, 1)\n",
    "\n",
    "        dB_dx = F.conv3d(B, kernel_dx, padding=(0, 0, 1), groups=components)\n",
    "        dB_dy = F.conv3d(B, kernel_dy, padding=(0, 1, 0), groups=components)\n",
    "        dB_dz = F.conv3d(B, kernel_dz, padding=(1, 0, 0), groups=components)\n",
    "\n",
    "        dB_x_dx = dB_dx[:, 0, :, :]\n",
    "        dB_y_dy = dB_dy[:, 1, :, :]\n",
    "        dB_z_dz = dB_dz[:, 2, :, :]\n",
    "\n",
    "        divergence = dB_x_dx + dB_y_dy + dB_z_dz\n",
    "        divergence_loss = torch.mean(divergence ** 2, dim=(1, 2, 3))\n",
    "\n",
    "        dB_x_dy = dB_dy[:, 0, :, :]\n",
    "        dB_x_dz = dB_dz[:, 0, :, :]\n",
    "\n",
    "        dB_y_dx = dB_dx[:, 1, :, :]\n",
    "        dB_y_dz = dB_dz[:, 1, :, :]\n",
    "\n",
    "        dB_z_dx = dB_dx[:, 2, :, :]\n",
    "        dB_z_dy = dB_dy[:, 2, :, :]\n",
    "\n",
    "        rot_x = dB_z_dy - dB_y_dz\n",
    "        rot_y = dB_x_dz - dB_z_dx\n",
    "        rot_z = dB_y_dx - dB_x_dy\n",
    "\n",
    "        j = torch.stack([rot_x, rot_y, rot_z], dim=1)  # [batch_size, 3, height, width]\n",
    "\n",
    "        jxb = torch.cross(j, B, dim=1)  # [batch_size, 3, height, width]\n",
    "        B_magnitude_squared = torch.sum(B ** 2, dim=1, keepdim=True) + 1e-7\n",
    "        force_free_loss = torch.mean(torch.sum(jxb ** 2, dim=1) / B_magnitude_squared.squeeze(1), dim=(1, 2, 3))\n",
    "\n",
    "        physics_loss = divergence_loss\n",
    "\n",
    "        return physics_loss\n",
    "\n",
    "class singlePhysicsInformedForce_Free_Loss(nn.Module):\n",
    "    def __init__(self, weight=1.0, alpha=1.0, beta=1.0, gamma=1.0):\n",
    "        super(singlePhysicsInformedForce_Free_Loss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.alpha = alpha  \n",
    "        self.beta = beta    \n",
    "        self.gamma = gamma  \n",
    "\n",
    "    def forward(self, output, target): \n",
    "        loss = self.compute_single_slice_physics_loss(output)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def compute_single_slice_physics_loss(self, output_slice):\n",
    "\n",
    "        batch_size, components, height, width = output_slice.shape\n",
    "        #print(output_slice.shape)\n",
    "        B = output_slice.unsqueeze(2)\n",
    "        device = output_slice.device\n",
    "\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "\n",
    "        kernel_dx = kernel_dx.repeat(components, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(components, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(components, 1, 1, 1, 1)\n",
    "\n",
    "        dB_dx = F.conv3d(B, kernel_dx, padding=(0, 0, 1), groups=components)\n",
    "        dB_dy = F.conv3d(B, kernel_dy, padding=(0, 1, 0), groups=components)\n",
    "        dB_dz = F.conv3d(B, kernel_dz, padding=(1, 0, 0), groups=components)\n",
    "\n",
    "        dB_x_dx = dB_dx[:, 0, :, :]\n",
    "\n",
    "        dB_y_dy = dB_dy[:, 1, :, :]\n",
    "\n",
    "        dB_z_dz = dB_dz[:, 2, :, :]\n",
    "\n",
    "        divergence = dB_x_dx + dB_y_dy + dB_z_dz\n",
    "        divergence_loss = torch.mean(divergence ** 2, dim=(1, 2, 3))\n",
    "\n",
    "        dB_x_dy = dB_dy[:, 0, :, :]\n",
    "        dB_x_dz = dB_dz[:, 0, :, :]\n",
    "\n",
    "        dB_y_dx = dB_dx[:, 1, :, :]\n",
    "        dB_y_dz = dB_dz[:, 1, :, :]\n",
    "\n",
    "        dB_z_dx = dB_dx[:, 2, :, :]\n",
    "        dB_z_dy = dB_dy[:, 2, :, :]\n",
    "\n",
    "        rot_x = dB_z_dy - dB_y_dz\n",
    "        rot_y = dB_x_dz - dB_z_dx\n",
    "        rot_z = dB_y_dx - dB_x_dy\n",
    "\n",
    "        j = torch.stack([rot_x, rot_y, rot_z], dim=1)  # [batch_size, 3, height, width]\n",
    "\n",
    "        jxb = torch.cross(j, B, dim=1)  # [batch_size, 3, height, width]\n",
    "        B_magnitude_squared = torch.sum(B ** 2, dim=1, keepdim=True) + 1e-7\n",
    "        force_free_loss = torch.mean(torch.sum(jxb ** 2, dim=1) / B_magnitude_squared.squeeze(1), dim=(1, 2, 3))\n",
    "\n",
    "        physics_loss = force_free_loss\n",
    "\n",
    "        return physics_loss\n",
    "\n",
    "\n",
    "class ECA3DLayer(nn.Module):\n",
    "    def __init__(self, channel, k_size=3):\n",
    "        super(ECA3DLayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, channels, seq_len, height, width]\n",
    "        \n",
    "        # Global average pooling across seq_len, height, width\n",
    "        y = self.avg_pool(x)  # Shape: [batch_size, channels, 1, 1, 1]\n",
    "\n",
    "        # Apply 1D convolution across the channel dimension\n",
    "        y = self.conv(y.squeeze(-1).squeeze(-1).transpose(-1, -2))  # Shape: [batch_size, 1, channels]\n",
    "        y = y.transpose(-1, -2).unsqueeze(-1).unsqueeze(-1)  # Shape: [batch_size, channels, 1, 1, 1]\n",
    "\n",
    "        # Apply attention to input\n",
    "        return x * self.sigmoid(y).expand_as(x)\n",
    "\n",
    "\n",
    "class DilatedConvYWithECA(nn.Module):\n",
    "    def __init__(self, channels, dilation_y=2, k_size=3):\n",
    "        super(DilatedConvYWithECA, self).__init__()\n",
    "        # Dilated convolution in y dimension\n",
    "        self.conv = nn.Conv3d(\n",
    "            in_channels=channels,\n",
    "            out_channels=channels,\n",
    "            kernel_size=(1, 3, 1),  \n",
    "            padding=(0, dilation_y, 0),  \n",
    "            dilation=(1, dilation_y, 1),\n",
    "            bias=False\n",
    "        )\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        # ECA Attention layer\n",
    "        self.eca = ECA3DLayer(channel=channels, k_size=k_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply dilated convolution\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Apply ECA attention\n",
    "        x = self.eca(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomFNOnew(nn.Module):\n",
    "    def __init__(self, n_modes, hidden_channels, in_channels=3, out_channels=1,\n",
    "                 lifting_channels=256, projection_channels=256, n_layers=4,\n",
    "                 output_scaling_factor=None, max_n_modes=None,\n",
    "                 fno_block_precision=\"full\", use_mlp=False, mlp_dropout=0,\n",
    "                 mlp_expansion=0.5, non_linearity=F.gelu, stabilizer=None,\n",
    "                 norm=None, preactivation=False, fno_skip=\"linear\",\n",
    "                 mlp_skip=\"soft-gating\", separable=False, factorization=None,\n",
    "                 rank=1.0, joint_factorization=False, fixed_rank_modes=False,\n",
    "                 implementation=\"factorized\", decomposition_kwargs=dict(),\n",
    "                 domain_padding=None, domain_padding_mode=\"one-sided\",\n",
    "                 fft_norm=\"forward\", SpectralConv=SpectralConv,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.n_dim = len(n_modes)\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Define the ECA-Net block for lengths_lifted\n",
    "        self.DilatedConvYWithECA = DilatedConvYWithECA(hidden_channels, dilation_y=2).to(device0)\n",
    "\n",
    "        # Define the lifting layers for two inputs\n",
    "        self.lifting1 = MLP(\n",
    "            in_channels=3,\n",
    "            out_channels=hidden_channels,\n",
    "            hidden_channels=lifting_channels,\n",
    "            n_layers=1,\n",
    "            n_dim=self.n_dim,\n",
    "        ).to(device0)\n",
    "        \n",
    "        self.lifting_y = MLP(\n",
    "            in_channels=3,  \n",
    "            out_channels=hidden_channels,\n",
    "            hidden_channels=lifting_channels,\n",
    "            n_layers=2,\n",
    "            n_dim=1,\n",
    "        ).to(device0)\n",
    "        \n",
    "    \n",
    "        # Define the FNO blocks\n",
    "        self.fno_blocks = FNOBlocks(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            n_modes=n_modes,\n",
    "            output_scaling_factor=output_scaling_factor,\n",
    "            use_mlp=use_mlp,\n",
    "            mlp_dropout=mlp_dropout,\n",
    "            mlp_expansion=mlp_expansion,\n",
    "            non_linearity=non_linearity,\n",
    "            stabilizer=stabilizer,\n",
    "            norm=norm,\n",
    "            preactivation=preactivation,\n",
    "            fno_skip=fno_skip,\n",
    "            mlp_skip=mlp_skip,\n",
    "            max_n_modes=max_n_modes,\n",
    "            fno_block_precision=fno_block_precision,\n",
    "            rank=rank,\n",
    "            fft_norm=fft_norm,\n",
    "            fixed_rank_modes=fixed_rank_modes,\n",
    "            implementation=implementation,\n",
    "            separable=separable,\n",
    "            factorization=factorization,\n",
    "            decomposition_kwargs=decomposition_kwargs,\n",
    "            joint_factorization=joint_factorization,\n",
    "            SpectralConv=SpectralConv,\n",
    "            n_layers=n_layers,\n",
    "            **kwargs\n",
    "        ).to(device0)\n",
    "\n",
    "        self.projection = MLP(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=out_channels,\n",
    "            hidden_channels=projection_channels,\n",
    "            n_layers=2,\n",
    "            n_dim=self.n_dim,\n",
    "            non_linearity=non_linearity,\n",
    "        ).to(device0)\n",
    "\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "\n",
    "        x_orig = x.clone()\n",
    "        \n",
    "        lengths = lengths.view(-1, 3, 1)  \n",
    "\n",
    "        lengths_lifted = self.lifting_y(lengths)  \n",
    "\n",
    "        lengths_lifted = lengths_lifted.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        lengths_lifted = self.DilatedConvYWithECA(lengths_lifted)\n",
    "        \n",
    "        x = x + lengths_lifted\n",
    "\n",
    "        for layer_idx in range(self.n_layers):\n",
    "            x = self.fno_blocks(x, layer_idx)\n",
    "\n",
    "        x = self.projection(x)\n",
    "\n",
    "        x[:, 0, :, :, :] = x_orig[:, 0, :, :, :]\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59d3c1de-9bc4-4a56-a56f-c4354a3c1f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Your model has 24742316 parameters.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jc2687/.local/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:60: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "newmodel = CustomFNOnew(n_modes = (32, 32, 32), in_channels=1, out_channels=25, n_layers = 6,\n",
    "               hidden_channels=25, use_mlp=True, factorization='tucker', rank=0.2)\n",
    "\n",
    "newmodel = newmodel.to(device0)\n",
    "\n",
    "n_params = count_model_params(newmodel)\n",
    "print(f'\\nYour model has {n_params} parameters.')\n",
    "\n",
    "optimizer = torch.optim.Adam(newmodel.parameters(), lr=1e-3, weight_decay=1e-4) \n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=1, verbose=True)\n",
    "\n",
    "h1loss = H1Loss(d=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4683b82-4531-443f-b006-71921902ec32",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 1/150: 100%|██████████| 15/15 [00:45<00:00,  3.06s/it, loss_Bx=10.5, loss_By=10.5, loss_Bz=10.4, physics_loss=1.4]\n",
      "Test Epoch 1/150: 100%|██████████| 3/3 [00:03<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/150, Duration: 50.24s, Train Loss - Bx: 8.5516, By: 8.6002, Bz: 8.4173, Physics Loss: 1.0573, Test R2 - Bx: 0.3864, By: 0.3678, Bz: 0.3990\n",
      "Estimated Remaining Time: 2h 4m 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 2/150: 100%|██████████| 15/15 [00:42<00:00,  2.83s/it, loss_Bx=7.83, loss_By=7.85, loss_Bz=7.41, physics_loss=0.799]\n",
      "Test Epoch 2/150: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/150, Duration: 46.94s, Train Loss - Bx: 6.6102, By: 6.7468, Bz: 6.4801, Physics Loss: 0.7024, Test R2 - Bx: 0.6909, By: 0.6643, Bz: 0.7367\n",
      "Estimated Remaining Time: 1h 59m 52s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 3/150: 100%|██████████| 15/15 [00:43<00:00,  2.88s/it, loss_Bx=6.16, loss_By=6.61, loss_Bz=5.31, physics_loss=0.427]\n",
      "Test Epoch 3/150: 100%|██████████| 3/3 [00:03<00:00,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/150, Duration: 47.51s, Train Loss - Bx: 5.4065, By: 5.4094, Bz: 4.5533, Physics Loss: 0.2834, Test R2 - Bx: 0.8599, By: 0.8530, Bz: 0.8964\n",
      "Estimated Remaining Time: 1h 58m 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 4/150: 100%|██████████| 15/15 [00:26<00:00,  1.78s/it, loss_Bx=5.27, loss_By=5.06, loss_Bz=4.12, physics_loss=0.189]\n",
      "Test Epoch 4/150: 100%|██████████| 3/3 [00:03<00:00,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/150, Duration: 30.53s, Train Loss - Bx: 4.8209, By: 4.7731, Bz: 3.8404, Physics Loss: 0.1716, Test R2 - Bx: 0.8831, By: 0.8650, Bz: 0.9180\n",
      "Estimated Remaining Time: 1h 46m 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 5/150: 100%|██████████| 15/15 [00:25<00:00,  1.73s/it, loss_Bx=4.64, loss_By=4.92, loss_Bz=3.61, physics_loss=0.172]\n",
      "Test Epoch 5/150: 100%|██████████| 3/3 [00:03<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/150, Duration: 29.79s, Train Loss - Bx: 4.5583, By: 4.4776, Bz: 3.4931, Physics Loss: 0.1331, Test R2 - Bx: 0.9131, By: 0.9006, Bz: 0.9436\n",
      "Estimated Remaining Time: 1h 39m 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 6/150: 100%|██████████| 15/15 [00:26<00:00,  1.77s/it, loss_Bx=4.62, loss_By=4.75, loss_Bz=3.53, physics_loss=0.122]\n",
      "Test Epoch 6/150: 100%|██████████| 3/3 [00:03<00:00,  1.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/150, Duration: 30.69s, Train Loss - Bx: 4.4268, By: 4.3376, Bz: 3.3116, Physics Loss: 0.1084, Test R2 - Bx: 0.9265, By: 0.9184, Bz: 0.9564\n",
      "Estimated Remaining Time: 1h 34m 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 7/150: 100%|██████████| 15/15 [00:26<00:00,  1.78s/it, loss_Bx=4.82, loss_By=4.68, loss_Bz=3.58, physics_loss=0.111]\n",
      "Test Epoch 7/150: 100%|██████████| 3/3 [00:03<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/150, Duration: 30.44s, Train Loss - Bx: 4.3627, By: 4.2705, Bz: 3.2139, Physics Loss: 0.0995, Test R2 - Bx: 0.9280, By: 0.9174, Bz: 0.9615\n",
      "Estimated Remaining Time: 1h 30m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 8/150: 100%|██████████| 15/15 [00:26<00:00,  1.75s/it, loss_Bx=4.56, loss_By=4.08, loss_Bz=3.32, physics_loss=0.0936]\n",
      "Test Epoch 8/150: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/150, Duration: 30.22s, Train Loss - Bx: 4.3284, By: 4.2353, Bz: 3.1694, Physics Loss: 0.1033, Test R2 - Bx: 0.9235, By: 0.9139, Bz: 0.9566\n",
      "Estimated Remaining Time: 1h 27m 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 9/150: 100%|██████████| 15/15 [00:25<00:00,  1.71s/it, loss_Bx=4.43, loss_By=4.04, loss_Bz=3.22, physics_loss=0.0999]\n",
      "Test Epoch 9/150: 100%|██████████| 3/3 [00:03<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/150, Duration: 29.22s, Train Loss - Bx: 4.3015, By: 4.2124, Bz: 3.1315, Physics Loss: 0.0960, Test R2 - Bx: 0.9302, By: 0.9225, Bz: 0.9658\n",
      "Estimated Remaining Time: 1h 25m 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 10/150: 100%|██████████| 15/15 [00:25<00:00,  1.73s/it, loss_Bx=4.55, loss_By=4.87, loss_Bz=3.4, physics_loss=0.0979]\n",
      "Test Epoch 10/150: 100%|██████████| 3/3 [00:03<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/150, Duration: 30.14s, Train Loss - Bx: 4.2869, By: 4.1937, Bz: 3.1135, Physics Loss: 0.0997, Test R2 - Bx: 0.9179, By: 0.9083, Bz: 0.9523\n",
      "Estimated Remaining Time: 1h 23m 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 11/150: 100%|██████████| 15/15 [00:26<00:00,  1.75s/it, loss_Bx=4.44, loss_By=4.21, loss_Bz=3.23, physics_loss=0.0988]\n",
      "Test Epoch 11/150: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 11/150, Duration: 30.27s, Train Loss - Bx: 4.2920, By: 4.2009, Bz: 3.1266, Physics Loss: 0.1142, Test R2 - Bx: 0.9263, By: 0.9138, Bz: 0.9546\n",
      "Estimated Remaining Time: 1h 21m 17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 12/150: 100%|██████████| 15/15 [00:25<00:00,  1.72s/it, loss_Bx=4.71, loss_By=4.43, loss_Bz=3.3, physics_loss=0.102]\n",
      "Test Epoch 12/150: 100%|██████████| 3/3 [00:03<00:00,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 12/150, Duration: 29.35s, Train Loss - Bx: 4.2691, By: 4.1775, Bz: 3.0892, Physics Loss: 0.0963, Test R2 - Bx: 0.9306, By: 0.9204, Bz: 0.9635\n",
      "Estimated Remaining Time: 1h 19m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 13/150: 100%|██████████| 15/15 [00:26<00:00,  1.75s/it, loss_Bx=4.29, loss_By=4.39, loss_Bz=3.1, physics_loss=0.0929]\n",
      "Test Epoch 13/150: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 13/150, Duration: 30.26s, Train Loss - Bx: 4.2596, By: 4.1676, Bz: 3.0744, Physics Loss: 0.0913, Test R2 - Bx: 0.9366, By: 0.9264, Bz: 0.9686\n",
      "Estimated Remaining Time: 1h 18m 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 14/150: 100%|██████████| 15/15 [00:25<00:00,  1.73s/it, loss_Bx=4.18, loss_By=4.66, loss_Bz=3.12, physics_loss=0.0851]\n",
      "Test Epoch 14/150: 100%|██████████| 3/3 [00:03<00:00,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 14/150, Duration: 30.10s, Train Loss - Bx: 4.2492, By: 4.1579, Bz: 3.0599, Physics Loss: 0.0889, Test R2 - Bx: 0.9350, By: 0.9245, Bz: 0.9703\n",
      "Estimated Remaining Time: 1h 17m 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 15/150: 100%|██████████| 15/15 [00:25<00:00,  1.72s/it, loss_Bx=4.04, loss_By=3.8, loss_Bz=2.82, physics_loss=0.0631]\n",
      "Test Epoch 15/150: 100%|██████████| 3/3 [00:03<00:00,  1.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 15/150, Duration: 29.74s, Train Loss - Bx: 4.2442, By: 4.1543, Bz: 3.0524, Physics Loss: 0.0874, Test R2 - Bx: 0.9299, By: 0.9214, Bz: 0.9658\n",
      "Estimated Remaining Time: 1h 15m 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 16/150: 100%|██████████| 15/15 [00:25<00:00,  1.73s/it, loss_Bx=4.79, loss_By=4.63, loss_Bz=3.45, physics_loss=0.111]\n",
      "Test Epoch 16/150: 100%|██████████| 3/3 [00:03<00:00,  1.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 16/150, Duration: 30.06s, Train Loss - Bx: 4.2389, By: 4.1529, Bz: 3.0519, Physics Loss: 0.0912, Test R2 - Bx: 0.9338, By: 0.9228, Bz: 0.9704\n",
      "Estimated Remaining Time: 1h 14m 44s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 17/150: 100%|██████████| 15/15 [00:25<00:00,  1.72s/it, loss_Bx=4.45, loss_By=4.41, loss_Bz=3.15, physics_loss=0.0875]\n",
      "Test Epoch 17/150: 100%|██████████| 3/3 [00:03<00:00,  1.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 17/150, Duration: 29.87s, Train Loss - Bx: 4.2389, By: 4.1462, Bz: 3.0451, Physics Loss: 0.0854, Test R2 - Bx: 0.9356, By: 0.9270, Bz: 0.9672\n",
      "Estimated Remaining Time: 1h 13m 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 18/150: 100%|██████████| 15/15 [00:25<00:00,  1.72s/it, loss_Bx=4.31, loss_By=4.06, loss_Bz=3.02, physics_loss=0.0744]\n",
      "Test Epoch 18/150: 100%|██████████| 3/3 [00:03<00:00,  1.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 18/150, Duration: 29.87s, Train Loss - Bx: 4.2331, By: 4.1415, Bz: 3.0365, Physics Loss: 0.0866, Test R2 - Bx: 0.9337, By: 0.9224, Bz: 0.9689\n",
      "Estimated Remaining Time: 1h 12m 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 19/150: 100%|██████████| 15/15 [00:26<00:00,  1.74s/it, loss_Bx=4.53, loss_By=4.71, loss_Bz=3.35, physics_loss=0.0956]\n",
      "Test Epoch 19/150: 100%|██████████| 3/3 [00:03<00:00,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 19/150, Duration: 30.12s, Train Loss - Bx: 4.2330, By: 4.1417, Bz: 3.0388, Physics Loss: 0.0917, Test R2 - Bx: 0.9283, By: 0.9166, Bz: 0.9640\n",
      "Estimated Remaining Time: 1h 11m 51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 20/150: 100%|██████████| 15/15 [00:26<00:00,  1.76s/it, loss_Bx=4.13, loss_By=3.93, loss_Bz=3.01, physics_loss=0.0853]\n",
      "Test Epoch 20/150: 100%|██████████| 3/3 [00:03<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 20/150, Duration: 30.54s, Train Loss - Bx: 4.2335, By: 4.1469, Bz: 3.0478, Physics Loss: 0.0961, Test R2 - Bx: 0.9314, By: 0.9241, Bz: 0.9646\n",
      "Estimated Remaining Time: 1h 11m 3s\n",
      "Checkpoint saved at epoch 20: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_20.pt\n",
      "bx - Mean: -2.4474583817934992e-11, Std: 1.0\n",
      "by - Mean: 7.899204727823683e-12, Std: 0.9999974966049194\n",
      "bz - Mean: -7.704961668686394e-11, Std: 0.999999463558197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 21/150: 100%|██████████| 15/15 [00:27<00:00,  1.81s/it, loss_Bx=4.38, loss_By=4.54, loss_Bz=3.33, physics_loss=0.105]\n",
      "Test Epoch 21/150: 100%|██████████| 3/3 [00:20<00:00,  6.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 21/150, Duration: 49.39s, Train Loss - Bx: 4.2231, By: 4.1361, Bz: 3.0324, Physics Loss: 0.0892, Test R2 - Bx: 0.9306, By: 0.9213, Bz: 0.9645\n",
      "Estimated Remaining Time: 1h 12m 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 22/150: 100%|██████████| 15/15 [00:27<00:00,  1.81s/it, loss_Bx=4.2, loss_By=3.99, loss_Bz=3.04, physics_loss=0.0872]\n",
      "Test Epoch 22/150: 100%|██████████| 3/3 [00:06<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 22/150, Duration: 35.70s, Train Loss - Bx: 4.2196, By: 4.1344, Bz: 3.0350, Physics Loss: 0.0950, Test R2 - Bx: 0.9105, By: 0.9049, Bz: 0.9442\n",
      "Estimated Remaining Time: 1h 11m 51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 23/150: 100%|██████████| 15/15 [00:28<00:00,  1.87s/it, loss_Bx=4.22, loss_By=4.26, loss_Bz=3.05, physics_loss=0.114]\n",
      "Test Epoch 23/150: 100%|██████████| 3/3 [00:06<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 23/150, Duration: 36.69s, Train Loss - Bx: 4.2263, By: 4.1405, Bz: 3.0480, Physics Loss: 0.0985, Test R2 - Bx: 0.9346, By: 0.9199, Bz: 0.9675\n",
      "Estimated Remaining Time: 1h 11m 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 24/150: 100%|██████████| 15/15 [00:27<00:00,  1.86s/it, loss_Bx=4.49, loss_By=4.48, loss_Bz=3.29, physics_loss=0.09]\n",
      "Test Epoch 24/150: 100%|██████████| 3/3 [00:06<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 24/150, Duration: 36.30s, Train Loss - Bx: 4.2223, By: 4.1282, Bz: 3.0372, Physics Loss: 0.0878, Test R2 - Bx: 0.9344, By: 0.9236, Bz: 0.9689\n",
      "Estimated Remaining Time: 1h 11m 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 25/150: 100%|██████████| 15/15 [00:28<00:00,  1.88s/it, loss_Bx=4.44, loss_By=4.45, loss_Bz=3.18, physics_loss=0.0894]\n",
      "Test Epoch 25/150: 100%|██████████| 3/3 [00:06<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 25/150, Duration: 37.55s, Train Loss - Bx: 4.2068, By: 4.1216, Bz: 3.0203, Physics Loss: 0.0834, Test R2 - Bx: 0.9388, By: 0.9276, Bz: 0.9716\n",
      "Estimated Remaining Time: 1h 10m 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 26/150: 100%|██████████| 15/15 [00:27<00:00,  1.82s/it, loss_Bx=4.45, loss_By=4.75, loss_Bz=3.19, physics_loss=0.0872]\n",
      "Test Epoch 26/150: 100%|██████████| 3/3 [00:06<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26/150, Duration: 36.57s, Train Loss - Bx: 4.2028, By: 4.1139, Bz: 3.0170, Physics Loss: 0.0836, Test R2 - Bx: 0.9389, By: 0.9299, Bz: 0.9718\n",
      "Estimated Remaining Time: 1h 10m 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 27/150: 100%|██████████| 15/15 [00:27<00:00,  1.86s/it, loss_Bx=3.99, loss_By=3.94, loss_Bz=2.79, physics_loss=0.0629]\n",
      "Test Epoch 27/150: 100%|██████████| 3/3 [00:15<00:00,  5.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27/150, Duration: 45.54s, Train Loss - Bx: 4.2033, By: 4.1082, Bz: 3.0162, Physics Loss: 0.0840, Test R2 - Bx: 0.9342, By: 0.9271, Bz: 0.9683\n",
      "Estimated Remaining Time: 1h 10m 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 28/150: 100%|██████████| 15/15 [00:28<00:00,  1.89s/it, loss_Bx=4.69, loss_By=4.83, loss_Bz=3.37, physics_loss=0.104]\n",
      "Test Epoch 28/150: 100%|██████████| 3/3 [00:07<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 28/150, Duration: 38.23s, Train Loss - Bx: 4.2017, By: 4.1049, Bz: 3.0145, Physics Loss: 0.0859, Test R2 - Bx: 0.9316, By: 0.9261, Bz: 0.9624\n",
      "Estimated Remaining Time: 1h 10m 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 29/150: 100%|██████████| 15/15 [00:27<00:00,  1.85s/it, loss_Bx=4.59, loss_By=4.48, loss_Bz=3.32, physics_loss=0.0919]\n",
      "Test Epoch 29/150: 100%|██████████| 3/3 [00:07<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29/150, Duration: 37.48s, Train Loss - Bx: 4.2071, By: 4.1079, Bz: 3.0230, Physics Loss: 0.0846, Test R2 - Bx: 0.9357, By: 0.9225, Bz: 0.9707\n",
      "Estimated Remaining Time: 1h 10m 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 30/150: 100%|██████████| 15/15 [00:28<00:00,  1.88s/it, loss_Bx=4.26, loss_By=4.43, loss_Bz=3.13, physics_loss=0.0876]\n",
      "Test Epoch 30/150: 100%|██████████| 3/3 [00:07<00:00,  2.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 30/150, Duration: 37.80s, Train Loss - Bx: 4.2024, By: 4.1041, Bz: 3.0266, Physics Loss: 0.0882, Test R2 - Bx: 0.9369, By: 0.9283, Bz: 0.9702\n",
      "Estimated Remaining Time: 1h 9m 48s\n",
      "Checkpoint saved at epoch 30: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_30.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx - Mean: 4.046723459799617e-12, Std: 0.9999992251396179\n",
      "by - Mean: -3.7812586395347125e-11, Std: 1.0000017881393433\n",
      "bz - Mean: -2.2273167685216144e-11, Std: 1.000000238418579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 31/150: 100%|██████████| 15/15 [00:29<00:00,  1.95s/it, loss_Bx=4.54, loss_By=4.49, loss_Bz=3.26, physics_loss=0.0905]\n",
      "Test Epoch 31/150: 100%|██████████| 3/3 [00:09<00:00,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31/150, Duration: 42.28s, Train Loss - Bx: 4.1958, By: 4.0917, Bz: 3.0111, Physics Loss: 0.0843, Test R2 - Bx: 0.9374, By: 0.9295, Bz: 0.9711\n",
      "Estimated Remaining Time: 1h 9m 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 32/150: 100%|██████████| 15/15 [00:28<00:00,  1.89s/it, loss_Bx=4.37, loss_By=4.32, loss_Bz=3.16, physics_loss=0.0877]\n",
      "Test Epoch 32/150: 100%|██████████| 3/3 [00:09<00:00,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 32/150, Duration: 42.85s, Train Loss - Bx: 4.1880, By: 4.0928, Bz: 3.0128, Physics Loss: 0.0827, Test R2 - Bx: 0.9377, By: 0.9292, Bz: 0.9724\n",
      "Estimated Remaining Time: 1h 9m 35s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 33/150: 100%|██████████| 15/15 [00:28<00:00,  1.87s/it, loss_Bx=4.4, loss_By=4.51, loss_Bz=3.03, physics_loss=0.0748]\n",
      "Test Epoch 33/150: 100%|██████████| 3/3 [00:08<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 33/150, Duration: 39.83s, Train Loss - Bx: 4.1876, By: 4.0835, Bz: 3.0098, Physics Loss: 0.0829, Test R2 - Bx: 0.9366, By: 0.9284, Bz: 0.9705\n",
      "Estimated Remaining Time: 1h 9m 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 34/150: 100%|██████████| 15/15 [00:27<00:00,  1.85s/it, loss_Bx=4.42, loss_By=4.37, loss_Bz=3.23, physics_loss=0.0887]\n",
      "Test Epoch 34/150: 100%|██████████| 3/3 [00:08<00:00,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 34/150, Duration: 40.23s, Train Loss - Bx: 4.1835, By: 4.0752, Bz: 3.0112, Physics Loss: 0.0851, Test R2 - Bx: 0.9361, By: 0.9284, Bz: 0.9704\n",
      "Estimated Remaining Time: 1h 8m 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 35/150: 100%|██████████| 15/15 [00:28<00:00,  1.89s/it, loss_Bx=4.64, loss_By=4.87, loss_Bz=3.43, physics_loss=0.1]\n",
      "Test Epoch 35/150: 100%|██████████| 3/3 [00:08<00:00,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 35/150, Duration: 39.60s, Train Loss - Bx: 4.1740, By: 4.0660, Bz: 3.0071, Physics Loss: 0.0831, Test R2 - Bx: 0.9386, By: 0.9300, Bz: 0.9715\n",
      "Estimated Remaining Time: 1h 8m 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 36/150: 100%|██████████| 15/15 [00:28<00:00,  1.90s/it, loss_Bx=4.15, loss_By=4.09, loss_Bz=3.03, physics_loss=0.0798]\n",
      "Test Epoch 36/150: 100%|██████████| 3/3 [00:08<00:00,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 36/150, Duration: 41.57s, Train Loss - Bx: 4.1758, By: 4.0589, Bz: 3.0055, Physics Loss: 0.0820, Test R2 - Bx: 0.9377, By: 0.9301, Bz: 0.9715\n",
      "Estimated Remaining Time: 1h 8m 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 37/150: 100%|██████████| 15/15 [00:27<00:00,  1.86s/it, loss_Bx=4.76, loss_By=4.25, loss_Bz=3.43, physics_loss=0.0937]\n",
      "Test Epoch 37/150: 100%|██████████| 3/3 [00:09<00:00,  3.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 37/150, Duration: 42.37s, Train Loss - Bx: 4.1678, By: 4.0472, Bz: 3.0075, Physics Loss: 0.0821, Test R2 - Bx: 0.9381, By: 0.9289, Bz: 0.9700\n",
      "Estimated Remaining Time: 1h 7m 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 38/150: 100%|██████████| 15/15 [00:27<00:00,  1.84s/it, loss_Bx=4.41, loss_By=4.05, loss_Bz=3, physics_loss=0.0684]\n",
      "Test Epoch 38/150: 100%|██████████| 3/3 [00:09<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 38/150, Duration: 41.70s, Train Loss - Bx: 4.1922, By: 4.0867, Bz: 3.0227, Physics Loss: 0.0846, Test R2 - Bx: 0.9391, By: 0.9296, Bz: 0.9717\n",
      "Estimated Remaining Time: 1h 7m 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 39/150: 100%|██████████| 15/15 [00:32<00:00,  2.17s/it, loss_Bx=4.57, loss_By=4.52, loss_Bz=3.33, physics_loss=0.0937]\n",
      "Test Epoch 39/150: 100%|██████████| 3/3 [00:08<00:00,  2.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 39/150, Duration: 46.22s, Train Loss - Bx: 4.1724, By: 4.0432, Bz: 3.0041, Physics Loss: 0.0835, Test R2 - Bx: 0.9373, By: 0.9275, Bz: 0.9703\n",
      "Estimated Remaining Time: 1h 7m 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 40/150: 100%|██████████| 15/15 [00:38<00:00,  2.55s/it, loss_Bx=4.31, loss_By=4.03, loss_Bz=3.13, physics_loss=0.0838]\n",
      "Test Epoch 40/150: 100%|██████████| 3/3 [00:09<00:00,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 40/150, Duration: 52.69s, Train Loss - Bx: 4.1606, By: 4.0228, Bz: 3.0057, Physics Loss: 0.0817, Test R2 - Bx: 0.9386, By: 0.9292, Bz: 0.9713\n",
      "Estimated Remaining Time: 1h 7m 40s\n",
      "Checkpoint saved at epoch 40: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_40.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx - Mean: 2.160950411667084e-11, Std: 0.9999986886978149\n",
      "by - Mean: -9.73803607196011e-11, Std: 1.0000020265579224\n",
      "bz - Mean: -4.0325603099800045e-12, Std: 0.9999994039535522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 41/150: 100%|██████████| 15/15 [00:39<00:00,  2.65s/it, loss_Bx=4.33, loss_By=3.96, loss_Bz=3.05, physics_loss=0.0829]\n",
      "Test Epoch 41/150: 100%|██████████| 3/3 [00:13<00:00,  4.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 41/150, Duration: 56.30s, Train Loss - Bx: 4.1659, By: 4.0217, Bz: 3.0124, Physics Loss: 0.0832, Test R2 - Bx: 0.9354, By: 0.9275, Bz: 0.9716\n",
      "Estimated Remaining Time: 1h 7m 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 42/150: 100%|██████████| 15/15 [00:40<00:00,  2.72s/it, loss_Bx=4.49, loss_By=4.17, loss_Bz=3.33, physics_loss=0.0917]\n",
      "Test Epoch 42/150: 100%|██████████| 3/3 [00:07<00:00,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 42/150, Duration: 51.49s, Train Loss - Bx: 4.1656, By: 4.0474, Bz: 3.0140, Physics Loss: 0.0855, Test R2 - Bx: 0.9344, By: 0.9286, Bz: 0.9676\n",
      "Estimated Remaining Time: 1h 7m 53s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 43/150: 100%|██████████| 15/15 [00:40<00:00,  2.70s/it, loss_Bx=5.04, loss_By=4.6, loss_Bz=3.48, physics_loss=0.0938]\n",
      "Test Epoch 43/150: 100%|██████████| 3/3 [00:07<00:00,  2.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 43/150, Duration: 50.56s, Train Loss - Bx: 4.1681, By: 4.0426, Bz: 3.0128, Physics Loss: 0.0862, Test R2 - Bx: 0.9368, By: 0.9298, Bz: 0.9699\n",
      "Estimated Remaining Time: 1h 7m 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 44/150: 100%|██████████| 15/15 [00:36<00:00,  2.42s/it, loss_Bx=4.55, loss_By=4.06, loss_Bz=3.19, physics_loss=0.0805]\n",
      "Test Epoch 44/150: 100%|██████████| 3/3 [00:08<00:00,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 44/150, Duration: 47.48s, Train Loss - Bx: 4.1407, By: 3.9735, Bz: 2.9947, Physics Loss: 0.0830, Test R2 - Bx: 0.9388, By: 0.9301, Bz: 0.9714\n",
      "Estimated Remaining Time: 1h 7m 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 45/150: 100%|██████████| 15/15 [00:27<00:00,  1.87s/it, loss_Bx=4.81, loss_By=4.65, loss_Bz=3.52, physics_loss=0.0931]\n",
      "Test Epoch 45/150: 100%|██████████| 3/3 [00:07<00:00,  2.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 45/150, Duration: 38.87s, Train Loss - Bx: 4.1231, By: 3.9377, Bz: 2.9933, Physics Loss: 0.0835, Test R2 - Bx: 0.9342, By: 0.9262, Bz: 0.9679\n",
      "Estimated Remaining Time: 1h 6m 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 46/150: 100%|██████████| 15/15 [00:27<00:00,  1.85s/it, loss_Bx=4.12, loss_By=3.97, loss_Bz=2.98, physics_loss=0.0808]\n",
      "Test Epoch 46/150: 100%|██████████| 3/3 [00:07<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 46/150, Duration: 38.98s, Train Loss - Bx: 4.1514, By: 4.0728, Bz: 3.0264, Physics Loss: 0.0862, Test R2 - Bx: 0.9364, By: 0.9240, Bz: 0.9687\n",
      "Estimated Remaining Time: 1h 6m 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 47/150: 100%|██████████| 15/15 [00:27<00:00,  1.84s/it, loss_Bx=4.43, loss_By=4.04, loss_Bz=3.14, physics_loss=0.0845]\n",
      "Test Epoch 47/150: 100%|██████████| 3/3 [00:08<00:00,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 47/150, Duration: 38.92s, Train Loss - Bx: 4.1254, By: 4.0386, Bz: 2.9926, Physics Loss: 0.0853, Test R2 - Bx: 0.9312, By: 0.9209, Bz: 0.9620\n",
      "Estimated Remaining Time: 1h 5m 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 48/150: 100%|██████████| 15/15 [00:27<00:00,  1.85s/it, loss_Bx=4.45, loss_By=4.51, loss_Bz=3.28, physics_loss=0.107]\n",
      "Test Epoch 48/150: 100%|██████████| 3/3 [00:07<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 48/150, Duration: 38.63s, Train Loss - Bx: 4.0978, By: 4.0190, Bz: 2.9816, Physics Loss: 0.0849, Test R2 - Bx: 0.9355, By: 0.9273, Bz: 0.9706\n",
      "Estimated Remaining Time: 1h 5m 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 49/150: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s, loss_Bx=3.77, loss_By=3.83, loss_Bz=2.95, physics_loss=0.0768]\n",
      "Test Epoch 49/150: 100%|██████████| 3/3 [00:06<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 49/150, Duration: 24.28s, Train Loss - Bx: 4.0824, By: 4.0024, Bz: 2.9761, Physics Loss: 0.0856, Test R2 - Bx: 0.9366, By: 0.9275, Bz: 0.9718\n",
      "Estimated Remaining Time: 1h 3m 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 50/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=4.48, loss_By=4.31, loss_Bz=3.21, physics_loss=0.0855]\n",
      "Test Epoch 50/150: 100%|██████████| 3/3 [00:07<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 50/150, Duration: 24.70s, Train Loss - Bx: 4.0630, By: 3.9888, Bz: 2.9728, Physics Loss: 0.0829, Test R2 - Bx: 0.9374, By: 0.9277, Bz: 0.9730\n",
      "Estimated Remaining Time: 1h 2m 53s\n",
      "Checkpoint saved at epoch 50: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_50.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx - Mean: 1.5798409455647366e-11, Std: 1.0000041723251343\n",
      "by - Mean: -8.015749869416666e-11, Std: 1.000001311302185\n",
      "bz - Mean: -1.6415130366098651e-10, Std: 1.0000015497207642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 51/150: 100%|██████████| 15/15 [00:15<00:00,  1.02s/it, loss_Bx=4.31, loss_By=4.14, loss_Bz=3.22, physics_loss=0.0885]\n",
      "Test Epoch 51/150: 100%|██████████| 3/3 [00:06<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 51/150, Duration: 23.83s, Train Loss - Bx: 4.0431, By: 3.9696, Bz: 2.9668, Physics Loss: 0.0819, Test R2 - Bx: 0.9383, By: 0.9301, Bz: 0.9715\n",
      "Estimated Remaining Time: 1h 1m 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 52/150: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s, loss_Bx=3.99, loss_By=3.87, loss_Bz=2.95, physics_loss=0.0733]\n",
      "Test Epoch 52/150: 100%|██████████| 3/3 [00:05<00:00,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 52/150, Duration: 21.55s, Train Loss - Bx: 4.0244, By: 3.9562, Bz: 2.9661, Physics Loss: 0.0822, Test R2 - Bx: 0.9369, By: 0.9295, Bz: 0.9722\n",
      "Estimated Remaining Time: 1h 0m 41s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 53/150: 100%|██████████| 15/15 [00:13<00:00,  1.08it/s, loss_Bx=4.12, loss_By=4.02, loss_Bz=3.01, physics_loss=0.0733]\n",
      "Test Epoch 53/150: 100%|██████████| 3/3 [00:05<00:00,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/150, Duration: 21.94s, Train Loss - Bx: 4.0373, By: 3.9715, Bz: 2.9961, Physics Loss: 0.0837, Test R2 - Bx: 0.9359, By: 0.9297, Bz: 0.9709\n",
      "Estimated Remaining Time: 0h 59m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 54/150: 100%|██████████| 15/15 [00:19<00:00,  1.32s/it, loss_Bx=4.31, loss_By=4.34, loss_Bz=3.22, physics_loss=0.0959]\n",
      "Test Epoch 54/150: 100%|██████████| 3/3 [00:06<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 54/150, Duration: 28.08s, Train Loss - Bx: 4.0184, By: 3.9558, Bz: 2.9814, Physics Loss: 0.0827, Test R2 - Bx: 0.9356, By: 0.9265, Bz: 0.9713\n",
      "Estimated Remaining Time: 0h 58m 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 55/150: 100%|██████████| 15/15 [00:21<00:00,  1.43s/it, loss_Bx=4.4, loss_By=4.4, loss_Bz=3.18, physics_loss=0.0858]\n",
      "Test Epoch 55/150: 100%|██████████| 3/3 [00:06<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 55/150, Duration: 29.86s, Train Loss - Bx: 4.0359, By: 3.9809, Bz: 3.0107, Physics Loss: 0.0869, Test R2 - Bx: 0.9366, By: 0.9282, Bz: 0.9709\n",
      "Estimated Remaining Time: 0h 57m 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 56/150: 100%|██████████| 15/15 [00:21<00:00,  1.42s/it, loss_Bx=4.41, loss_By=4.21, loss_Bz=3.2, physics_loss=0.0812]\n",
      "Test Epoch 56/150: 100%|██████████| 3/3 [00:06<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 56/150, Duration: 29.65s, Train Loss - Bx: 4.0230, By: 3.9529, Bz: 2.9827, Physics Loss: 0.0838, Test R2 - Bx: 0.9369, By: 0.9289, Bz: 0.9720\n",
      "Estimated Remaining Time: 0h 57m 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 57/150: 100%|██████████| 15/15 [00:21<00:00,  1.44s/it, loss_Bx=4.64, loss_By=4.76, loss_Bz=3.34, physics_loss=0.0993]\n",
      "Test Epoch 57/150: 100%|██████████| 3/3 [00:05<00:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 57/150, Duration: 29.77s, Train Loss - Bx: 3.9876, By: 3.9329, Bz: 2.9638, Physics Loss: 0.0814, Test R2 - Bx: 0.9390, By: 0.9300, Bz: 0.9732\n",
      "Estimated Remaining Time: 0h 56m 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 58/150: 100%|██████████| 15/15 [00:20<00:00,  1.37s/it, loss_Bx=4.1, loss_By=4.18, loss_Bz=3, physics_loss=0.0793]\n",
      "Test Epoch 58/150: 100%|██████████| 3/3 [00:06<00:00,  2.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 58/150, Duration: 28.77s, Train Loss - Bx: 3.9582, By: 3.9090, Bz: 2.9542, Physics Loss: 0.0830, Test R2 - Bx: 0.9376, By: 0.9298, Bz: 0.9715\n",
      "Estimated Remaining Time: 0h 55m 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 59/150: 100%|██████████| 15/15 [00:21<00:00,  1.42s/it, loss_Bx=3.88, loss_By=3.87, loss_Bz=3, physics_loss=0.0721]\n",
      "Test Epoch 59/150: 100%|██████████| 3/3 [00:06<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 59/150, Duration: 29.84s, Train Loss - Bx: 3.9380, By: 3.8936, Bz: 2.9541, Physics Loss: 0.0820, Test R2 - Bx: 0.9380, By: 0.9293, Bz: 0.9728\n",
      "Estimated Remaining Time: 0h 54m 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 60/150: 100%|██████████| 15/15 [00:21<00:00,  1.41s/it, loss_Bx=4.08, loss_By=4.34, loss_Bz=3.1, physics_loss=0.0793]\n",
      "Test Epoch 60/150: 100%|██████████| 3/3 [00:17<00:00,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 60/150, Duration: 40.81s, Train Loss - Bx: 3.9162, By: 3.8787, Bz: 2.9526, Physics Loss: 0.0829, Test R2 - Bx: 0.9382, By: 0.9291, Bz: 0.9727\n",
      "Estimated Remaining Time: 0h 54m 16s\n",
      "Checkpoint saved at epoch 60: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_60.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx - Mean: 2.271021391775374e-11, Std: 0.9999996423721313\n",
      "by - Mean: -6.319363782258947e-11, Std: 0.999997079372406\n",
      "bz - Mean: 4.904629133384297e-11, Std: 1.000001072883606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 61/150: 100%|██████████| 15/15 [00:20<00:00,  1.38s/it, loss_Bx=4.13, loss_By=3.78, loss_Bz=3.15, physics_loss=0.0831]\n",
      "Test Epoch 61/150: 100%|██████████| 3/3 [00:06<00:00,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 61/150, Duration: 29.83s, Train Loss - Bx: 3.9102, By: 3.8749, Bz: 2.9697, Physics Loss: 0.0807, Test R2 - Bx: 0.9367, By: 0.9285, Bz: 0.9720\n",
      "Estimated Remaining Time: 0h 53m 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 62/150: 100%|██████████| 15/15 [00:21<00:00,  1.43s/it, loss_Bx=4.03, loss_By=4.32, loss_Bz=3.09, physics_loss=0.083]\n",
      "Test Epoch 62/150: 100%|██████████| 3/3 [00:06<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 62/150, Duration: 30.47s, Train Loss - Bx: 3.9379, By: 3.8973, Bz: 3.0050, Physics Loss: 0.0826, Test R2 - Bx: 0.9340, By: 0.9255, Bz: 0.9698\n",
      "Estimated Remaining Time: 0h 52m 46s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 63/150: 100%|██████████| 15/15 [00:19<00:00,  1.32s/it, loss_Bx=4.37, loss_By=4.43, loss_Bz=3.24, physics_loss=0.102]\n",
      "Test Epoch 63/150: 100%|██████████| 3/3 [00:06<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 63/150, Duration: 28.43s, Train Loss - Bx: 3.9293, By: 3.8716, Bz: 2.9685, Physics Loss: 0.0823, Test R2 - Bx: 0.9381, By: 0.9284, Bz: 0.9709\n",
      "Estimated Remaining Time: 0h 52m 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 64/150: 100%|██████████| 15/15 [00:21<00:00,  1.41s/it, loss_Bx=4.47, loss_By=4.03, loss_Bz=3.48, physics_loss=0.0944]\n",
      "Test Epoch 64/150: 100%|██████████| 3/3 [00:06<00:00,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 64/150, Duration: 29.48s, Train Loss - Bx: 3.8845, By: 3.8522, Bz: 2.9547, Physics Loss: 0.0813, Test R2 - Bx: 0.9391, By: 0.9303, Bz: 0.9726\n",
      "Estimated Remaining Time: 0h 51m 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 65/150: 100%|██████████| 15/15 [00:21<00:00,  1.44s/it, loss_Bx=4.07, loss_By=4.14, loss_Bz=3.25, physics_loss=0.0901]\n",
      "Test Epoch 65/150: 100%|██████████| 3/3 [00:06<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 65/150, Duration: 30.11s, Train Loss - Bx: 3.8574, By: 3.8319, Bz: 2.9498, Physics Loss: 0.0810, Test R2 - Bx: 0.9386, By: 0.9293, Bz: 0.9722\n",
      "Estimated Remaining Time: 0h 50m 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 66/150: 100%|██████████| 15/15 [00:21<00:00,  1.41s/it, loss_Bx=4.24, loss_By=4.01, loss_Bz=3.22, physics_loss=0.0949]\n",
      "Test Epoch 66/150: 100%|██████████| 3/3 [00:05<00:00,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 66/150, Duration: 29.25s, Train Loss - Bx: 3.8390, By: 3.8179, Bz: 2.9465, Physics Loss: 0.0817, Test R2 - Bx: 0.9381, By: 0.9298, Bz: 0.9709\n",
      "Estimated Remaining Time: 0h 49m 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 67/150: 100%|██████████| 15/15 [00:21<00:00,  1.44s/it, loss_Bx=3.9, loss_By=4.12, loss_Bz=3.13, physics_loss=0.0908]\n",
      "Test Epoch 67/150: 100%|██████████| 3/3 [00:06<00:00,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 67/150, Duration: 30.15s, Train Loss - Bx: 3.8277, By: 3.8028, Bz: 2.9463, Physics Loss: 0.0813, Test R2 - Bx: 0.9379, By: 0.9294, Bz: 0.9704\n",
      "Estimated Remaining Time: 0h 49m 6s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 68/150: 100%|██████████| 15/15 [00:21<00:00,  1.45s/it, loss_Bx=4.45, loss_By=4.19, loss_Bz=3.48, physics_loss=0.099]\n",
      "Test Epoch 68/150: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 68/150, Duration: 29.78s, Train Loss - Bx: 3.8130, By: 3.7961, Bz: 2.9504, Physics Loss: 0.0814, Test R2 - Bx: 0.9386, By: 0.9299, Bz: 0.9721\n",
      "Estimated Remaining Time: 0h 48m 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 69/150: 100%|██████████| 15/15 [00:21<00:00,  1.43s/it, loss_Bx=3.82, loss_By=3.78, loss_Bz=2.84, physics_loss=0.0692]\n",
      "Test Epoch 69/150: 100%|██████████| 3/3 [00:06<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 69/150, Duration: 29.90s, Train Loss - Bx: 3.8021, By: 3.7817, Bz: 2.9509, Physics Loss: 0.0814, Test R2 - Bx: 0.9384, By: 0.9293, Bz: 0.9709\n",
      "Estimated Remaining Time: 0h 47m 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 70/150: 100%|██████████| 15/15 [00:20<00:00,  1.36s/it, loss_Bx=3.7, loss_By=3.8, loss_Bz=2.99, physics_loss=0.0727]\n",
      "Test Epoch 70/150: 100%|██████████| 3/3 [00:06<00:00,  2.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 70/150, Duration: 29.04s, Train Loss - Bx: 3.8296, By: 3.8140, Bz: 3.0003, Physics Loss: 0.0839, Test R2 - Bx: 0.9368, By: 0.9281, Bz: 0.9684\n",
      "Estimated Remaining Time: 0h 46m 59s\n",
      "Checkpoint saved at epoch 70: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_70.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx - Mean: -3.5740663900662994e-11, Std: 0.9999989867210388\n",
      "by - Mean: 1.8181120498006464e-10, Std: 0.9999993443489075\n",
      "bz - Mean: -3.3911543712017433e-11, Std: 1.0000011920928955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 71/150: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s, loss_Bx=3.73, loss_By=3.7, loss_Bz=2.96, physics_loss=0.0723]\n",
      "Test Epoch 71/150: 100%|██████████| 3/3 [00:06<00:00,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 71/150, Duration: 23.07s, Train Loss - Bx: 3.7988, By: 3.7905, Bz: 2.9646, Physics Loss: 0.0834, Test R2 - Bx: 0.9360, By: 0.9265, Bz: 0.9720\n",
      "Estimated Remaining Time: 0h 46m 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 72/150: 100%|██████████| 15/15 [00:15<00:00,  1.01s/it, loss_Bx=3.93, loss_By=3.92, loss_Bz=3.12, physics_loss=0.088]\n",
      "Test Epoch 72/150: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 72/150, Duration: 23.10s, Train Loss - Bx: 3.7815, By: 3.7644, Bz: 2.9535, Physics Loss: 0.0819, Test R2 - Bx: 0.9375, By: 0.9286, Bz: 0.9697\n",
      "Estimated Remaining Time: 0h 45m 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 73/150: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s, loss_Bx=3.95, loss_By=3.59, loss_Bz=2.97, physics_loss=0.0773]\n",
      "Test Epoch 73/150: 100%|██████████| 3/3 [00:06<00:00,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 73/150, Duration: 22.43s, Train Loss - Bx: 3.7630, By: 3.7490, Bz: 2.9428, Physics Loss: 0.0818, Test R2 - Bx: 0.9373, By: 0.9276, Bz: 0.9727\n",
      "Estimated Remaining Time: 0h 44m 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 74/150: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s, loss_Bx=3.67, loss_By=3.71, loss_Bz=2.81, physics_loss=0.0695]\n",
      "Test Epoch 74/150: 100%|██████████| 3/3 [00:20<00:00,  6.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 74/150, Duration: 36.89s, Train Loss - Bx: 3.7476, By: 3.7331, Bz: 2.9385, Physics Loss: 0.0814, Test R2 - Bx: 0.9383, By: 0.9297, Bz: 0.9722\n",
      "Estimated Remaining Time: 0h 44m 2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 75/150: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s, loss_Bx=4.11, loss_By=3.96, loss_Bz=3.15, physics_loss=0.0802]\n",
      "Test Epoch 75/150: 100%|██████████| 3/3 [00:05<00:00,  1.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 75/150, Duration: 22.47s, Train Loss - Bx: 3.7377, By: 3.7226, Bz: 2.9432, Physics Loss: 0.0808, Test R2 - Bx: 0.9390, By: 0.9294, Bz: 0.9730\n",
      "Estimated Remaining Time: 0h 43m 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 76/150: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, loss_Bx=3.62, loss_By=3.8, loss_Bz=2.8, physics_loss=0.0682]\n",
      "Test Epoch 76/150: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 76/150, Duration: 22.66s, Train Loss - Bx: 3.7375, By: 3.7236, Bz: 2.9546, Physics Loss: 0.0805, Test R2 - Bx: 0.9386, By: 0.9302, Bz: 0.9724\n",
      "Estimated Remaining Time: 0h 42m 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 77/150: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, loss_Bx=4.1, loss_By=4.21, loss_Bz=3.24, physics_loss=0.0837]\n",
      "Test Epoch 77/150: 100%|██████████| 3/3 [00:06<00:00,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 77/150, Duration: 23.28s, Train Loss - Bx: 3.7564, By: 3.7634, Bz: 2.9854, Physics Loss: 0.0846, Test R2 - Bx: 0.9361, By: 0.9285, Bz: 0.9707\n",
      "Estimated Remaining Time: 0h 41m 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 78/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=4.01, loss_By=4.01, loss_Bz=3.18, physics_loss=0.0866]\n",
      "Test Epoch 78/150: 100%|██████████| 3/3 [00:06<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 78/150, Duration: 23.15s, Train Loss - Bx: 3.7381, By: 3.7332, Bz: 2.9619, Physics Loss: 0.0819, Test R2 - Bx: 0.9382, By: 0.9298, Bz: 0.9719\n",
      "Estimated Remaining Time: 0h 40m 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 79/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=3.78, loss_By=3.9, loss_Bz=3.01, physics_loss=0.0795]\n",
      "Test Epoch 79/150: 100%|██████████| 3/3 [00:06<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 79/150, Duration: 23.54s, Train Loss - Bx: 3.7219, By: 3.7123, Bz: 2.9529, Physics Loss: 0.0814, Test R2 - Bx: 0.9380, By: 0.9296, Bz: 0.9720\n",
      "Estimated Remaining Time: 0h 40m 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 80/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=3.96, loss_By=3.97, loss_Bz=3.2, physics_loss=0.077]\n",
      "Test Epoch 80/150: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 80/150, Duration: 22.88s, Train Loss - Bx: 3.7259, By: 3.7171, Bz: 2.9638, Physics Loss: 0.0820, Test R2 - Bx: 0.9386, By: 0.9294, Bz: 0.9725\n",
      "Estimated Remaining Time: 0h 39m 31s\n",
      "Checkpoint saved at epoch 80: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_80.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx - Mean: 3.962551814451487e-11, Std: 0.999999463558197\n",
      "by - Mean: -5.671887959302069e-11, Std: 1.0000003576278687\n",
      "bz - Mean: -5.076210285448468e-11, Std: 0.9999982714653015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 81/150: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, loss_Bx=4.13, loss_By=4.03, loss_Bz=3.24, physics_loss=0.0838]\n",
      "Test Epoch 81/150: 100%|██████████| 3/3 [00:06<00:00,  2.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 81/150, Duration: 24.27s, Train Loss - Bx: 3.7223, By: 3.7176, Bz: 2.9648, Physics Loss: 0.0806, Test R2 - Bx: 0.9393, By: 0.9302, Bz: 0.9730\n",
      "Estimated Remaining Time: 0h 38m 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 82/150: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s, loss_Bx=3.8, loss_By=3.63, loss_Bz=3.07, physics_loss=0.0777]\n",
      "Test Epoch 82/150: 100%|██████████| 3/3 [00:06<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 82/150, Duration: 24.01s, Train Loss - Bx: 3.6998, By: 3.6864, Bz: 2.9377, Physics Loss: 0.0808, Test R2 - Bx: 0.9390, By: 0.9303, Bz: 0.9728\n",
      "Estimated Remaining Time: 0h 38m 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 83/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=3.83, loss_By=3.74, loss_Bz=3.03, physics_loss=0.0794]\n",
      "Test Epoch 83/150: 100%|██████████| 3/3 [00:07<00:00,  2.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83/150, Duration: 24.40s, Train Loss - Bx: 3.6869, By: 3.6728, Bz: 2.9297, Physics Loss: 0.0808, Test R2 - Bx: 0.9394, By: 0.9303, Bz: 0.9730\n",
      "Estimated Remaining Time: 0h 37m 26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 84/150: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s, loss_Bx=4.3, loss_By=4.18, loss_Bz=3.35, physics_loss=0.102]\n",
      "Test Epoch 84/150: 100%|██████████| 3/3 [00:06<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84/150, Duration: 23.48s, Train Loss - Bx: 3.6805, By: 3.6635, Bz: 2.9301, Physics Loss: 0.0815, Test R2 - Bx: 0.9395, By: 0.9306, Bz: 0.9728\n",
      "Estimated Remaining Time: 0h 36m 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 85/150: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s, loss_Bx=3.73, loss_By=3.88, loss_Bz=2.88, physics_loss=0.0757]\n",
      "Test Epoch 85/150: 100%|██████████| 3/3 [00:06<00:00,  2.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 85/150, Duration: 23.32s, Train Loss - Bx: 3.6784, By: 3.6659, Bz: 2.9356, Physics Loss: 0.0801, Test R2 - Bx: 0.9391, By: 0.9307, Bz: 0.9720\n",
      "Estimated Remaining Time: 0h 36m 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 86/150: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s, loss_Bx=3.74, loss_By=3.79, loss_Bz=2.95, physics_loss=0.0766]\n",
      "Test Epoch 86/150: 100%|██████████| 3/3 [00:06<00:00,  2.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/150, Duration: 23.24s, Train Loss - Bx: 3.6697, By: 3.6541, Bz: 2.9331, Physics Loss: 0.0817, Test R2 - Bx: 0.9382, By: 0.9297, Bz: 0.9727\n",
      "Estimated Remaining Time: 0h 35m 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 87/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=3.94, loss_By=3.96, loss_Bz=3.19, physics_loss=0.0807]\n",
      "Test Epoch 87/150: 100%|██████████| 3/3 [00:06<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/150, Duration: 23.23s, Train Loss - Bx: 3.6707, By: 3.6527, Bz: 2.9385, Physics Loss: 0.0810, Test R2 - Bx: 0.9385, By: 0.9297, Bz: 0.9725\n",
      "Estimated Remaining Time: 0h 34m 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 88/150: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, loss_Bx=4.14, loss_By=4.05, loss_Bz=3.35, physics_loss=0.103]\n",
      "Test Epoch 88/150: 100%|██████████| 3/3 [00:06<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 88/150, Duration: 23.83s, Train Loss - Bx: 3.6604, By: 3.6431, Bz: 2.9316, Physics Loss: 0.0817, Test R2 - Bx: 0.9395, By: 0.9307, Bz: 0.9731\n",
      "Estimated Remaining Time: 0h 34m 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 89/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=3.86, loss_By=3.81, loss_Bz=3.08, physics_loss=0.0843]\n",
      "Test Epoch 89/150: 100%|██████████| 3/3 [00:07<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 89/150, Duration: 24.09s, Train Loss - Bx: 3.6580, By: 3.6428, Bz: 2.9383, Physics Loss: 0.0801, Test R2 - Bx: 0.9391, By: 0.9301, Bz: 0.9719\n",
      "Estimated Remaining Time: 0h 33m 24s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 90/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=3.79, loss_By=3.73, loss_Bz=3.08, physics_loss=0.0737]\n",
      "Test Epoch 90/150: 100%|██████████| 3/3 [00:06<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90/150, Duration: 23.90s, Train Loss - Bx: 3.6552, By: 3.6360, Bz: 2.9375, Physics Loss: 0.0816, Test R2 - Bx: 0.9390, By: 0.9308, Bz: 0.9729\n",
      "Estimated Remaining Time: 0h 32m 45s\n",
      "Checkpoint saved at epoch 90: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_90.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx - Mean: 3.611296331418323e-11, Std: 1.000001311302185\n",
      "by - Mean: -7.251729078339153e-11, Std: 0.9999979138374329\n",
      "bz - Mean: 1.0888721868607121e-10, Std: 1.000001072883606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 91/150: 100%|██████████| 15/15 [00:14<00:00,  1.01it/s, loss_Bx=4.11, loss_By=3.89, loss_Bz=3.32, physics_loss=0.0947]\n",
      "Test Epoch 91/150: 100%|██████████| 3/3 [00:06<00:00,  2.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 91/150, Duration: 23.86s, Train Loss - Bx: 3.6468, By: 3.6309, Bz: 2.9321, Physics Loss: 0.0805, Test R2 - Bx: 0.9391, By: 0.9307, Bz: 0.9728\n",
      "Estimated Remaining Time: 0h 32m 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 92/150: 100%|██████████| 15/15 [00:13<00:00,  1.08it/s, loss_Bx=3.73, loss_By=3.8, loss_Bz=2.97, physics_loss=0.0785]\n",
      "Test Epoch 92/150: 100%|██████████| 3/3 [00:06<00:00,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 92/150, Duration: 22.62s, Train Loss - Bx: 3.6425, By: 3.6228, Bz: 2.9339, Physics Loss: 0.0810, Test R2 - Bx: 0.9385, By: 0.9300, Bz: 0.9734\n",
      "Estimated Remaining Time: 0h 31m 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 93/150: 100%|██████████| 15/15 [00:13<00:00,  1.08it/s, loss_Bx=3.73, loss_By=3.68, loss_Bz=3.06, physics_loss=0.0774]\n",
      "Test Epoch 93/150: 100%|██████████| 3/3 [00:06<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 93/150, Duration: 23.10s, Train Loss - Bx: 3.6374, By: 3.6180, Bz: 2.9321, Physics Loss: 0.0808, Test R2 - Bx: 0.9376, By: 0.9300, Bz: 0.9718\n",
      "Estimated Remaining Time: 0h 30m 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 94/150: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s, loss_Bx=4.09, loss_By=4.15, loss_Bz=3.31, physics_loss=0.0948]\n",
      "Test Epoch 94/150: 100%|██████████| 3/3 [00:06<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 94/150, Duration: 22.70s, Train Loss - Bx: 3.6333, By: 3.6121, Bz: 2.9351, Physics Loss: 0.0838, Test R2 - Bx: 0.9387, By: 0.9299, Bz: 0.9723\n",
      "Estimated Remaining Time: 0h 30m 11s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 95/150: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s, loss_Bx=3.91, loss_By=3.97, loss_Bz=3.29, physics_loss=0.0801]\n",
      "Test Epoch 95/150: 100%|██████████| 3/3 [00:06<00:00,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 95/150, Duration: 22.75s, Train Loss - Bx: 3.6326, By: 3.6131, Bz: 2.9360, Physics Loss: 0.0807, Test R2 - Bx: 0.9393, By: 0.9307, Bz: 0.9729\n",
      "Estimated Remaining Time: 0h 29m 33s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 96/150: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s, loss_Bx=3.91, loss_By=3.97, loss_Bz=3.12, physics_loss=0.0835]\n",
      "Test Epoch 96/150: 100%|██████████| 3/3 [00:06<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 96/150, Duration: 22.22s, Train Loss - Bx: 3.6251, By: 3.6046, Bz: 2.9323, Physics Loss: 0.0809, Test R2 - Bx: 0.9378, By: 0.9298, Bz: 0.9726\n",
      "Estimated Remaining Time: 0h 28m 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 97/150: 100%|██████████| 15/15 [00:13<00:00,  1.08it/s, loss_Bx=3.65, loss_By=3.49, loss_Bz=3.01, physics_loss=0.0799]\n",
      "Test Epoch 97/150: 100%|██████████| 3/3 [00:07<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 97/150, Duration: 23.49s, Train Loss - Bx: 3.6223, By: 3.6007, Bz: 2.9339, Physics Loss: 0.0812, Test R2 - Bx: 0.9388, By: 0.9303, Bz: 0.9728\n",
      "Estimated Remaining Time: 0h 28m 18s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 98/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=3.68, loss_By=3.55, loss_Bz=2.99, physics_loss=0.0712]\n",
      "Test Epoch 98/150: 100%|██████████| 3/3 [00:06<00:00,  2.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 98/150, Duration: 23.23s, Train Loss - Bx: 3.6194, By: 3.5991, Bz: 2.9363, Physics Loss: 0.0803, Test R2 - Bx: 0.9393, By: 0.9303, Bz: 0.9731\n",
      "Estimated Remaining Time: 0h 27m 42s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 99/150: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s, loss_Bx=3.96, loss_By=4.25, loss_Bz=3.08, physics_loss=0.0799]\n",
      "Test Epoch 99/150: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 99/150, Duration: 21.64s, Train Loss - Bx: 3.6153, By: 3.5998, Bz: 2.9388, Physics Loss: 0.0810, Test R2 - Bx: 0.9394, By: 0.9303, Bz: 0.9728\n",
      "Estimated Remaining Time: 0h 27m 4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 100/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=3.84, loss_By=3.86, loss_Bz=3.14, physics_loss=0.087]\n",
      "Test Epoch 100/150: 100%|██████████| 3/3 [00:06<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100/150, Duration: 23.40s, Train Loss - Bx: 3.6259, By: 3.6054, Bz: 2.9515, Physics Loss: 0.0806, Test R2 - Bx: 0.9363, By: 0.9285, Bz: 0.9715\n",
      "Estimated Remaining Time: 0h 26m 28s\n",
      "Checkpoint saved at epoch 100: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_100.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx - Mean: -5.050311297633003e-12, Std: 1.0000017881393433\n",
      "by - Mean: 5.438796635282017e-11, Std: 1.0000008344650269\n",
      "bz - Mean: 5.464695709833656e-11, Std: 1.0000001192092896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 101/150: 100%|██████████| 15/15 [00:21<00:00,  1.41s/it, loss_Bx=3.4, loss_By=3.43, loss_Bz=2.76, physics_loss=0.0652]\n",
      "Test Epoch 101/150: 100%|██████████| 3/3 [00:06<00:00,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 101/150, Duration: 30.26s, Train Loss - Bx: 3.6235, By: 3.6048, Bz: 2.9491, Physics Loss: 0.0819, Test R2 - Bx: 0.9394, By: 0.9301, Bz: 0.9728\n",
      "Estimated Remaining Time: 0h 25m 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 102/150: 100%|██████████| 15/15 [00:18<00:00,  1.27s/it, loss_Bx=4.04, loss_By=3.87, loss_Bz=3.3, physics_loss=0.0947]\n",
      "Test Epoch 102/150: 100%|██████████| 3/3 [00:06<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 102/150, Duration: 27.63s, Train Loss - Bx: 3.6101, By: 3.5914, Bz: 2.9360, Physics Loss: 0.0808, Test R2 - Bx: 0.9388, By: 0.9302, Bz: 0.9731\n",
      "Estimated Remaining Time: 0h 25m 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 103/150: 100%|██████████| 15/15 [00:20<00:00,  1.38s/it, loss_Bx=3.78, loss_By=3.69, loss_Bz=3.1, physics_loss=0.0853]\n",
      "Test Epoch 103/150: 100%|██████████| 3/3 [00:06<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 103/150, Duration: 29.38s, Train Loss - Bx: 3.5988, By: 3.5764, Bz: 2.9250, Physics Loss: 0.0806, Test R2 - Bx: 0.9398, By: 0.9310, Bz: 0.9729\n",
      "Estimated Remaining Time: 0h 24m 49s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 104/150: 100%|██████████| 15/15 [00:21<00:00,  1.40s/it, loss_Bx=3.78, loss_By=3.63, loss_Bz=3.09, physics_loss=0.0832]\n",
      "Test Epoch 104/150: 100%|██████████| 3/3 [00:06<00:00,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 104/150, Duration: 29.58s, Train Loss - Bx: 3.5944, By: 3.5709, Bz: 2.9242, Physics Loss: 0.0808, Test R2 - Bx: 0.9388, By: 0.9308, Bz: 0.9728\n",
      "Estimated Remaining Time: 0h 24m 17s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 105/150: 100%|██████████| 15/15 [00:21<00:00,  1.46s/it, loss_Bx=3.95, loss_By=3.96, loss_Bz=3.23, physics_loss=0.0861]\n",
      "Test Epoch 105/150: 100%|██████████| 3/3 [00:06<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105/150, Duration: 30.84s, Train Loss - Bx: 3.5934, By: 3.5702, Bz: 2.9277, Physics Loss: 0.0810, Test R2 - Bx: 0.9393, By: 0.9306, Bz: 0.9726\n",
      "Estimated Remaining Time: 0h 23m 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 106/150: 100%|██████████| 15/15 [00:22<00:00,  1.48s/it, loss_Bx=3.8, loss_By=3.81, loss_Bz=3.14, physics_loss=0.0821]\n",
      "Test Epoch 106/150: 100%|██████████| 3/3 [00:06<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 106/150, Duration: 31.40s, Train Loss - Bx: 3.5886, By: 3.5651, Bz: 2.9264, Physics Loss: 0.0814, Test R2 - Bx: 0.9393, By: 0.9310, Bz: 0.9725\n",
      "Estimated Remaining Time: 0h 23m 13s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 107/150: 100%|██████████| 15/15 [00:21<00:00,  1.42s/it, loss_Bx=3.72, loss_By=3.73, loss_Bz=3.04, physics_loss=0.083]\n",
      "Test Epoch 107/150: 100%|██████████| 3/3 [00:06<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 107/150, Duration: 30.02s, Train Loss - Bx: 3.5896, By: 3.5664, Bz: 2.9272, Physics Loss: 0.0811, Test R2 - Bx: 0.9394, By: 0.9304, Bz: 0.9729\n",
      "Estimated Remaining Time: 0h 22m 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 108/150: 100%|██████████| 15/15 [00:20<00:00,  1.35s/it, loss_Bx=3.64, loss_By=3.4, loss_Bz=2.91, physics_loss=0.0692]\n",
      "Test Epoch 108/150: 100%|██████████| 3/3 [00:11<00:00,  3.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 108/150, Duration: 34.16s, Train Loss - Bx: 3.5808, By: 3.5564, Bz: 2.9237, Physics Loss: 0.0822, Test R2 - Bx: 0.9392, By: 0.9313, Bz: 0.9726\n",
      "Estimated Remaining Time: 0h 22m 10s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 109/150: 100%|██████████| 15/15 [00:22<00:00,  1.48s/it, loss_Bx=3.44, loss_By=3.43, loss_Bz=2.86, physics_loss=0.0646]\n",
      "Test Epoch 109/150: 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 109/150, Duration: 30.01s, Train Loss - Bx: 3.5797, By: 3.5549, Bz: 2.9251, Physics Loss: 0.0800, Test R2 - Bx: 0.9395, By: 0.9304, Bz: 0.9731\n",
      "Estimated Remaining Time: 0h 21m 37s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 110/150: 100%|██████████| 15/15 [00:22<00:00,  1.51s/it, loss_Bx=4.1, loss_By=3.93, loss_Bz=3.35, physics_loss=0.0928]\n",
      "Test Epoch 110/150: 100%|██████████| 3/3 [00:06<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110/150, Duration: 31.08s, Train Loss - Bx: 3.5974, By: 3.5756, Bz: 2.9495, Physics Loss: 0.0822, Test R2 - Bx: 0.9390, By: 0.9307, Bz: 0.9719\n",
      "Estimated Remaining Time: 0h 21m 6s\n",
      "Checkpoint saved at epoch 110: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_110.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx - Mean: 3.786114477488667e-11, Std: 1.0000005960464478\n",
      "by - Mean: -1.2807070681741806e-10, Std: 1.0000007152557373\n",
      "bz - Mean: 8.682650431968142e-11, Std: 1.0000019073486328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 111/150: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s, loss_Bx=3.89, loss_By=4.06, loss_Bz=3.23, physics_loss=0.0919]\n",
      "Test Epoch 111/150: 100%|██████████| 3/3 [00:06<00:00,  2.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 111/150, Duration: 22.73s, Train Loss - Bx: 3.5873, By: 3.5687, Bz: 2.9400, Physics Loss: 0.0807, Test R2 - Bx: 0.9394, By: 0.9303, Bz: 0.9734\n",
      "Estimated Remaining Time: 0h 20m 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 112/150: 100%|██████████| 15/15 [00:13<00:00,  1.11it/s, loss_Bx=4.18, loss_By=4.2, loss_Bz=3.46, physics_loss=0.098]\n",
      "Test Epoch 112/150: 100%|██████████| 3/3 [00:06<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 112/150, Duration: 22.34s, Train Loss - Bx: 3.5745, By: 3.5501, Bz: 2.9247, Physics Loss: 0.0795, Test R2 - Bx: 0.9393, By: 0.9300, Bz: 0.9736\n",
      "Estimated Remaining Time: 0h 19m 56s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 113/150: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s, loss_Bx=3.69, loss_By=3.61, loss_Bz=2.97, physics_loss=0.0731]\n",
      "Test Epoch 113/150: 100%|██████████| 3/3 [00:06<00:00,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 113/150, Duration: 23.06s, Train Loss - Bx: 3.5692, By: 3.5444, Bz: 2.9201, Physics Loss: 0.0803, Test R2 - Bx: 0.9399, By: 0.9313, Bz: 0.9730\n",
      "Estimated Remaining Time: 0h 19m 22s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 114/150: 100%|██████████| 15/15 [00:13<00:00,  1.08it/s, loss_Bx=3.7, loss_By=3.73, loss_Bz=3.18, physics_loss=0.0771]\n",
      "Test Epoch 114/150: 100%|██████████| 3/3 [00:06<00:00,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 114/150, Duration: 22.67s, Train Loss - Bx: 3.5655, By: 3.5409, Bz: 2.9178, Physics Loss: 0.0806, Test R2 - Bx: 0.9398, By: 0.9311, Bz: 0.9730\n",
      "Estimated Remaining Time: 0h 18m 48s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 115/150: 100%|██████████| 15/15 [00:13<00:00,  1.08it/s, loss_Bx=3.95, loss_By=3.99, loss_Bz=3.27, physics_loss=0.0898]\n",
      "Test Epoch 115/150: 100%|██████████| 3/3 [00:07<00:00,  2.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 115/150, Duration: 23.52s, Train Loss - Bx: 3.5639, By: 3.5376, Bz: 2.9186, Physics Loss: 0.0809, Test R2 - Bx: 0.9395, By: 0.9307, Bz: 0.9726\n",
      "Estimated Remaining Time: 0h 18m 14s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 116/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=4.04, loss_By=4.07, loss_Bz=3.26, physics_loss=0.0932]\n",
      "Test Epoch 116/150: 100%|██████████| 3/3 [00:06<00:00,  2.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 116/150, Duration: 23.61s, Train Loss - Bx: 3.5622, By: 3.5365, Bz: 2.9186, Physics Loss: 0.0804, Test R2 - Bx: 0.9391, By: 0.9306, Bz: 0.9730\n",
      "Estimated Remaining Time: 0h 17m 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 117/150: 100%|██████████| 15/15 [00:13<00:00,  1.08it/s, loss_Bx=3.96, loss_By=3.97, loss_Bz=3.15, physics_loss=0.0939]\n",
      "Test Epoch 117/150: 100%|██████████| 3/3 [00:06<00:00,  2.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 117/150, Duration: 23.10s, Train Loss - Bx: 3.5589, By: 3.5314, Bz: 2.9183, Physics Loss: 0.0807, Test R2 - Bx: 0.9396, By: 0.9307, Bz: 0.9733\n",
      "Estimated Remaining Time: 0h 17m 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 118/150: 100%|██████████| 15/15 [00:13<00:00,  1.09it/s, loss_Bx=3.55, loss_By=3.52, loss_Bz=2.88, physics_loss=0.0629]\n",
      "Test Epoch 118/150: 100%|██████████| 3/3 [00:06<00:00,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 118/150, Duration: 22.65s, Train Loss - Bx: 3.5570, By: 3.5289, Bz: 2.9171, Physics Loss: 0.0795, Test R2 - Bx: 0.9392, By: 0.9312, Bz: 0.9724\n",
      "Estimated Remaining Time: 0h 16m 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 119/150: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, loss_Bx=3.92, loss_By=4.06, loss_Bz=3.25, physics_loss=0.0916]\n",
      "Test Epoch 119/150: 100%|██████████| 3/3 [00:05<00:00,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 119/150, Duration: 23.23s, Train Loss - Bx: 3.5560, By: 3.5297, Bz: 2.9197, Physics Loss: 0.0817, Test R2 - Bx: 0.9394, By: 0.9297, Bz: 0.9731\n",
      "Estimated Remaining Time: 0h 16m 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 120/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=3.45, loss_By=3.58, loss_Bz=2.86, physics_loss=0.0772]\n",
      "Test Epoch 120/150: 100%|██████████| 3/3 [00:06<00:00,  2.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 120/150, Duration: 23.48s, Train Loss - Bx: 3.5543, By: 3.5272, Bz: 2.9188, Physics Loss: 0.0811, Test R2 - Bx: 0.9395, By: 0.9312, Bz: 0.9724\n",
      "Estimated Remaining Time: 0h 15m 28s\n",
      "Checkpoint saved at epoch 120: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_120.pt\n",
      "bx - Mean: 2.6287517301826213e-11, Std: 1.0000009536743164\n",
      "by - Mean: 9.73803607196011e-11, Std: 1.0000032186508179\n",
      "bz - Mean: -4.538805095655185e-11, Std: 1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 121/150: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s, loss_Bx=3.83, loss_By=3.54, loss_Bz=3.06, physics_loss=0.0776]\n",
      "Test Epoch 121/150: 100%|██████████| 3/3 [00:07<00:00,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 121/150, Duration: 24.43s, Train Loss - Bx: 3.5563, By: 3.5305, Bz: 2.9238, Physics Loss: 0.0808, Test R2 - Bx: 0.9394, By: 0.9309, Bz: 0.9727\n",
      "Estimated Remaining Time: 0h 14m 55s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 122/150: 100%|██████████| 15/15 [00:13<00:00,  1.10it/s, loss_Bx=3.72, loss_By=3.84, loss_Bz=2.99, physics_loss=0.0807]\n",
      "Test Epoch 122/150: 100%|██████████| 3/3 [00:07<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 122/150, Duration: 24.13s, Train Loss - Bx: 3.5521, By: 3.5240, Bz: 2.9186, Physics Loss: 0.0798, Test R2 - Bx: 0.9397, By: 0.9303, Bz: 0.9733\n",
      "Estimated Remaining Time: 0h 14m 23s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 123/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=3.94, loss_By=3.97, loss_Bz=3.2, physics_loss=0.0925]\n",
      "Test Epoch 123/150: 100%|██████████| 3/3 [00:11<00:00,  3.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 123/150, Duration: 29.41s, Train Loss - Bx: 3.5472, By: 3.5185, Bz: 2.9172, Physics Loss: 0.0839, Test R2 - Bx: 0.9398, By: 0.9314, Bz: 0.9731\n",
      "Estimated Remaining Time: 0h 13m 51s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 124/150: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s, loss_Bx=3.89, loss_By=3.77, loss_Bz=3.13, physics_loss=0.0805]\n",
      "Test Epoch 124/150: 100%|██████████| 3/3 [00:06<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 124/150, Duration: 23.32s, Train Loss - Bx: 3.5459, By: 3.5180, Bz: 2.9182, Physics Loss: 0.0797, Test R2 - Bx: 0.9394, By: 0.9306, Bz: 0.9733\n",
      "Estimated Remaining Time: 0h 13m 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 125/150: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s, loss_Bx=3.47, loss_By=3.44, loss_Bz=2.83, physics_loss=0.0672]\n",
      "Test Epoch 125/150: 100%|██████████| 3/3 [00:06<00:00,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 125/150, Duration: 23.70s, Train Loss - Bx: 3.5639, By: 3.5370, Bz: 2.9429, Physics Loss: 0.0804, Test R2 - Bx: 0.9390, By: 0.9304, Bz: 0.9732\n",
      "Estimated Remaining Time: 0h 12m 47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 126/150: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s, loss_Bx=3.52, loss_By=3.5, loss_Bz=2.95, physics_loss=0.0732]\n",
      "Test Epoch 126/150: 100%|██████████| 3/3 [00:06<00:00,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 126/150, Duration: 23.93s, Train Loss - Bx: 3.5494, By: 3.5217, Bz: 2.9241, Physics Loss: 0.0803, Test R2 - Bx: 0.9397, By: 0.9311, Bz: 0.9733\n",
      "Estimated Remaining Time: 0h 12m 15s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 127/150: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, loss_Bx=3.39, loss_By=3.4, loss_Bz=2.73, physics_loss=0.0608]\n",
      "Test Epoch 127/150: 100%|██████████| 3/3 [00:07<00:00,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 127/150, Duration: 24.41s, Train Loss - Bx: 3.5417, By: 3.5150, Bz: 2.9155, Physics Loss: 0.0801, Test R2 - Bx: 0.9399, By: 0.9305, Bz: 0.9732\n",
      "Estimated Remaining Time: 0h 11m 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 128/150: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s, loss_Bx=3.57, loss_By=3.41, loss_Bz=2.98, physics_loss=0.0705]\n",
      "Test Epoch 128/150: 100%|██████████| 3/3 [00:07<00:00,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 128/150, Duration: 24.74s, Train Loss - Bx: 3.5402, By: 3.5090, Bz: 2.9129, Physics Loss: 0.0804, Test R2 - Bx: 0.9399, By: 0.9312, Bz: 0.9734\n",
      "Estimated Remaining Time: 0h 11m 12s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 129/150: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, loss_Bx=3.53, loss_By=3.6, loss_Bz=2.95, physics_loss=0.0769]\n",
      "Test Epoch 129/150: 100%|██████████| 3/3 [00:06<00:00,  2.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 129/150, Duration: 24.81s, Train Loss - Bx: 3.5375, By: 3.5088, Bz: 2.9147, Physics Loss: 0.0804, Test R2 - Bx: 0.9399, By: 0.9304, Bz: 0.9734\n",
      "Estimated Remaining Time: 0h 10m 40s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 130/150: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s, loss_Bx=3.74, loss_By=3.69, loss_Bz=3.12, physics_loss=0.0775]\n",
      "Test Epoch 130/150: 100%|██████████| 3/3 [00:07<00:00,  2.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 130/150, Duration: 25.22s, Train Loss - Bx: 3.5382, By: 3.5080, Bz: 2.9157, Physics Loss: 0.0807, Test R2 - Bx: 0.9400, By: 0.9307, Bz: 0.9733\n",
      "Estimated Remaining Time: 0h 10m 9s\n",
      "Checkpoint saved at epoch 130: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_130.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx - Mean: -3.023711836469545e-11, Std: 1.0000019073486328\n",
      "by - Mean: 9.602065670355486e-11, Std: 0.999999463558197\n",
      "bz - Mean: -8.672938062170843e-11, Std: 0.9999996423721313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 131/150: 100%|██████████| 15/15 [00:14<00:00,  1.00it/s, loss_Bx=3.6, loss_By=3.7, loss_Bz=3.06, physics_loss=0.0783]\n",
      "Test Epoch 131/150: 100%|██████████| 3/3 [00:08<00:00,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 131/150, Duration: 26.16s, Train Loss - Bx: 3.5351, By: 3.5051, Bz: 2.9139, Physics Loss: 0.0799, Test R2 - Bx: 0.9402, By: 0.9312, Bz: 0.9729\n",
      "Estimated Remaining Time: 0h 9m 38s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 132/150: 100%|██████████| 15/15 [00:14<00:00,  1.02it/s, loss_Bx=3.73, loss_By=3.65, loss_Bz=2.97, physics_loss=0.0789]\n",
      "Test Epoch 132/150: 100%|██████████| 3/3 [00:07<00:00,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 132/150, Duration: 26.49s, Train Loss - Bx: 3.5356, By: 3.5040, Bz: 2.9137, Physics Loss: 0.0798, Test R2 - Bx: 0.9398, By: 0.9310, Bz: 0.9732\n",
      "Estimated Remaining Time: 0h 9m 7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 133/150: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s, loss_Bx=3.7, loss_By=3.75, loss_Bz=3.04, physics_loss=0.084]\n",
      "Test Epoch 133/150: 100%|██████████| 3/3 [00:07<00:00,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 133/150, Duration: 25.43s, Train Loss - Bx: 3.5339, By: 3.5050, Bz: 2.9136, Physics Loss: 0.0799, Test R2 - Bx: 0.9401, By: 0.9311, Bz: 0.9733\n",
      "Estimated Remaining Time: 0h 8m 36s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 134/150: 100%|██████████| 15/15 [00:14<00:00,  1.07it/s, loss_Bx=3.86, loss_By=3.67, loss_Bz=3.11, physics_loss=0.0886]\n",
      "Test Epoch 134/150: 100%|██████████| 3/3 [00:07<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 134/150, Duration: 24.39s, Train Loss - Bx: 3.5327, By: 3.5021, Bz: 2.9149, Physics Loss: 0.0799, Test R2 - Bx: 0.9392, By: 0.9305, Bz: 0.9731\n",
      "Estimated Remaining Time: 0h 8m 5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 135/150: 100%|██████████| 15/15 [00:13<00:00,  1.08it/s, loss_Bx=3.56, loss_By=3.61, loss_Bz=2.99, physics_loss=0.081]\n",
      "Test Epoch 135/150: 100%|██████████| 3/3 [00:07<00:00,  2.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 135/150, Duration: 24.33s, Train Loss - Bx: 3.5299, By: 3.4999, Bz: 2.9115, Physics Loss: 0.0800, Test R2 - Bx: 0.9401, By: 0.9312, Bz: 0.9733\n",
      "Estimated Remaining Time: 0h 7m 34s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 136/150: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, loss_Bx=3.47, loss_By=3.56, loss_Bz=2.9, physics_loss=0.0676]\n",
      "Test Epoch 136/150: 100%|██████████| 3/3 [00:07<00:00,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 136/150, Duration: 25.26s, Train Loss - Bx: 3.5283, By: 3.4966, Bz: 2.9106, Physics Loss: 0.0810, Test R2 - Bx: 0.9400, By: 0.9311, Bz: 0.9735\n",
      "Estimated Remaining Time: 0h 7m 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 137/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=3.61, loss_By=3.57, loss_Bz=2.96, physics_loss=0.0783]\n",
      "Test Epoch 137/150: 100%|██████████| 3/3 [00:07<00:00,  2.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 137/150, Duration: 24.37s, Train Loss - Bx: 3.5275, By: 3.4973, Bz: 2.9129, Physics Loss: 0.0821, Test R2 - Bx: 0.9398, By: 0.9310, Bz: 0.9725\n",
      "Estimated Remaining Time: 0h 6m 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 138/150: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, loss_Bx=3.81, loss_By=3.58, loss_Bz=3.07, physics_loss=0.0808]\n",
      "Test Epoch 138/150: 100%|██████████| 3/3 [00:07<00:00,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 138/150, Duration: 25.49s, Train Loss - Bx: 3.5302, By: 3.5009, Bz: 2.9202, Physics Loss: 0.0816, Test R2 - Bx: 0.9396, By: 0.9307, Bz: 0.9733\n",
      "Estimated Remaining Time: 0h 6m 1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 139/150: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s, loss_Bx=3.95, loss_By=3.85, loss_Bz=3.21, physics_loss=0.0888]\n",
      "Test Epoch 139/150: 100%|██████████| 3/3 [00:07<00:00,  2.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 139/150, Duration: 25.79s, Train Loss - Bx: 3.5254, By: 3.4933, Bz: 2.9117, Physics Loss: 0.0810, Test R2 - Bx: 0.9398, By: 0.9310, Bz: 0.9736\n",
      "Estimated Remaining Time: 0h 5m 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 140/150: 100%|██████████| 15/15 [00:14<00:00,  1.06it/s, loss_Bx=3.72, loss_By=3.59, loss_Bz=3.06, physics_loss=0.0846]\n",
      "Test Epoch 140/150: 100%|██████████| 3/3 [00:06<00:00,  2.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 140/150, Duration: 24.06s, Train Loss - Bx: 3.5222, By: 3.4913, Bz: 2.9083, Physics Loss: 0.0806, Test R2 - Bx: 0.9401, By: 0.9307, Bz: 0.9736\n",
      "Estimated Remaining Time: 0h 5m 0s\n",
      "Checkpoint saved at epoch 140: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_140.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx - Mean: 1.7190481677031855e-11, Std: 1.0000032186508179\n",
      "by - Mean: -1.099413893257406e-10, Std: 0.9999971389770508\n",
      "bz - Mean: 8.188140443454728e-11, Std: 0.9999998807907104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Train Epoch 141/150: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s, loss_Bx=3.61, loss_By=3.62, loss_Bz=3.01, physics_loss=0.0791]\n",
      "Test Epoch 141/150: 100%|██████████| 3/3 [00:07<00:00,  2.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 141/150, Duration: 24.69s, Train Loss - Bx: 3.5225, By: 3.4906, Bz: 2.9104, Physics Loss: 0.0795, Test R2 - Bx: 0.9401, By: 0.9315, Bz: 0.9733\n",
      "Estimated Remaining Time: 0h 4m 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 142/150: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, loss_Bx=3.4, loss_By=3.48, loss_Bz=2.71, physics_loss=0.0655]\n",
      "Test Epoch 142/150: 100%|██████████| 3/3 [00:07<00:00,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 142/150, Duration: 25.30s, Train Loss - Bx: 3.5231, By: 3.4948, Bz: 2.9136, Physics Loss: 0.0796, Test R2 - Bx: 0.9398, By: 0.9313, Bz: 0.9729\n",
      "Estimated Remaining Time: 0h 4m 0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 143/150: 100%|██████████| 15/15 [00:15<00:00,  1.01s/it, loss_Bx=3.53, loss_By=3.55, loss_Bz=2.9, physics_loss=0.0692]\n",
      "Test Epoch 143/150: 100%|██████████| 3/3 [00:07<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 143/150, Duration: 25.85s, Train Loss - Bx: 3.5237, By: 3.4946, Bz: 2.9126, Physics Loss: 0.0821, Test R2 - Bx: 0.9394, By: 0.9313, Bz: 0.9728\n",
      "Estimated Remaining Time: 0h 3m 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 144/150: 100%|██████████| 15/15 [00:15<00:00,  1.01s/it, loss_Bx=3.55, loss_By=3.72, loss_Bz=3.04, physics_loss=0.0822]\n",
      "Test Epoch 144/150: 100%|██████████| 3/3 [00:07<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 144/150, Duration: 26.86s, Train Loss - Bx: 3.5206, By: 3.4939, Bz: 2.9113, Physics Loss: 0.0791, Test R2 - Bx: 0.9399, By: 0.9311, Bz: 0.9731\n",
      "Estimated Remaining Time: 0h 2m 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 145/150: 100%|██████████| 15/15 [00:14<00:00,  1.02it/s, loss_Bx=3.65, loss_By=3.74, loss_Bz=3.03, physics_loss=0.0849]\n",
      "Test Epoch 145/150: 100%|██████████| 3/3 [00:07<00:00,  2.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 145/150, Duration: 24.73s, Train Loss - Bx: 3.5183, By: 3.4875, Bz: 2.9098, Physics Loss: 0.0799, Test R2 - Bx: 0.9399, By: 0.9315, Bz: 0.9732\n",
      "Estimated Remaining Time: 0h 2m 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 146/150: 100%|██████████| 15/15 [00:14<00:00,  1.05it/s, loss_Bx=3.9, loss_By=3.85, loss_Bz=3.11, physics_loss=0.085]\n",
      "Test Epoch 146/150: 100%|██████████| 3/3 [00:07<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 146/150, Duration: 24.45s, Train Loss - Bx: 3.5165, By: 3.4847, Bz: 2.9062, Physics Loss: 0.0802, Test R2 - Bx: 0.9400, By: 0.9312, Bz: 0.9736\n",
      "Estimated Remaining Time: 0h 1m 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 147/150: 100%|██████████| 15/15 [00:14<00:00,  1.01it/s, loss_Bx=4.01, loss_By=3.99, loss_Bz=3.44, physics_loss=0.0949]\n",
      "Test Epoch 147/150: 100%|██████████| 3/3 [00:07<00:00,  2.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 147/150, Duration: 25.01s, Train Loss - Bx: 3.5163, By: 3.4846, Bz: 2.9061, Physics Loss: 0.0794, Test R2 - Bx: 0.9401, By: 0.9313, Bz: 0.9734\n",
      "Estimated Remaining Time: 0h 1m 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 148/150: 100%|██████████| 15/15 [00:14<00:00,  1.04it/s, loss_Bx=3.8, loss_By=3.84, loss_Bz=3.11, physics_loss=0.089]\n",
      "Test Epoch 148/150: 100%|██████████| 3/3 [00:06<00:00,  2.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 148/150, Duration: 24.30s, Train Loss - Bx: 3.5154, By: 3.4826, Bz: 2.9050, Physics Loss: 0.0795, Test R2 - Bx: 0.9401, By: 0.9313, Bz: 0.9735\n",
      "Estimated Remaining Time: 0h 0m 59s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 149/150: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, loss_Bx=3.49, loss_By=3.42, loss_Bz=2.83, physics_loss=0.0709]\n",
      "Test Epoch 149/150: 100%|██████████| 3/3 [00:07<00:00,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 149/150, Duration: 24.78s, Train Loss - Bx: 3.5137, By: 3.4818, Bz: 2.9053, Physics Loss: 0.0800, Test R2 - Bx: 0.9401, By: 0.9313, Bz: 0.9735\n",
      "Estimated Remaining Time: 0h 0m 29s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Epoch 150/150: 100%|██████████| 15/15 [00:14<00:00,  1.03it/s, loss_Bx=3.6, loss_By=3.53, loss_Bz=3.05, physics_loss=0.0701]\n",
      "Test Epoch 150/150: 100%|██████████| 3/3 [00:07<00:00,  2.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 150/150, Duration: 24.90s, Train Loss - Bx: 3.5129, By: 3.4798, Bz: 2.9067, Physics Loss: 0.0807, Test R2 - Bx: 0.9401, By: 0.9315, Bz: 0.9733\n",
      "Estimated Remaining Time: 0h 0m 0s\n",
      "Checkpoint saved at epoch 150: /mmfs1/project/bs644/jc2687/FNO/result/NLFFF_Cube2Step/step2/checkpoint_epoch_150.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bx - Mean: 1.1266078348004527e-11, Std: 1.0000020265579224\n",
      "by - Mean: 9.530843475547002e-11, Std: 0.9999985694885254\n",
      "bz - Mean: -7.410360519655157e-11, Std: 1.0000026226043701\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 150\n",
    "print_frequency = 40\n",
    "save_checkpoint_start_epoch = 20\n",
    "save_checkpoint_interval = 10\n",
    "checkpoint_dir = \"result/NLFFF_Cube2Step/step2\"\n",
    "results_file = os.path.join(checkpoint_dir, \"result.csv\")\n",
    "\n",
    "physics_loss_fn = PhysicsInformedLoss(weight=0.35, alpha=1, beta=1, gamma=1, delta = 0)\n",
    "single_physics_loss_DIV_fn = singlePhysicsInformedDivergence_Loss(weight=1, alpha=1.0, beta=1, gamma=1)\n",
    "single_physics_loss_FF_fn = singlePhysicsInformedForce_Free_Loss(weight=1, alpha=1.0, beta=1, gamma=1)\n",
    "\n",
    "with open(results_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['epoch', 'comp', 'r2', 'relative_error', 'mse', 'mae', 'psnr', 'ssim'])\n",
    "\n",
    "train_losses_Bx = []\n",
    "train_losses_By = []\n",
    "train_losses_Bz = []\n",
    "test_losses_Bx = []\n",
    "test_losses_By = []\n",
    "test_losses_Bz = []\n",
    "physics_losses_epoch = []\n",
    "epoch_durations = []\n",
    "\n",
    "#z_df = pd.read_csv(z_csv_path)\n",
    "#z_values = z_df['z'].values\n",
    "#assert len(z_values) == 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss_Bx = 0.0\n",
    "    epoch_loss_By = 0.0\n",
    "    epoch_loss_Bz = 0.0\n",
    "    epoch_physics_loss = 0.0\n",
    "    \n",
    "    \n",
    "    time_step_DIV_losses_accum = None\n",
    "    time_step_FF_losses_accum = None\n",
    "\n",
    "    train_loader_tqdm = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Train Epoch {epoch+1}/{num_epochs}')\n",
    "    for batch_idx, (batch_i, sample) in enumerate(train_loader_tqdm):\n",
    "        optimizer.zero_grad()\n",
    "        data, target = sample['input'].to(device0), sample['target'].to(device0)\n",
    "        lengths = sample['lengths'].to(device0)  \n",
    "\n",
    "        output = newmodel(data, lengths)\n",
    "\n",
    "        #print(output.shape)\n",
    "\n",
    "        loss_Bx = h1loss(output[:, :, 0, :, :], target[:, :, 0, :, :]).mean()\n",
    "        loss_By = h1loss(output[:, :, 1, :, :], target[:, :, 1, :, :]).mean()\n",
    "        loss_Bz = h1loss(output[:, :, 2, :, :], target[:, :, 2, :, :]).mean()\n",
    "\n",
    "        physics_loss = physics_loss_fn(output, target)\n",
    "\n",
    "        num_time_steps = output.size(1)\n",
    "\n",
    "        if time_step_DIV_losses_accum is None:\n",
    "            time_step_DIV_losses_accum = np.zeros(num_time_steps, dtype=np.float32)\n",
    "\n",
    "        if time_step_FF_losses_accum is None:\n",
    "            time_step_FF_losses_accum = np.zeros(num_time_steps, dtype=np.float32)\n",
    "\n",
    "        for i in range(num_time_steps):\n",
    "            DIV_losses_step = single_physics_loss_DIV_fn(output[:, i, :, :, :], target[:, i, :, :, :])\n",
    "            DIV_losses_step_scalar = DIV_losses_step.mean().item()\n",
    "\n",
    "            time_step_DIV_losses_accum[i] += DIV_losses_step_scalar\n",
    "\n",
    "        for i in range(num_time_steps):\n",
    "            FF_losses_step = single_physics_loss_FF_fn(output[:, i, :, :, :], target[:, i, :, :, :])\n",
    "            FF_losses_step_scalar = FF_losses_step.mean().item()\n",
    "\n",
    "            time_step_FF_losses_accum[i] += FF_losses_step_scalar        \n",
    "\n",
    "        total_loss = loss_Bx + loss_By + loss_Bz + physics_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss_Bx += loss_Bx.item()\n",
    "        epoch_loss_By += loss_By.item()\n",
    "        epoch_loss_Bz += loss_Bz.item()\n",
    "        epoch_physics_loss += physics_loss.item()\n",
    "\n",
    "        if batch_idx % print_frequency == 0:\n",
    "            train_loader_tqdm.set_postfix(\n",
    "                loss_Bx=loss_Bx.item(),\n",
    "                loss_By=loss_By.item(),\n",
    "                loss_Bz=loss_Bz.item(),\n",
    "                physics_loss=physics_loss.item()\n",
    "            )\n",
    "\n",
    "    avg_loss_Bx = epoch_loss_Bx / len(train_loader)\n",
    "    avg_loss_By = epoch_loss_By / len(train_loader)\n",
    "    avg_loss_Bz = epoch_loss_Bz / len(train_loader)\n",
    "    avg_physics_loss = epoch_physics_loss / len(train_loader)\n",
    "\n",
    "    train_losses_Bx.append(avg_loss_Bx)\n",
    "    train_losses_By.append(avg_loss_By)\n",
    "    train_losses_Bz.append(avg_loss_Bz)\n",
    "    physics_losses_epoch.append(avg_physics_loss)\n",
    "\n",
    "    all_E_pred = []\n",
    "    all_E_true = []\n",
    "\n",
    "    model.eval()\n",
    "    epoch_r2_Bx = []\n",
    "    epoch_r2_By = []\n",
    "    epoch_r2_Bz = []\n",
    "    test_loader_tqdm = tqdm(test_loader, total=len(test_loader), desc=f'Test Epoch {epoch+1}/{num_epochs}')\n",
    "    with torch.no_grad():\n",
    "        for sample in test_loader_tqdm:\n",
    "            x = sample['input'].to(device0)\n",
    "            lengths = sample['lengths'].to(device0)  \n",
    "            target = sample['target'].cpu().numpy()\n",
    "            output = newmodel(x, lengths).cpu().numpy()\n",
    "\n",
    "            for true_sample, pred_sample in zip(target, output):\n",
    "                r2_Bx = r2_score(true_sample[:, 0].flatten(), pred_sample[:, 0].flatten())\n",
    "                r2_By = r2_score(true_sample[:, 1].flatten(), pred_sample[:, 1].flatten())\n",
    "                r2_Bz = r2_score(true_sample[:, 2].flatten(), pred_sample[:, 2].flatten())\n",
    "\n",
    "                epoch_r2_Bx.append(r2_Bx)\n",
    "                epoch_r2_By.append(r2_By)\n",
    "                epoch_r2_Bz.append(r2_Bz)\n",
    "\n",
    "\n",
    "    avg_r2_Bx = np.mean(epoch_r2_Bx)\n",
    "    avg_r2_By = np.mean(epoch_r2_By)\n",
    "    avg_r2_Bz = np.mean(epoch_r2_Bz)\n",
    "\n",
    "    test_losses_Bx.append(avg_r2_Bx)\n",
    "    test_losses_By.append(avg_r2_By)\n",
    "    test_losses_Bz.append(avg_r2_Bz)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    epoch_durations.append(epoch_duration)\n",
    "\n",
    "    avg_train_loss_combined = (avg_loss_Bx + avg_loss_By + avg_loss_Bz + avg_physics_loss) / 3\n",
    "    scheduler.step(avg_train_loss_combined)\n",
    "\n",
    "    avg_epoch_duration = np.mean(epoch_durations)\n",
    "    remaining_epochs = num_epochs - (epoch + 1)\n",
    "    remaining_time = remaining_epochs * avg_epoch_duration\n",
    "    hours, rem = divmod(remaining_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}, Duration: {epoch_duration:.2f}s, '\n",
    "          f'Train Loss - Bx: {avg_loss_Bx:.4f}, By: {avg_loss_By:.4f}, Bz: {avg_loss_Bz:.4f}, Physics Loss: {avg_physics_loss:.4f}, '\n",
    "          f'Test R2 - Bx: {avg_r2_Bx:.4f}, By: {avg_r2_By:.4f}, Bz: {avg_r2_Bz:.4f}')\n",
    "\n",
    "    print(f'Estimated Remaining Time: {int(hours)}h {int(minutes)}m {int(seconds)}s')\n",
    "\n",
    "    if (epoch + 1) >= save_checkpoint_start_epoch and (epoch + 1) % save_checkpoint_interval == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pt\")\n",
    "        torch.save(newmodel.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}: {checkpoint_path}\")\n",
    "\n",
    "        min_val = float('inf')\n",
    "        max_val = float('-inf')\n",
    "\n",
    "        for sample in test_loader:\n",
    "            y_true_batch = sample['target'].numpy()\n",
    "            batch_min = y_true_batch.min()\n",
    "            batch_max = y_true_batch.max()\n",
    "            min_val = min(min_val, batch_min)\n",
    "            max_val = max(max_val, batch_max)\n",
    "\n",
    "        data_range = max_val - min_val\n",
    "\n",
    "        sample_r2_scores = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_relative_errors = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_mses = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_maes = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_psnr_values = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_ssim_values = {'bx': [], 'by': [], 'bz': []}\n",
    "        mean_std = {comp: {'mean': None, 'std': None} for comp in ['bx', 'by', 'bz']}\n",
    "        true_values_by_component = {comp: [] for comp in ['bx', 'by', 'bz']}\n",
    "\n",
    "        for sample in train_loader: \n",
    "            y_true_batch = sample['target'].cpu().numpy()\n",
    "            for true_sample in y_true_batch:\n",
    "                for i, comp in enumerate(['bx', 'by', 'bz']):\n",
    "                    true_sample_component = true_sample[:, i]\n",
    "                    true_sample_flat = true_sample_component.flatten()\n",
    "                    true_values_by_component[comp].extend(true_sample_flat)\n",
    "\n",
    "        for comp in ['bx', 'by', 'bz']:\n",
    "            true_values = np.array(true_values_by_component[comp])\n",
    "            mean_std[comp]['mean'] = np.mean(true_values)\n",
    "            mean_std[comp]['std'] = np.std(true_values)\n",
    "\n",
    "        for comp in mean_std:\n",
    "            print(f\"{comp} - Mean: {mean_std[comp]['mean']}, Std: {mean_std[comp]['std']}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for sample in test_loader:\n",
    "                x = sample['input'].to(device0)\n",
    "                lengths = sample['lengths'].to(device0)  \n",
    "                y_true_batch = sample['target'].cpu().numpy()\n",
    "                y_pred_batch = newmodel(x, lengths).cpu().numpy()\n",
    "\n",
    "                for true_sample, pred_sample in zip(y_true_batch, y_pred_batch):\n",
    "                    for i, comp in enumerate(['bx', 'by', 'bz']):\n",
    "                        true_sample_component = true_sample[:, i]\n",
    "                        pred_sample_component = pred_sample[:, i]\n",
    "\n",
    "                        true_sample_flat = true_sample_component.flatten()\n",
    "                        pred_sample_flat = pred_sample_component.flatten()\n",
    "\n",
    "                        r2 = r2_score(true_sample_flat, pred_sample_flat)\n",
    "                        sample_r2_scores[comp].append(r2)\n",
    "\n",
    "                        mean = mean_std[comp]['mean']\n",
    "                        std = mean_std[comp]['std']\n",
    "                        true_sample_original = true_sample_flat * std + mean\n",
    "                        pred_sample_original = pred_sample_flat * std + mean\n",
    "\n",
    "                        absolute_error = np.linalg.norm(true_sample_original - pred_sample_original, 1)\n",
    "\n",
    "                        relative_error = absolute_error / np.linalg.norm(true_sample_original, 1)\n",
    "                        sample_relative_errors[comp].append(relative_error)\n",
    "\n",
    "                        mse = mean_squared_error(true_sample_flat, pred_sample_flat)\n",
    "                        sample_mses[comp].append(mse)\n",
    "\n",
    "                        mae = mean_absolute_error(true_sample_flat, pred_sample_flat)\n",
    "                        sample_maes[comp].append(mae)\n",
    "\n",
    "                        psnr_value = psnr(true_sample_component, pred_sample_component, data_range=data_range)\n",
    "                        sample_psnr_values[comp].append(psnr_value)\n",
    "\n",
    "                        ssim_value = ssim(true_sample_component, pred_sample_component, data_range=data_range)\n",
    "                        sample_ssim_values[comp].append(ssim_value)\n",
    "\n",
    "        with open(results_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for comp in ['bx', 'by', 'bz']:\n",
    "                writer.writerow([epoch+1, comp,\n",
    "                                 np.mean(sample_r2_scores[comp]),\n",
    "                                 np.mean(sample_relative_errors[comp]),\n",
    "                                 np.mean(sample_mses[comp]),\n",
    "                                 np.mean(sample_maes[comp]),\n",
    "                                 np.mean(sample_psnr_values[comp]),\n",
    "                                 np.mean(sample_ssim_values[comp])])\n",
    "\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses_Bx.npy'), np.array(train_losses_Bx))\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses_By.npy'), np.array(train_losses_By))\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses_Bz.npy'), np.array(train_losses_Bz))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses_Bx.npy'), np.array(test_losses_Bx))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses_By.npy'), np.array(test_losses_By))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses_Bz.npy'), np.array(test_losses_Bz))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses_Bx, label='Training Loss Bx', color='red')\n",
    "plt.plot(train_losses_By, label='Training Loss By', color='green')\n",
    "plt.plot(train_losses_Bz, label='Training Loss Bz', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses for Bx, By, Bz')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(test_losses_Bx, label='Testing R2 Bx', color='red')\n",
    "plt.plot(test_losses_By, label='Testing R2 By', color='green')\n",
    "plt.plot(test_losses_Bz, label='Testing R2 Bz', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.title('Testing R2 Scores for Bx, By, Bz')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbf689ce-8f08-41c8-9f0d-200caa033083",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2217498/1754979559.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  newmodel.load_state_dict(torch.load(\"result/NLFFF_Cube2Step/step2/checkpoint_epoch_140.pt\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CustomFNOnew(\n",
       "  (DilatedConvYWithECA): DilatedConvYWithECA(\n",
       "    (conv): Conv3d(25, 25, kernel_size=(1, 3, 1), stride=(1, 1, 1), padding=(0, 2, 0), dilation=(1, 2, 1), bias=False)\n",
       "    (activation): ReLU()\n",
       "    (eca): ECA3DLayer(\n",
       "      (avg_pool): AdaptiveAvgPool3d(output_size=1)\n",
       "      (conv): Conv1d(1, 1, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
       "      (sigmoid): Sigmoid()\n",
       "    )\n",
       "  )\n",
       "  (lifting1): MLP(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Conv3d(3, 25, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       "  (lifting_y): MLP(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Conv1d(3, 256, kernel_size=(1,), stride=(1,))\n",
       "      (1): Conv1d(256, 25, kernel_size=(1,), stride=(1,))\n",
       "    )\n",
       "  )\n",
       "  (fno_blocks): FNOBlocks(\n",
       "    (convs): SpectralConv(\n",
       "      (weight): ModuleList(\n",
       "        (0-5): 6 x ComplexTuckerTensor(shape=(25, 25, 32, 32, 17), rank=(18, 18, 23, 23, 12))\n",
       "      )\n",
       "    )\n",
       "    (fno_skips): ModuleList(\n",
       "      (0-5): 6 x Conv3d(25, 25, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "    )\n",
       "    (mlp): ModuleList(\n",
       "      (0-5): 6 x MLP(\n",
       "        (fcs): ModuleList(\n",
       "          (0): Conv3d(25, 12, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "          (1): Conv3d(12, 25, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (mlp_skips): ModuleList(\n",
       "      (0-5): 6 x SoftGating()\n",
       "    )\n",
       "  )\n",
       "  (projection): MLP(\n",
       "    (fcs): ModuleList(\n",
       "      (0): Conv3d(25, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "      (1): Conv3d(256, 25, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newmodel.load_state_dict(torch.load(\"result/NLFFF_Cube2Step/step2/checkpoint_epoch_140.pt\"))\n",
    "newmodel.eval() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f0b44dd9-0c60-4817-b81f-28fef4d0ce41",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR! Session/line number was not unique in database. History logging moved to new session 498\n",
      "[✓] sample 0 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 0 | By: GT & Pred videos saved.\n",
      "[✓] sample 0 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 1 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 1 | By: GT & Pred videos saved.\n",
      "[✓] sample 1 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 2 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 2 | By: GT & Pred videos saved.\n",
      "[✓] sample 2 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 3 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 3 | By: GT & Pred videos saved.\n",
      "[✓] sample 3 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 4 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 4 | By: GT & Pred videos saved.\n",
      "[✓] sample 4 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 5 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 5 | By: GT & Pred videos saved.\n",
      "[✓] sample 5 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 6 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 6 | By: GT & Pred videos saved.\n",
      "[✓] sample 6 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 7 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 7 | By: GT & Pred videos saved.\n",
      "[✓] sample 7 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 8 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 8 | By: GT & Pred videos saved.\n",
      "[✓] sample 8 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 9 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 9 | By: GT & Pred videos saved.\n",
      "[✓] sample 9 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 10 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 10 | By: GT & Pred videos saved.\n",
      "[✓] sample 10 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 11 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 11 | By: GT & Pred videos saved.\n",
      "[✓] sample 11 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 12 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 12 | By: GT & Pred videos saved.\n",
      "[✓] sample 12 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 13 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 13 | By: GT & Pred videos saved.\n",
      "[✓] sample 13 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 14 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 14 | By: GT & Pred videos saved.\n",
      "[✓] sample 14 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 15 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 15 | By: GT & Pred videos saved.\n",
      "[✓] sample 15 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 16 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 16 | By: GT & Pred videos saved.\n",
      "[✓] sample 16 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 17 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 17 | By: GT & Pred videos saved.\n",
      "[✓] sample 17 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 18 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 18 | By: GT & Pred videos saved.\n",
      "[✓] sample 18 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 19 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 19 | By: GT & Pred videos saved.\n",
      "[✓] sample 19 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 20 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 20 | By: GT & Pred videos saved.\n",
      "[✓] sample 20 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 21 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 21 | By: GT & Pred videos saved.\n",
      "[✓] sample 21 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 22 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 22 | By: GT & Pred videos saved.\n",
      "[✓] sample 22 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 23 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 23 | By: GT & Pred videos saved.\n",
      "[✓] sample 23 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 24 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 24 | By: GT & Pred videos saved.\n",
      "[✓] sample 24 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 25 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 25 | By: GT & Pred videos saved.\n",
      "[✓] sample 25 | Bz: GT & Pred videos saved.\n",
      "[✓] sample 26 | Bx: GT & Pred videos saved.\n",
      "[✓] sample 26 | By: GT & Pred videos saved.\n",
      "[✓] sample 26 | Bz: GT & Pred videos saved.\n",
      "✅ All videos have been generated.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "# ============== 0) 工具函数：Figure → RGB ndarray ==============\n",
    "def fig_to_rgb_array(fig):\n",
    "    \"\"\"\n",
    "    把 Matplotlib Figure 转成 (H, W, 3) 的 uint8 RGB 数组\n",
    "    兼容所有后端：先 draw() 再用 buffer_rgba()\n",
    "    \"\"\"\n",
    "    fig.canvas.draw()                               # 必须先绘制\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    buf = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "    img = buf.reshape(h, w, 4)[..., :3]             # 去掉 Alpha 通道\n",
    "    return img\n",
    "\n",
    "# ============== 1) 读取 CSV，获取和时间步对齐的 z 值 ==============\n",
    "z_csv_path = \"NLFFF_data/height_12443.csv\"          # 替换为你的 CSV 路径\n",
    "z_df = pd.read_csv(z_csv_path)\n",
    "z_values = z_df[\"z\"].values                         # shape: (time_length,)\n",
    "\n",
    "# ============== 2) 遍历测试集并生成视频 ============================\n",
    "output_dir = \"result/NLFFF_Cube2Step/step2Test/visualizations\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "fps         = 3\n",
    "frame_size  = (1024, 512)                           # (W, H) for VideoWriter\n",
    "channel_ids = [\"Bx\", \"By\", \"Bz\"]\n",
    "\n",
    "device0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for sample_idx, sample in enumerate(test_dataset):\n",
    "\n",
    "    # 2.1 取出单个样本\n",
    "    input_data = sample[\"input\"]                    # (T, 3, H, W)\n",
    "    true_data  = sample[\"target\"]                   # (T, 3, H, W)\n",
    "    lengths    = sample[\"lengths\"]\n",
    "\n",
    "    # 2.2 推理\n",
    "    with torch.no_grad():\n",
    "        pred_batch = newmodel(\n",
    "            input_data.unsqueeze(0).to(device0),    # (1, T, 3, H, W)\n",
    "            lengths.to(device0)\n",
    "        )\n",
    "    pred_data = pred_batch.cpu().numpy()[0]         # (T, 3, H, W)\n",
    "\n",
    "    time_length = pred_data.shape[0]\n",
    "\n",
    "    # 2.3 为每个通道分别写 GT / Pred 视频\n",
    "    for ch_idx, ch_name in enumerate(channel_ids):\n",
    "\n",
    "        # ---------- 打开 VideoWriter ----------\n",
    "        gt_path   = os.path.join(output_dir, f\"gt_{ch_name}_sample_{sample_idx}.mp4\")\n",
    "        pred_path = os.path.join(output_dir, f\"pred_{ch_name}_sample_{sample_idx}.mp4\")\n",
    "\n",
    "        gt_writer   = cv2.VideoWriter(gt_path,   cv2.VideoWriter_fourcc(*\"mp4v\"), fps, frame_size)\n",
    "        pred_writer = cv2.VideoWriter(pred_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, frame_size)\n",
    "\n",
    "        # ---------- 逐时间步写帧 ----------\n",
    "        for t in range(time_length):\n",
    "\n",
    "            z_val = z_values[t]\n",
    "\n",
    "            true_frame = true_data[t, ch_idx]       # (H, W)\n",
    "            pred_frame = pred_data[t, ch_idx]       # (H, W)\n",
    "\n",
    "            vmin, vmax = true_frame.min(), true_frame.max()\n",
    "            vmin = min(vmin, pred_frame.min())\n",
    "            vmax = max(vmax, pred_frame.max())\n",
    "\n",
    "            # ===== Ground Truth =====\n",
    "            fig_gt, ax_gt = plt.subplots(figsize=(14, 7))\n",
    "            plt.subplots_adjust(top=0.95, bottom=0.05, left=0.05, right=0.95)\n",
    "            ax_gt.imshow(true_frame, cmap=\"RdBu\", origin=\"lower\", vmin=vmin, vmax=vmax)\n",
    "            ax_gt.axis(\"off\")\n",
    "            fig_gt.suptitle(f\"{z_val} Mm\", fontsize=14)\n",
    "\n",
    "            gt_img = fig_to_rgb_array(fig_gt)\n",
    "            gt_img = cv2.resize(gt_img, frame_size)\n",
    "            gt_writer.write(cv2.cvtColor(gt_img, cv2.COLOR_RGB2BGR))\n",
    "            plt.close(fig_gt)\n",
    "\n",
    "            # ===== Prediction =====\n",
    "            fig_pred, ax_pred = plt.subplots(figsize=(14, 7))\n",
    "            plt.subplots_adjust(top=0.95, bottom=0.05, left=0.05, right=0.95)\n",
    "            ax_pred.imshow(pred_frame, cmap=\"RdBu\", origin=\"lower\", vmin=vmin, vmax=vmax)\n",
    "            ax_pred.axis(\"off\")\n",
    "\n",
    "            pred_img = fig_to_rgb_array(fig_pred)\n",
    "            pred_img = cv2.resize(pred_img, frame_size)\n",
    "            pred_writer.write(cv2.cvtColor(pred_img, cv2.COLOR_RGB2BGR))\n",
    "            plt.close(fig_pred)\n",
    "\n",
    "        # ---------- 收尾 ----------\n",
    "        gt_writer.release()\n",
    "        pred_writer.release()\n",
    "        print(f\"[✓] sample {sample_idx} | {ch_name}: GT & Pred videos saved.\")\n",
    "\n",
    "print(\"✅ All videos have been generated.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11c9c9b8-ac38-4357-a929-28a0c1e90997",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 0 - Bx] R2=0.9441, MSE=5.595e-02, MAE=1.597e-01, RE=0.2359, PSNR=39.52, SSIM=0.8284\n",
      "[Sample 0 - By] R2=0.9447, MSE=5.530e-02, MAE=1.665e-01, RE=0.2583, PSNR=39.35, SSIM=0.8231\n",
      "[Sample 0 - Bz] R2=0.9792, MSE=2.081e-02, MAE=1.029e-01, RE=0.1892, PSNR=45.23, SSIM=0.9024\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 1 - Bx] R2=0.9539, MSE=4.613e-02, MAE=1.383e-01, RE=0.1828, PSNR=37.98, SSIM=0.8977\n",
      "[Sample 1 - By] R2=0.9397, MSE=6.026e-02, MAE=1.583e-01, RE=0.2508, PSNR=35.09, SSIM=0.8115\n",
      "[Sample 1 - Bz] R2=0.9832, MSE=1.678e-02, MAE=8.591e-02, RE=0.1582, PSNR=43.77, SSIM=0.9136\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 2 - Bx] R2=0.9695, MSE=3.051e-02, MAE=1.107e-01, RE=0.1824, PSNR=40.05, SSIM=0.8945\n",
      "[Sample 2 - By] R2=0.9519, MSE=4.808e-02, MAE=1.407e-01, RE=0.2692, PSNR=39.35, SSIM=0.8011\n",
      "[Sample 2 - Bz] R2=0.9859, MSE=1.414e-02, MAE=8.101e-02, RE=0.1838, PSNR=45.96, SSIM=0.9021\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 3 - Bx] R2=0.8668, MSE=1.332e-01, MAE=2.523e-01, RE=0.3347, PSNR=40.26, SSIM=0.7591\n",
      "[Sample 3 - By] R2=0.8866, MSE=1.134e-01, MAE=2.425e-01, RE=0.3336, PSNR=40.74, SSIM=0.7750\n",
      "[Sample 3 - Bz] R2=0.9390, MSE=6.103e-02, MAE=1.831e-01, RE=0.2721, PSNR=43.00, SSIM=0.8231\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 4 - Bx] R2=0.9094, MSE=9.063e-02, MAE=2.019e-01, RE=0.2956, PSNR=38.07, SSIM=0.8232\n",
      "[Sample 4 - By] R2=0.9486, MSE=5.143e-02, MAE=1.553e-01, RE=0.2683, PSNR=39.81, SSIM=0.8339\n",
      "[Sample 4 - Bz] R2=0.9710, MSE=2.898e-02, MAE=1.149e-01, RE=0.2150, PSNR=43.36, SSIM=0.8784\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 5 - Bx] R2=0.9232, MSE=7.678e-02, MAE=1.806e-01, RE=0.3739, PSNR=38.53, SSIM=0.7551\n",
      "[Sample 5 - By] R2=0.9167, MSE=8.328e-02, MAE=1.977e-01, RE=0.3988, PSNR=37.37, SSIM=0.6910\n",
      "[Sample 5 - Bz] R2=0.9648, MSE=3.518e-02, MAE=1.259e-01, RE=0.3049, PSNR=42.72, SSIM=0.8249\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 6 - Bx] R2=0.9441, MSE=5.595e-02, MAE=1.599e-01, RE=0.3184, PSNR=38.63, SSIM=0.7492\n",
      "[Sample 6 - By] R2=0.9322, MSE=6.778e-02, MAE=1.680e-01, RE=0.3328, PSNR=38.61, SSIM=0.7441\n",
      "[Sample 6 - Bz] R2=0.9779, MSE=2.206e-02, MAE=1.031e-01, RE=0.2571, PSNR=44.28, SSIM=0.8548\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 7 - Bx] R2=0.9305, MSE=6.948e-02, MAE=1.775e-01, RE=0.2284, PSNR=40.15, SSIM=0.8652\n",
      "[Sample 7 - By] R2=0.9172, MSE=8.277e-02, MAE=2.028e-01, RE=0.3017, PSNR=39.97, SSIM=0.7719\n",
      "[Sample 7 - Bz] R2=0.9755, MSE=2.455e-02, MAE=1.124e-01, RE=0.1755, PSNR=44.78, SSIM=0.8919\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 8 - Bx] R2=0.9091, MSE=9.088e-02, MAE=1.977e-01, RE=0.2983, PSNR=37.90, SSIM=0.7986\n",
      "[Sample 8 - By] R2=0.8579, MSE=1.421e-01, MAE=2.590e-01, RE=0.3979, PSNR=36.51, SSIM=0.7507\n",
      "[Sample 8 - Bz] R2=0.9369, MSE=6.311e-02, MAE=1.568e-01, RE=0.2983, PSNR=41.61, SSIM=0.8458\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 9 - Bx] R2=0.9253, MSE=7.466e-02, MAE=1.867e-01, RE=0.2722, PSNR=42.15, SSIM=0.8389\n",
      "[Sample 9 - By] R2=0.9262, MSE=7.379e-02, MAE=1.890e-01, RE=0.2999, PSNR=40.61, SSIM=0.8115\n",
      "[Sample 9 - Bz] R2=0.9766, MSE=2.337e-02, MAE=1.065e-01, RE=0.1868, PSNR=46.03, SSIM=0.9033\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 10 - Bx] R2=0.9179, MSE=8.211e-02, MAE=1.967e-01, RE=0.3270, PSNR=38.34, SSIM=0.7426\n",
      "[Sample 10 - By] R2=0.9103, MSE=8.967e-02, MAE=2.065e-01, RE=0.4184, PSNR=39.12, SSIM=0.7397\n",
      "[Sample 10 - Bz] R2=0.9605, MSE=3.954e-02, MAE=1.424e-01, RE=0.2796, PSNR=41.34, SSIM=0.7999\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 11 - Bx] R2=0.9594, MSE=4.062e-02, MAE=1.344e-01, RE=0.2130, PSNR=40.90, SSIM=0.8830\n",
      "[Sample 11 - By] R2=0.9515, MSE=4.853e-02, MAE=1.491e-01, RE=0.2890, PSNR=39.65, SSIM=0.8003\n",
      "[Sample 11 - Bz] R2=0.9831, MSE=1.687e-02, MAE=8.745e-02, RE=0.1780, PSNR=44.79, SSIM=0.8962\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 12 - Bx] R2=0.9541, MSE=4.589e-02, MAE=1.326e-01, RE=0.1766, PSNR=38.69, SSIM=0.8767\n",
      "[Sample 12 - By] R2=0.9286, MSE=7.137e-02, MAE=1.669e-01, RE=0.2508, PSNR=38.66, SSIM=0.8258\n",
      "[Sample 12 - Bz] R2=0.9784, MSE=2.158e-02, MAE=1.019e-01, RE=0.1658, PSNR=43.96, SSIM=0.9048\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 13 - Bx] R2=0.8918, MSE=1.082e-01, MAE=2.357e-01, RE=0.3440, PSNR=38.29, SSIM=0.7979\n",
      "[Sample 13 - By] R2=0.8493, MSE=1.507e-01, MAE=2.616e-01, RE=0.3869, PSNR=36.65, SSIM=0.7286\n",
      "[Sample 13 - Bz] R2=0.9668, MSE=3.324e-02, MAE=1.249e-01, RE=0.1881, PSNR=44.06, SSIM=0.9009\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 14 - Bx] R2=0.9408, MSE=5.923e-02, MAE=1.562e-01, RE=0.2268, PSNR=38.51, SSIM=0.8565\n",
      "[Sample 14 - By] R2=0.9446, MSE=5.537e-02, MAE=1.611e-01, RE=0.2651, PSNR=39.63, SSIM=0.8095\n",
      "[Sample 14 - Bz] R2=0.9733, MSE=2.668e-02, MAE=1.100e-01, RE=0.1946, PSNR=43.42, SSIM=0.8896\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 15 - Bx] R2=0.9589, MSE=4.113e-02, MAE=1.349e-01, RE=0.2019, PSNR=39.53, SSIM=0.8804\n",
      "[Sample 15 - By] R2=0.9248, MSE=7.522e-02, MAE=1.786e-01, RE=0.3251, PSNR=36.27, SSIM=0.7703\n",
      "[Sample 15 - Bz] R2=0.9818, MSE=1.818e-02, MAE=9.047e-02, RE=0.2048, PSNR=43.75, SSIM=0.8668\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 16 - Bx] R2=0.9399, MSE=6.012e-02, MAE=1.720e-01, RE=0.2503, PSNR=34.58, SSIM=0.8186\n",
      "[Sample 16 - By] R2=0.9328, MSE=6.716e-02, MAE=1.734e-01, RE=0.3298, PSNR=34.78, SSIM=0.7292\n",
      "[Sample 16 - Bz] R2=0.9772, MSE=2.281e-02, MAE=1.071e-01, RE=0.2153, PSNR=40.07, SSIM=0.8174\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 17 - Bx] R2=0.9350, MSE=6.502e-02, MAE=1.579e-01, RE=0.2681, PSNR=38.66, SSIM=0.8144\n",
      "[Sample 17 - By] R2=0.9050, MSE=9.500e-02, MAE=2.007e-01, RE=0.3289, PSNR=37.29, SSIM=0.7464\n",
      "[Sample 17 - Bz] R2=0.9683, MSE=3.173e-02, MAE=1.161e-01, RE=0.2331, PSNR=41.82, SSIM=0.8586\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 18 - Bx] R2=0.9302, MSE=6.980e-02, MAE=1.762e-01, RE=0.2841, PSNR=40.54, SSIM=0.8350\n",
      "[Sample 18 - By] R2=0.9305, MSE=6.951e-02, MAE=1.875e-01, RE=0.3118, PSNR=41.06, SSIM=0.8081\n",
      "[Sample 18 - Bz] R2=0.9718, MSE=2.817e-02, MAE=1.207e-01, RE=0.2097, PSNR=42.84, SSIM=0.8907\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 19 - Bx] R2=0.9435, MSE=5.645e-02, MAE=1.537e-01, RE=0.2127, PSNR=41.47, SSIM=0.8583\n",
      "[Sample 19 - By] R2=0.9478, MSE=5.221e-02, MAE=1.600e-01, RE=0.2601, PSNR=40.76, SSIM=0.8097\n",
      "[Sample 19 - Bz] R2=0.9798, MSE=2.023e-02, MAE=9.917e-02, RE=0.1818, PSNR=44.61, SSIM=0.8690\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 20 - Bx] R2=0.9056, MSE=9.444e-02, MAE=2.118e-01, RE=0.3079, PSNR=37.00, SSIM=0.7870\n",
      "[Sample 20 - By] R2=0.8936, MSE=1.064e-01, MAE=2.305e-01, RE=0.3574, PSNR=37.88, SSIM=0.7665\n",
      "[Sample 20 - Bz] R2=0.9564, MSE=4.360e-02, MAE=1.477e-01, RE=0.2506, PSNR=40.72, SSIM=0.8183\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 21 - Bx] R2=0.9417, MSE=5.833e-02, MAE=1.600e-01, RE=0.2265, PSNR=40.76, SSIM=0.8511\n",
      "[Sample 21 - By] R2=0.9546, MSE=4.537e-02, MAE=1.366e-01, RE=0.2380, PSNR=42.03, SSIM=0.8670\n",
      "[Sample 21 - Bz] R2=0.9766, MSE=2.342e-02, MAE=1.013e-01, RE=0.1850, PSNR=45.15, SSIM=0.9037\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 22 - Bx] R2=0.9532, MSE=4.680e-02, MAE=1.446e-01, RE=0.2041, PSNR=38.70, SSIM=0.8701\n",
      "[Sample 22 - By] R2=0.9364, MSE=6.359e-02, MAE=1.666e-01, RE=0.2433, PSNR=37.37, SSIM=0.8168\n",
      "[Sample 22 - Bz] R2=0.9781, MSE=2.190e-02, MAE=9.939e-02, RE=0.1624, PSNR=43.07, SSIM=0.9009\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 23 - Bx] R2=0.9475, MSE=5.245e-02, MAE=1.613e-01, RE=0.2519, PSNR=38.31, SSIM=0.8429\n",
      "[Sample 23 - By] R2=0.9349, MSE=6.505e-02, MAE=1.618e-01, RE=0.2850, PSNR=38.29, SSIM=0.7856\n",
      "[Sample 23 - Bz] R2=0.9826, MSE=1.744e-02, MAE=8.992e-02, RE=0.1754, PSNR=44.00, SSIM=0.8961\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 24 - Bx] R2=0.9466, MSE=5.341e-02, MAE=1.569e-01, RE=0.2746, PSNR=39.39, SSIM=0.8290\n",
      "[Sample 24 - By] R2=0.9182, MSE=8.180e-02, MAE=1.884e-01, RE=0.3285, PSNR=37.46, SSIM=0.7964\n",
      "[Sample 24 - Bz] R2=0.9725, MSE=2.750e-02, MAE=1.078e-01, RE=0.2187, PSNR=43.22, SSIM=0.8959\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 25 - Bx] R2=0.9786, MSE=2.145e-02, MAE=9.688e-02, RE=0.1379, PSNR=42.21, SSIM=0.9284\n",
      "[Sample 25 - By] R2=0.9692, MSE=3.077e-02, MAE=1.213e-01, RE=0.2432, PSNR=40.16, SSIM=0.8384\n",
      "[Sample 25 - Bz] R2=0.9885, MSE=1.153e-02, MAE=7.493e-02, RE=0.1531, PSNR=44.80, SSIM=0.9188\n",
      "torch.Size([25, 3, 257, 513])\n",
      "[Sample 26 - Bx] R2=0.9520, MSE=4.804e-02, MAE=1.564e-01, RE=0.2593, PSNR=37.18, SSIM=0.8331\n",
      "[Sample 26 - By] R2=0.9440, MSE=5.599e-02, MAE=1.560e-01, RE=0.2954, PSNR=36.66, SSIM=0.7693\n",
      "[Sample 26 - Bz] R2=0.9800, MSE=2.002e-02, MAE=9.678e-02, RE=0.2227, PSNR=42.71, SSIM=0.8832\n",
      "\n",
      "✓ 所有指标已保存到 result/NLFFF_Cube2Step/step2Test/cube/cube_metrics.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "output_dir = \"result/NLFFF_Cube2Step/step2Test/cube\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "npy_dir = os.path.join(output_dir, \"npy_data\")\n",
    "os.makedirs(npy_dir, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(output_dir, \"cube_metrics.csv\")\n",
    "\n",
    "def mean_relative_error(y_true, y_pred, zeroarr):\n",
    "\n",
    "    return mean_absolute_error(y_true, y_pred) / mean_absolute_error(y_true,zeroarr)\n",
    "\n",
    "def compute_psnr(y_true, y_pred):\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    if mse == 0:\n",
    "        return float(\"inf\")\n",
    "    data_range = np.max(y_true) - np.min(y_true)\n",
    "    data_range = data_range if data_range > 0 else 1.0\n",
    "    return 20 * np.log10(data_range / np.sqrt(mse))\n",
    "\n",
    "def compute_ssim_cube(true_cube, pred_cube):\n",
    "    ssim_vals = []\n",
    "    for i in range(true_cube.shape[0]):\n",
    "        data_range = true_cube[i].max() - true_cube[i].min()\n",
    "        data_range = data_range if data_range > 0 else 1.0\n",
    "        ssim_vals.append(\n",
    "            ssim(true_cube[i], pred_cube[i], data_range=data_range)\n",
    "        )\n",
    "    return float(np.mean(ssim_vals))\n",
    "\n",
    "# ---------------------- 主循环 ----------------------\n",
    "rows = []\n",
    "\n",
    "for sample_idx, sample in enumerate(test_dataset):\n",
    "\n",
    "    input_data = sample[\"input\"]          # (T, 3, H, W)  torch.Tensor\n",
    "    true_data  = sample[\"target\"]         # (T, 3, H, W)  torch.Tensor\n",
    "    lengths    = sample[\"lengths\"]        # (1,)          torch.Tensor\n",
    "\n",
    "    print(true_data.shape)\n",
    "\n",
    "    # 2) 推理\n",
    "    with torch.no_grad():\n",
    "        pred_batch = newmodel(\n",
    "            input_data.unsqueeze(0).to(device0),  # (1, T, 3, H, W)\n",
    "            lengths.to(device0)\n",
    "        )\n",
    "    pred_data = pred_batch.cpu().numpy()[0]       # (T, 3, H, W)\n",
    "    true_data_np = true_data.cpu().numpy()        # (T, 3, H, W)\n",
    "\n",
    "    # 3) 按通道处理\n",
    "    for channel_idx, channel_name in enumerate([\"Bx\", \"By\", \"Bz\"]):\n",
    "        pred_cube  = pred_data[:, channel_idx, :, :]    # (T, H, W)\n",
    "        true_cube  = true_data_np[:, channel_idx, :, :]\n",
    "\n",
    "        # --- 保存 npy ---\n",
    "        np.save(\n",
    "            os.path.join(npy_dir, f\"sample_{sample_idx}_{channel_name}_pred.npy\"),\n",
    "            pred_cube\n",
    "        )\n",
    "\n",
    "        # --- 计算指标 ---\n",
    "        y_true = true_cube.flatten()\n",
    "        y_pred = pred_cube.flatten()\n",
    "        \n",
    "\n",
    "        r2_val   = r2_score(y_true, y_pred)\n",
    "        mse_val  = mean_squared_error(y_true, y_pred)\n",
    "        mae_val  = mean_absolute_error(y_true, y_pred)\n",
    "        zeroarr = np.zeros(y_true.shape)\n",
    "        re_val   = mean_relative_error(y_true, y_pred, zeroarr)\n",
    "        psnr_val = compute_psnr(true_cube, pred_cube)\n",
    "        ssim_val = compute_ssim_cube(true_cube, pred_cube)\n",
    "\n",
    "        rows.append({\n",
    "            \"sample\":  sample_idx,\n",
    "            \"channel\": channel_name,\n",
    "            \"R2\":      r2_val,\n",
    "            \"MSE\":     mse_val,\n",
    "            \"MAE\":     mae_val,\n",
    "            \"RE\":      re_val,\n",
    "            \"PSNR\":    psnr_val,\n",
    "            \"SSIM\":    ssim_val\n",
    "        })\n",
    "\n",
    "        print(f\"[Sample {sample_idx} - {channel_name}] \"\n",
    "              f\"R2={r2_val:.4f}, MSE={mse_val:.3e}, MAE={mae_val:.3e}, \"\n",
    "              f\"RE={re_val:.4f}, PSNR={psnr_val:.2f}, SSIM={ssim_val:.4f}\")\n",
    "\n",
    "# 4) 保存 CSV\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "print(f\"\\n✓ 所有指标已保存到 {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673539a6-8cbb-4fe7-a0c6-c64bbd90d9ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
