{
 "cells": [
  {
   "cell_type": "code",
   "id": "25bb1acb-d746-421a-b836-0de18bf2c716",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from neuralop.models.fno import TFNO\n",
    "from neuralop.models.fno import TFNO3d\n",
    "from neuralop.training.trainer import Trainer\n",
    "from neuralop.utils import count_model_params\n",
    "from neuralop.losses.data_losses import LpLoss, H1Loss\n",
    "import pdb\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "from astropy.io import fits\n",
    "from torch.utils.data.dataset import Subset\n",
    "import random\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import Subset\n",
    "from torchvision.transforms.functional import normalize\n",
    "from matplotlib.animation import FuncAnimation, FFMpegWriter\n",
    "from IPython.display import HTML\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import random_split\n",
    "import h5py\n",
    "import torch.nn as nn\n",
    "import time\n",
    "\n",
    "device0 = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "#device1 = torch.device('cuda:1' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "print(device0)\n",
    "#print(device1)\n",
    "\n",
    "from functools import partialmethod\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from neuralop.layers.spectral_convolution import SpectralConv\n",
    "from neuralop.layers.padding import DomainPadding\n",
    "from neuralop.layers.fno_block import FNOBlocks\n",
    "from neuralop.layers.mlp import MLP\n",
    "from neuralop.models.base_model import BaseModel"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "76f62935-4f49-4f88-b61e-a27e0adf6eba",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import h5py\n",
    "import pandas as pd\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(\n",
    "        self, \n",
    "        hdf5_file_paths, \n",
    "        x_lengths, \n",
    "        y_lengths, \n",
    "        z_lengths, \n",
    "        excel_path\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            hdf5_file_paths (list): List of paths to the HDF5 files [Bx_file, By_file, Bz_file].\n",
    "            x_lengths, y_lengths, z_lengths (np.ndarray): Arrays of lengths (1D).\n",
    "            excel_path (str): Path to the Excel file containing NOAA AR, date, and type.\n",
    "        \"\"\"\n",
    "        # 1) Store HDF5 file paths and open the files\n",
    "        self.hdf5_file_paths = hdf5_file_paths\n",
    "        self.hdf5_files = [h5py.File(path, 'r') for path in self.hdf5_file_paths]\n",
    "        \n",
    "        # 2) Store lengths\n",
    "        self.x_lengths = x_lengths\n",
    "        self.y_lengths = y_lengths\n",
    "        self.z_lengths = z_lengths\n",
    "        \n",
    "        # 3) Read Excel file to get the NOAA AR, date, and type\n",
    "        df = pd.read_excel(excel_path)\n",
    "        \n",
    "        # Make sure the rows in 'df' match the exact order of samples in HDF5\n",
    "        # If you need to sort the DataFrame, do it here, e.g.:\n",
    "        # df = df.sort_values(by='date')  # or by 'NOAA AR', etc.\n",
    "        # df = df.reset_index(drop=True)\n",
    "\n",
    "        # Just store the raw type strings:\n",
    "        self.type_labels_str = df['type'].astype(str).values\n",
    "        \n",
    "        # 4) Assume all HDF5 files have the same number of samples\n",
    "        self.dataset_length = len(self.hdf5_files[0])\n",
    "        \n",
    "        # 5) Calculate means and stds for normalization\n",
    "        self.x_mean = np.mean(self.x_lengths)\n",
    "        self.x_std = np.std(self.x_lengths)\n",
    "\n",
    "        self.y_mean = np.mean(self.y_lengths)\n",
    "        self.y_std = np.std(self.y_lengths)\n",
    "\n",
    "        self.z_mean = np.mean(self.z_lengths)\n",
    "        self.z_std = np.std(self.z_lengths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.dataset_length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # ---------------------\n",
    "        # 1) Read input arrays\n",
    "        # ---------------------\n",
    "        input_data_x = torch.from_numpy(\n",
    "            self.hdf5_files[0][f'sample_{idx}/input'][:]\n",
    "        ).float()\n",
    "        input_data_y = torch.from_numpy(\n",
    "            self.hdf5_files[1][f'sample_{idx}/input'][:]\n",
    "        ).float()\n",
    "        input_data_z = torch.from_numpy(\n",
    "            self.hdf5_files[2][f'sample_{idx}/input'][:]\n",
    "        ).float()\n",
    "\n",
    "        # ----------------------\n",
    "        # 2) Read output arrays\n",
    "        # ----------------------\n",
    "        output_data_x = torch.from_numpy(\n",
    "            self.hdf5_files[0][f'sample_{idx}/output'][:]\n",
    "        ).float()\n",
    "        output_data_y = torch.from_numpy(\n",
    "            self.hdf5_files[1][f'sample_{idx}/output'][:]\n",
    "        ).float()\n",
    "        output_data_z = torch.from_numpy(\n",
    "            self.hdf5_files[2][f'sample_{idx}/output'][:]\n",
    "        ).float()\n",
    "\n",
    "        # ------------------------------------\n",
    "        # 3) Select some subset of output data\n",
    "        # ------------------------------------\n",
    "        selected_output_data_x = output_data_x[:25]\n",
    "        selected_output_data_y = output_data_y[:25]\n",
    "        selected_output_data_z = output_data_z[:25]\n",
    "\n",
    "        # ------------------------------------\n",
    "        # 4) Stack inputs into multi-channel\n",
    "        # ------------------------------------\n",
    "        input_data = torch.stack(\n",
    "            (input_data_x, input_data_y, input_data_z), dim=0\n",
    "        ).unsqueeze(0)\n",
    "\n",
    "        # ------------------------------------\n",
    "        # 5) Stack selected outputs\n",
    "        # ------------------------------------\n",
    "        output_data = torch.stack(\n",
    "            (selected_output_data_x, selected_output_data_y, selected_output_data_z), \n",
    "            dim=1\n",
    "        )\n",
    "\n",
    "        # ------------------------------------\n",
    "        # 6) Normalize lengths\n",
    "        # ------------------------------------\n",
    "        x_length_normalized = (self.x_lengths[idx] - self.x_mean) / self.x_std\n",
    "        y_length_normalized = (self.y_lengths[idx] - self.y_mean) / self.y_std\n",
    "        z_length_normalized = (self.z_lengths[idx] - self.z_mean) / self.z_std\n",
    "        \n",
    "        length_tensor = torch.tensor(\n",
    "            [x_length_normalized, y_length_normalized, z_length_normalized],\n",
    "            dtype=torch.float32\n",
    "        ).unsqueeze(0)\n",
    "\n",
    "        # ------------------------------------\n",
    "        # 7) Get the string label from Excel\n",
    "        # ------------------------------------\n",
    "        type_label_str = self.type_labels_str[idx]\n",
    "        # This remains a Python string. If you only need to read it\n",
    "        # later for grouping or analysis, you can just store it in the sample dict. \n",
    "        # (If you need it as a tensor, you can store it as an object \n",
    "        #  but note that PyTorch won't do much with it for training.)\n",
    "\n",
    "        sample = {\n",
    "            'input': input_data,      # shape: (1, 3, H, W) or similar\n",
    "            'output': output_data,    # shape: (N, 3) depending on your slicing\n",
    "            'lengths': length_tensor, # shape: (1, 3)\n",
    "            'type_label_str': type_label_str,  # e.g. 'β' or 'βγ'\n",
    "        }\n",
    "        return sample\n",
    "\n",
    "\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "# HDF5 file paths\n",
    "input1 = \"NLFFF_data/NLFFF_Bx_rmns_100.h5\"\n",
    "input2 = \"NLFFF_data/NLFFF_By_rmns_100.h5\"\n",
    "input3 = \"NLFFF_data/NLFFF_Bz_rmns_10.h5\"\n",
    "\n",
    "# NumPy length arrays\n",
    "x_lengths = np.load(\"NLFFF_data/x_height.npy\")\n",
    "y_lengths = np.load(\"NLFFF_data/y_height.npy\")\n",
    "z_lengths = np.load(\"NLFFF_data/z_height.npy\")\n",
    "\n",
    "# Excel path\n",
    "excel_path = \"NLFFF_data/NLFFF_datatype.xlsx\"\n",
    "\n",
    "# Initialize dataset\n",
    "dataset = CustomDataset(\n",
    "    [input1, input2, input3],\n",
    "    x_lengths,\n",
    "    y_lengths,\n",
    "    z_lengths,\n",
    "    excel_path\n",
    ")\n",
    "\n",
    "train_size = 143\n",
    "test_size = 27\n",
    "\n",
    "train_dataset = Subset(dataset, range(train_size))\n",
    "test_dataset = Subset(dataset, range(train_size, train_size + test_size))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=8, persistent_workers=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=8, persistent_workers=False)\n",
    "\n",
    "for batch in train_loader:\n",
    "    inputs = batch['input']\n",
    "    outputs = batch['output']\n",
    "    lengths = batch['lengths']\n",
    "    type_strings = batch['type_label_str']\n",
    "\n",
    "print(inputs.shape)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e7b53021-63da-4cd2-8943-7804075b6165",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PhysicsInformedLoss(nn.Module):\n",
    "    def __init__(self, weight=0.35, alpha=1.0, beta=1.0, gamma=1.0):\n",
    "        super(PhysicsInformedLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.alpha = alpha  \n",
    "        self.beta = beta    \n",
    "        self.gamma = gamma  \n",
    "\n",
    "    def forward(self, output, target): \n",
    "        divergence_loss = self.compute_divergence_loss(output)\n",
    "\n",
    "        force_free_loss = self.compute_force_free_loss(output)\n",
    "\n",
    "        total_loss = self.weight * ((self.beta * divergence_loss) + \\\n",
    "                     (self.gamma * force_free_loss))\n",
    "        return total_loss\n",
    "\n",
    "    def compute_divergence_loss(self, output):\n",
    "        batch_size, depth, components, height, width = output.shape\n",
    "        B = output.permute(0, 2, 1, 3, 4)  # B: [batch_size, 3, depth, height, width]\n",
    "        channels = components\n",
    "\n",
    "        device = output.device\n",
    "\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "        kernel_dx = kernel_dx.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(channels, 1, 1, 1, 1)\n",
    "\n",
    "        dB_dx = F.conv3d(B, kernel_dx, padding=(0, 0, 1), groups=channels)\n",
    "        dB_dy = F.conv3d(B, kernel_dy, padding=(0, 1, 0), groups=channels)\n",
    "        dB_dz = F.conv3d(B, kernel_dz, padding=(1, 0, 0), groups=channels)\n",
    "\n",
    "        # dB_x/dx\n",
    "        dB_x_dx = dB_dx[:, 0, :, :, :]\n",
    "        # dB_y/dy\n",
    "        dB_y_dy = dB_dy[:, 1, :, :, :]\n",
    "        # dB_z/dz\n",
    "        dB_z_dz = dB_dz[:, 2, :, :, :]\n",
    "\n",
    "\n",
    "        divergence = dB_x_dx + dB_y_dy + dB_z_dz\n",
    "        divergence_loss = torch.mean(divergence ** 2)\n",
    "\n",
    "        return divergence_loss\n",
    "\n",
    "    def compute_force_free_loss(self, output):\n",
    "        batch_size, depth, components, height, width = output.shape\n",
    "        B = output.permute(0, 2, 1, 3, 4)  # B: [batch_size, 3, depth, height, width]\n",
    "        channels = components  \n",
    "\n",
    "        device = output.device\n",
    "\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "\n",
    "        kernel_dx = kernel_dx.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(channels, 1, 1, 1, 1)\n",
    "\n",
    "        dB_dx = F.conv3d(B, kernel_dx, padding=(0, 0, 1), groups=channels)\n",
    "        dB_dy = F.conv3d(B, kernel_dy, padding=(0, 1, 0), groups=channels)\n",
    "        dB_dz = F.conv3d(B, kernel_dz, padding=(1, 0, 0), groups=channels)\n",
    "\n",
    "        dB_x_dy = dB_dy[:, 0, :, :, :]\n",
    "        dB_x_dz = dB_dz[:, 0, :, :, :]\n",
    "\n",
    "        dB_y_dx = dB_dx[:, 1, :, :, :]\n",
    "        dB_y_dz = dB_dz[:, 1, :, :, :]\n",
    "\n",
    "        dB_z_dx = dB_dx[:, 2, :, :, :]\n",
    "        dB_z_dy = dB_dy[:, 2, :, :, :]\n",
    "\n",
    "        rot_x = dB_z_dy - dB_y_dz\n",
    "        rot_y = dB_x_dz - dB_z_dx\n",
    "        rot_z = dB_y_dx - dB_x_dy\n",
    "\n",
    "        j = torch.stack([rot_x, rot_y, rot_z], dim=1)\n",
    "        jxb = torch.cross(j, B, dim=1)\n",
    "        B_magnitude_squared = torch.sum(B ** 2, dim=1, keepdim=True) + 1e-7\n",
    "        force_free_loss = torch.mean(torch.sum(jxb ** 2, dim=1) / B_magnitude_squared.squeeze(1))\n",
    "\n",
    "        return force_free_loss\n",
    "\n",
    "\n",
    "class ECA3DLayer(nn.Module):\n",
    "    def __init__(self, channel, k_size=3):\n",
    "        super(ECA3DLayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, channels, seq_len, height, width]\n",
    "        \n",
    "        # Global average pooling across seq_len, height, width\n",
    "        y = self.avg_pool(x)  # Shape: [batch_size, channels, 1, 1, 1]\n",
    "\n",
    "        # Apply 1D convolution across the channel dimension\n",
    "        y = self.conv(y.squeeze(-1).squeeze(-1).transpose(-1, -2))  # Shape: [batch_size, 1, channels]\n",
    "        y = y.transpose(-1, -2).unsqueeze(-1).unsqueeze(-1)  # Shape: [batch_size, channels, 1, 1, 1]\n",
    "\n",
    "        # Apply attention to input\n",
    "        return x * self.sigmoid(y).expand_as(x)\n",
    "\n",
    "class DilatedConvYWithECA(nn.Module):\n",
    "    def __init__(self, channels, dilation_y=2, k_size=3):\n",
    "        super(DilatedConvYWithECA, self).__init__()\n",
    "        self.conv = nn.Conv3d(\n",
    "            in_channels=channels,\n",
    "            out_channels=channels,\n",
    "            kernel_size=(1, 3, 1),  \n",
    "            padding=(0, dilation_y, 0),  \n",
    "            dilation=(1, dilation_y, 1),\n",
    "            bias=False\n",
    "        )\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        # ECA Attention layer\n",
    "        self.eca = ECA3DLayer(channel=channels, k_size=k_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply dilated convolution\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Apply ECA attention\n",
    "        x = self.eca(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# CustomFNO Model with ECA-Net applied to lengths_lifted\n",
    "class CustomFNO(BaseModel, name='CustomFNO'):\n",
    "    def __init__(self, n_modes, hidden_channels, in_channels=3, out_channels=1,\n",
    "                 lifting_channels=256, projection_channels=256, n_layers=4,\n",
    "                 output_scaling_factor=None, max_n_modes=None,\n",
    "                 fno_block_precision=\"full\", use_mlp=False, mlp_dropout=0,\n",
    "                 mlp_expansion=0.5, non_linearity=F.gelu, stabilizer=None,\n",
    "                 norm=None, preactivation=False, fno_skip=\"linear\",\n",
    "                 mlp_skip=\"soft-gating\", separable=False, factorization=None,\n",
    "                 rank=1.0, joint_factorization=False, fixed_rank_modes=False,\n",
    "                 implementation=\"factorized\", decomposition_kwargs=dict(),\n",
    "                 domain_padding=None, domain_padding_mode=\"one-sided\",\n",
    "                 fft_norm=\"forward\", SpectralConv=SpectralConv,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.n_dim = len(n_modes)\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Define the lifting layers for two inputs\n",
    "        self.lifting1 = MLP(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            hidden_channels=lifting_channels,\n",
    "            n_layers=2,\n",
    "            n_dim=self.n_dim,\n",
    "        )\n",
    "        \n",
    "        self.lifting_y = MLP(\n",
    "            in_channels=3,  \n",
    "            out_channels=hidden_channels,\n",
    "            hidden_channels=lifting_channels,\n",
    "            n_layers=2,\n",
    "            n_dim=1,\n",
    "        )\n",
    "\n",
    "        # Define the ECA-Net block for lengths_lifted\n",
    "        self.DilatedConvYWithECA = DilatedConvYWithECA(hidden_channels, dilation_y=2)\n",
    "\n",
    "        # Define the FNO blocks\n",
    "        self.fno_blocks = FNOBlocks(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            n_modes=n_modes,\n",
    "            output_scaling_factor=output_scaling_factor,\n",
    "            use_mlp=use_mlp,\n",
    "            mlp_dropout=mlp_dropout,\n",
    "            mlp_expansion=mlp_expansion,\n",
    "            non_linearity=non_linearity,\n",
    "            stabilizer=stabilizer,\n",
    "            norm=norm,\n",
    "            preactivation=preactivation,\n",
    "            fno_skip=fno_skip,\n",
    "            mlp_skip=mlp_skip,\n",
    "            max_n_modes=max_n_modes,\n",
    "            fno_block_precision=fno_block_precision,\n",
    "            rank=rank,\n",
    "            fft_norm=fft_norm,\n",
    "            fixed_rank_modes=fixed_rank_modes,\n",
    "            implementation=implementation,\n",
    "            separable=separable,\n",
    "            factorization=factorization,\n",
    "            decomposition_kwargs=decomposition_kwargs,\n",
    "            joint_factorization=joint_factorization,\n",
    "            SpectralConv=SpectralConv,\n",
    "            n_layers=n_layers,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        # Define the projection layer\n",
    "        self.projection = MLP(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=out_channels,\n",
    "            hidden_channels=projection_channels,\n",
    "            n_layers=2,\n",
    "            n_dim=self.n_dim,\n",
    "            non_linearity=non_linearity,\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, lengths):\n",
    "        \"\"\"Forward pass for the Custom FNO model.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x1 : tensor\n",
    "            Input tensor of shape [batch_size, 1, 3, 257, 513]\n",
    "        lengths : tensor\n",
    "            Tensor containing the normalized lengths of shape [batch_size, 1, 3]\n",
    "        \"\"\"\n",
    "        x_orig = x1.clone()\n",
    "        \n",
    "        # Apply lifting to the input\n",
    "        x1 = self.lifting1(x1)  # Result shape: [batch_size, hidden_channels, 3, 257, 513]\n",
    "\n",
    "        # Reshape lengths for processing\n",
    "        lengths = lengths.view(-1, 3, 1)  # Shape [batch_size, 3, 1] for processing\n",
    "\n",
    "        # Process lengths through lifting\n",
    "        lengths_lifted = self.lifting_y(lengths)  # Result shape: [batch_size, hidden_channels, 3]\n",
    "        \n",
    "        # Reshape lengths_lifted to match the spatial dimensions of x1\n",
    "        lengths_lifted = lengths_lifted.unsqueeze(-1).unsqueeze(-1)  # Shape: [batch_size, hidden_channels, 3, 1, 1]\n",
    "\n",
    "        # Apply ECA-Net block to lengths_lifted before adding to x1\n",
    "        lengths_lifted = self.DilatedConvYWithECA(lengths_lifted)\n",
    "\n",
    "        # Apply lengths_lifted to x1 (add)\n",
    "        x1 = x1 + lengths_lifted\n",
    "\n",
    "        # Apply FNO blocks\n",
    "        for layer_idx in range(self.n_layers):\n",
    "            x1 = self.fno_blocks(x1, layer_idx)\n",
    "\n",
    "        # Apply projection layer\n",
    "        x1 = self.projection(x1)\n",
    "\n",
    "        x1[:, 0, :, :, :] = x_orig[:, 0, :, :, :]\n",
    "\n",
    "        return x1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "e6b21e8e-0322-4102-8577-7282014ef71d",
   "metadata": {},
   "source": [
    "model = CustomFNO(n_modes = (32, 32, 32), in_channels=1, out_channels=25, n_layers = 6,\n",
    "               hidden_channels=32, use_mlp=True, factorization='tucker', rank=0.2)\n",
    "model = model.to(device0)\n",
    "\n",
    "n_params = count_model_params(model)\n",
    "print(f'\\nYour model has {n_params} parameters.')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4) \n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=1, verbose=True)\n",
    "\n",
    "h1loss = H1Loss(d=2)\n",
    "print(model)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9e71eef4-7a9c-4ba0-8172-72de62716b66",
   "metadata": {},
   "source": [
    "def l2_loss(pred, target):\n",
    "    return F.mse_loss(pred, target, reduction='mean')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "391856a6-948e-428c-bd54-eddd24744a7b",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "num_epochs = 150\n",
    "print_frequency = 40\n",
    "save_checkpoint_start_epoch = 50\n",
    "save_checkpoint_interval = 10\n",
    "checkpoint_dir = \"result/NLFFF_Cube2Step/step1\"\n",
    "results_file = os.path.join(checkpoint_dir, \"result.csv\")\n",
    "physics_loss_fn = PhysicsInformedLoss(weight=0.35, alpha=1.0, beta=1, gamma=1)\n",
    "\n",
    "# 准备CSV文件\n",
    "with open(results_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['epoch', 'comp', 'r2', 'relative_error', 'mse', 'mae', 'psnr', 'ssim'])\n",
    "\n",
    "train_losses_Bx = []\n",
    "train_losses_By = []\n",
    "train_losses_Bz = []\n",
    "test_losses_Bx = []\n",
    "test_losses_By = []\n",
    "test_losses_Bz = []\n",
    "physics_losses = []\n",
    "epoch_durations = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss_Bx = 0.0\n",
    "    epoch_loss_By = 0.0\n",
    "    epoch_loss_Bz = 0.0\n",
    "    epoch_physics_loss = 0.0\n",
    "\n",
    "    train_loader_tqdm = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Train Epoch {epoch+1}/{num_epochs}')\n",
    "    for batch_idx, sample in train_loader_tqdm:\n",
    "        optimizer.zero_grad()\n",
    "        data, target = sample['input'].to(device0), sample['output'].to(device0)\n",
    "        lengths = sample['lengths'].to(device0)  \n",
    "\n",
    "        output = model(data, lengths)\n",
    "\n",
    "        loss_Bx = h1loss(output[:, :, 0, :, :], target[:, :, 0, :, :]).mean()\n",
    "        loss_By = h1loss(output[:, :, 1, :, :], target[:, :, 1, :, :]).mean()\n",
    "        loss_Bz = h1loss(output[:, :, 2, :, :], target[:, :, 2, :, :]).mean()\n",
    "\n",
    "        physics_loss = physics_loss_fn(output, target)\n",
    "            \n",
    "        total_loss = loss_Bx + loss_By + loss_Bz + physics_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss_Bx += loss_Bx.item()\n",
    "        epoch_loss_By += loss_By.item()\n",
    "        epoch_loss_Bz += loss_Bz.item()\n",
    "        epoch_physics_loss += physics_loss.item()\n",
    "\n",
    "        if batch_idx % print_frequency == 0:\n",
    "            train_loader_tqdm.set_postfix(\n",
    "                loss_Bx=loss_Bx.item(),\n",
    "                loss_By=loss_By.item(),\n",
    "                loss_Bz=loss_Bz.item(),\n",
    "                physics_loss=physics_loss.item()\n",
    "            )\n",
    "\n",
    "    avg_loss_Bx = epoch_loss_Bx / len(train_loader)\n",
    "    avg_loss_By = epoch_loss_By / len(train_loader)\n",
    "    avg_loss_Bz = epoch_loss_Bz / len(train_loader)\n",
    "    avg_physics_loss = epoch_physics_loss / len(train_loader)\n",
    "\n",
    "    train_losses_Bx.append(avg_loss_Bx)\n",
    "    train_losses_By.append(avg_loss_By)\n",
    "    train_losses_Bz.append(avg_loss_Bz)\n",
    "    physics_losses.append(avg_physics_loss)\n",
    "\n",
    "    model.eval()\n",
    "    epoch_r2_Bx = []\n",
    "    epoch_r2_By = []\n",
    "    epoch_r2_Bz = []\n",
    "    test_loader_tqdm = tqdm(test_loader, total=len(test_loader), desc=f'Test Epoch {epoch+1}/{num_epochs}')\n",
    "    with torch.no_grad():\n",
    "        for sample in test_loader_tqdm:\n",
    "            x = sample['input'].to(device0)\n",
    "            lengths = sample['lengths'].to(device0)  \n",
    "            target = sample['output'].cpu().numpy()\n",
    "            output = model(x, lengths).cpu().numpy()\n",
    "\n",
    "            for true_sample, pred_sample in zip(target, output):\n",
    "                r2_Bx = r2_score(true_sample[:, 0].flatten(), pred_sample[:, 0].flatten())\n",
    "                r2_By = r2_score(true_sample[:, 1].flatten(), pred_sample[:, 1].flatten())\n",
    "                r2_Bz = r2_score(true_sample[:, 2].flatten(), pred_sample[:, 2].flatten())\n",
    "\n",
    "                epoch_r2_Bx.append(r2_Bx)\n",
    "                epoch_r2_By.append(r2_By)\n",
    "                epoch_r2_Bz.append(r2_Bz)\n",
    "\n",
    "    avg_r2_Bx = np.mean(epoch_r2_Bx)\n",
    "    avg_r2_By = np.mean(epoch_r2_By)\n",
    "    avg_r2_Bz = np.mean(epoch_r2_Bz)\n",
    "\n",
    "    test_losses_Bx.append(avg_r2_Bx)\n",
    "    test_losses_By.append(avg_r2_By)\n",
    "    test_losses_Bz.append(avg_r2_Bz)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    epoch_durations.append(epoch_duration)\n",
    "\n",
    "    avg_train_loss_combined = (avg_loss_Bx + avg_loss_By + avg_loss_Bz + avg_physics_loss) / 3\n",
    "    scheduler.step(avg_train_loss_combined)\n",
    "\n",
    "    avg_epoch_duration = np.mean(epoch_durations)\n",
    "    remaining_epochs = num_epochs - (epoch + 1)\n",
    "    remaining_time = remaining_epochs * avg_epoch_duration\n",
    "    hours, rem = divmod(remaining_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}, Duration: {epoch_duration:.2f}s, '\n",
    "          f'Train Loss - Bx: {avg_loss_Bx:.4f}, By: {avg_loss_By:.4f}, Bz: {avg_loss_Bz:.4f}, Physics Loss: {avg_physics_loss:.4f}, '\n",
    "          f'Test R2 - Bx: {avg_r2_Bx:.4f}, By: {avg_r2_By:.4f}, Bz: {avg_r2_Bz:.4f}')\n",
    "\n",
    "    print(f'Estimated Remaining Time: {int(hours)}h {int(minutes)}m {int(seconds)}s')\n",
    "\n",
    "    if (epoch + 1) >= save_checkpoint_start_epoch and (epoch + 1) % save_checkpoint_interval == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pt\")\n",
    "        torch.save(model.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}: {checkpoint_path}\")\n",
    "\n",
    "        min_val = float('inf')\n",
    "        max_val = float('-inf')\n",
    "        for sample in test_loader:\n",
    "            y_true_batch = sample['output'].numpy()\n",
    "            batch_min = y_true_batch.min()\n",
    "            batch_max = y_true_batch.max()\n",
    "            min_val = min(min_val, batch_min)\n",
    "            max_val = max(max_val, batch_max)\n",
    "        data_range = max_val - min_val\n",
    "        print(f\"[INFO] data_range = {data_range} (max_val={max_val}, min_val={min_val})\")\n",
    "\n",
    "        type_performance = {}\n",
    "\n",
    "        sample_r2_scores = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_relative_errors = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_mses = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_maes = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_psnr_values = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_ssim_values = {'bx': [], 'by': [], 'bz': []}\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for sample in test_loader:\n",
    "                x = sample['input'].to(device0)\n",
    "                lengths = sample['lengths'].to(device0)  \n",
    "                y_true_batch = sample['output'].cpu().numpy()\n",
    "                y_pred_batch = model(x, lengths).cpu().numpy()\n",
    "\n",
    "                for true_sample, pred_sample in zip(y_true_batch, y_pred_batch):\n",
    "                    for i, comp in enumerate(['bx', 'by', 'bz']):\n",
    "                        true_sample_component = true_sample[:, i]\n",
    "                        pred_sample_component = pred_sample[:, i]\n",
    "\n",
    "                        true_sample_flat = true_sample_component.flatten()\n",
    "                        pred_sample_flat = pred_sample_component.flatten()\n",
    "\n",
    "                        r2 = r2_score(true_sample_flat, pred_sample_flat)\n",
    "                        sample_r2_scores[comp].append(r2)\n",
    "\n",
    "                        absolute_error = np.linalg.norm(true_sample_flat - pred_sample_flat, 1)\n",
    "                        relative_error = absolute_error / np.linalg.norm(true_sample_flat, 1)\n",
    "                        sample_relative_errors[comp].append(relative_error)\n",
    "\n",
    "                        mse = mean_squared_error(true_sample_flat, pred_sample_flat)\n",
    "                        sample_mses[comp].append(mse)\n",
    "\n",
    "                        mae = mean_absolute_error(true_sample_flat, pred_sample_flat)\n",
    "                        sample_maes[comp].append(mae)\n",
    "\n",
    "                        psnr_value = psnr(true_sample_component, pred_sample_component, data_range=data_range)\n",
    "                        sample_psnr_values[comp].append(psnr_value)\n",
    "\n",
    "                        ssim_value = ssim(true_sample_component, pred_sample_component, data_range=data_range)\n",
    "                        sample_ssim_values[comp].append(ssim_value)\n",
    "                        \n",
    "        with open(results_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for comp in ['bx', 'by', 'bz']:\n",
    "                writer.writerow([epoch+1, comp,\n",
    "                                 np.mean(sample_r2_scores[comp]),\n",
    "                                 np.mean(sample_relative_errors[comp]),\n",
    "                                 np.mean(sample_mses[comp]),\n",
    "                                 np.mean(sample_maes[comp]),\n",
    "                                 np.mean(sample_psnr_values[comp]),\n",
    "                                 np.mean(sample_ssim_values[comp])])\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for sample in test_loader:\n",
    "                x = sample['input'].to(device0)\n",
    "                lengths = sample['lengths'].to(device0)  \n",
    "                y_true_batch = sample['output'].cpu().numpy()\n",
    "                y_pred_batch = model(x, lengths).cpu().numpy()\n",
    "\n",
    "                type_labels = sample['type_label_str']  \n",
    "\n",
    "                for true_sample, pred_sample, t_str in zip(y_true_batch, y_pred_batch, type_labels):\n",
    "                    if t_str not in type_performance:\n",
    "                        type_performance[t_str] = {\n",
    "                            'bx': {'r2': [], 'mse': [], 'mae': [], 'psnr': [], 'ssim': [], 'rel_err': []},\n",
    "                            'by': {'r2': [], 'mse': [], 'mae': [], 'psnr': [], 'ssim': [], 'rel_err': []},\n",
    "                            'bz': {'r2': [], 'mse': [], 'mae': [], 'psnr': [], 'ssim': [], 'rel_err': []},\n",
    "                        }\n",
    "\n",
    "                    for i, comp in enumerate(['bx', 'by', 'bz']):\n",
    "                        true_comp = true_sample[:, i].flatten()\n",
    "                        pred_comp = pred_sample[:, i].flatten()\n",
    "                        r2_val = r2_score(true_comp, pred_comp)\n",
    "\n",
    "                        abs_err = np.linalg.norm(true_comp - pred_comp, 1)\n",
    "                        rel_err = abs_err / np.linalg.norm(true_comp, 1)\n",
    "\n",
    "                        mse_val = mean_squared_error(true_comp, pred_comp)\n",
    "\n",
    "                        mae_val = mean_absolute_error(true_comp, pred_comp)\n",
    "\n",
    "                        psnr_val = psnr(true_comp, pred_comp, data_range=data_range)\n",
    "                        ssim_val = ssim(\n",
    "                            true_comp,\n",
    "                            pred_comp,\n",
    "                            data_range=data_range\n",
    "                        )\n",
    "\n",
    "                        metrics = type_performance[t_str][comp]\n",
    "                        metrics['r2'].append(r2_val)\n",
    "                        metrics['rel_err'].append(rel_err)\n",
    "                        metrics['mse'].append(mse_val)\n",
    "                        metrics['mae'].append(mae_val)\n",
    "                        metrics['psnr'].append(psnr_val)\n",
    "                        metrics['ssim'].append(ssim_val)\n",
    "                        \n",
    "        avg_type_performance = {}\n",
    "        for t_str, comp_dict in type_performance.items():\n",
    "            avg_type_performance[t_str] = {}\n",
    "            for comp in ['bx', 'by', 'bz']:\n",
    "                avg_type_performance[t_str][comp] = {\n",
    "                    'r2':    np.mean(comp_dict[comp]['r2']),\n",
    "                    'mse':   np.mean(comp_dict[comp]['mse']),\n",
    "                    'mae':   np.mean(comp_dict[comp]['mae']),\n",
    "                    'psnr':  np.mean(comp_dict[comp]['psnr']),\n",
    "                    'ssim':  np.mean(comp_dict[comp]['ssim']),\n",
    "                    'rel_err': np.mean(comp_dict[comp]['rel_err']),\n",
    "                }\n",
    "\n",
    "        all_types = sorted(avg_type_performance.keys())\n",
    "        comps = ['bx', 'by', 'bz']\n",
    "        \n",
    "        scores_by_comp = []\n",
    "        for comp in comps:\n",
    "            comp_scores = [avg_type_performance[t][comp]['r2'] for t in all_types]\n",
    "            scores_by_comp.append(comp_scores)\n",
    "        scores_by_comp = np.array(scores_by_comp)  # shape: (3, n_types)\n",
    "\n",
    "        plt.figure(figsize=(10,6))\n",
    "        bar_width = 0.25\n",
    "        x = np.arange(len(all_types))\n",
    "\n",
    "        for i, comp in enumerate(comps):\n",
    "            plt.bar(\n",
    "                x + i*bar_width, \n",
    "                scores_by_comp[i], \n",
    "                width=bar_width, \n",
    "                label=comp.upper()\n",
    "            )\n",
    "\n",
    "        plt.xticks(x + bar_width, all_types, rotation=45)\n",
    "        plt.ylabel('R2 Score')\n",
    "        \n",
    "\n",
    "        ax = plt.gca()\n",
    "\n",
    "        ax.yaxis.set_major_formatter(ticker.FormatStrFormatter('%.4f'))\n",
    "\n",
    "        plt.title(f'Comparison of R2 by Type (Epoch {epoch+1})')\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plot_path = os.path.join(checkpoint_dir, f\"R2_bar_chart_epoch_{epoch+1}.png\")\n",
    "        plt.savefig(plot_path)\n",
    "        plt.close()\n",
    "        print(f\"Grouped Bar Chart saved: {plot_path}\")\n",
    "\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses_Bx.npy'), np.array(train_losses_Bx))\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses_By.npy'), np.array(train_losses_By))\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses_Bz.npy'), np.array(train_losses_Bz))\n",
    "np.save(os.path.join(checkpoint_dir, 'physics_losses.npy'), np.array(physics_losses))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses_Bx.npy'), np.array(test_losses_Bx))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses_By.npy'), np.array(test_losses_By))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses_Bz.npy'), np.array(test_losses_Bz))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses_Bx, label='Training Loss Bx', color='red')\n",
    "plt.plot(train_losses_By, label='Training Loss By', color='green')\n",
    "plt.plot(train_losses_Bz, label='Training Loss Bz', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses for Bx, By, Bz')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(test_losses_Bx, label='Testing R2 Bx', color='red')\n",
    "plt.plot(test_losses_By, label='Testing R2 By', color='green')\n",
    "plt.plot(test_losses_Bz, label='Testing R2 Bz', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.title('Testing R2 Scores for Bx, By, Bz')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "7a9f3dae-a438-4b02-810a-26fff7cd45a6",
   "metadata": {},
   "source": [
    "model.load_state_dict(torch.load(\"result/NLFFF_Cube2Step/step1/checkpoint_epoch_150.pt\"))\n",
    "model.eval() "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "46bd3aa6-515f-42c7-958f-dfaa55838aa1",
   "metadata": {},
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "all_output_Bx = []\n",
    "all_output_By = []\n",
    "all_output_Bz = []\n",
    "all_target_Bx = []\n",
    "all_target_By = []\n",
    "all_target_Bz = []\n",
    "\n",
    "for sample in train_loader:\n",
    "    input_data = sample['input'].to(device0)  \n",
    "    lengths = sample['lengths'].to(device0)  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data, lengths)\n",
    "\n",
    "    output_Bx = output[:, :, 0, :, :].cpu().numpy() \n",
    "    output_By = output[:, :, 1, :, :].cpu().numpy()\n",
    "    output_Bz = output[:, :, 2, :, :].cpu().numpy()  \n",
    "\n",
    "    target_Bx = sample['output'][:, :, 0, :, :].cpu().numpy()  \n",
    "    target_By = sample['output'][:, :, 1, :, :].cpu().numpy()  \n",
    "    target_Bz = sample['output'][:, :, 2, :, :].cpu().numpy() \n",
    "\n",
    "    all_output_Bx.append(output_Bx)\n",
    "    all_output_By.append(output_By)\n",
    "    all_output_Bz.append(output_Bz)\n",
    "\n",
    "    all_target_Bx.append(target_Bx)\n",
    "    all_target_By.append(target_By)\n",
    "    all_target_Bz.append(target_Bz)\n",
    "\n",
    "all_output_Bx = np.concatenate(all_output_Bx, axis=0)\n",
    "all_output_By = np.concatenate(all_output_By, axis=0)\n",
    "all_output_Bz = np.concatenate(all_output_Bz, axis=0)\n",
    "all_target_Bx = np.concatenate(all_target_Bx, axis=0)\n",
    "all_target_By = np.concatenate(all_target_By, axis=0)\n",
    "all_target_Bz = np.concatenate(all_target_Bz, axis=0)\n",
    "\n",
    "print(f'All Bx shape: {all_output_Bx.shape}')\n",
    "print(f'All By shape: {all_output_By.shape}')\n",
    "print(f'All Bz shape: {all_output_Bz.shape}')\n",
    "print(f'All target By shape: {all_target_By.shape}')\n",
    "\n",
    "all_test_output_Bx = []\n",
    "all_test_output_By = []\n",
    "all_test_output_Bz = []\n",
    "all_test_target_Bx = []\n",
    "all_test_target_By = []\n",
    "all_test_target_Bz = []\n",
    "\n",
    "\n",
    "for sample in test_loader:\n",
    "\n",
    "    input_data = sample['input'].to(device0) \n",
    "    lengths = sample['lengths'].to(device0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_data, lengths)\n",
    "\n",
    "    output_Bx = output[:, :, 0, :, :].cpu().numpy()\n",
    "    output_By = output[:, :, 1, :, :].cpu().numpy()\n",
    "    output_Bz = output[:, :, 2, :, :].cpu().numpy()  \n",
    "\n",
    "    target_Bx = sample['output'][:, :, 0, :, :].cpu().numpy()  \n",
    "    target_By = sample['output'][:, :, 1, :, :].cpu().numpy()  \n",
    "    target_Bz = sample['output'][:, :, 2, :, :].cpu().numpy()  \n",
    "\n",
    "    all_test_output_Bx.append(output_Bx)\n",
    "    all_test_output_By.append(output_By)\n",
    "    all_test_output_Bz.append(output_Bz)\n",
    "    all_test_target_Bx.append(target_Bx)\n",
    "    all_test_target_By.append(target_By)\n",
    "    all_test_target_Bz.append(target_Bz)\n",
    "\n",
    "all_test_output_Bx = np.concatenate(all_test_output_Bx, axis=0)\n",
    "all_test_output_By = np.concatenate(all_test_output_By, axis=0)\n",
    "all_test_output_Bz = np.concatenate(all_test_output_Bz, axis=0)\n",
    "all_test_target_Bx = np.concatenate(all_test_target_Bx, axis=0)\n",
    "all_test_target_By = np.concatenate(all_test_target_By, axis=0)\n",
    "all_test_target_Bz = np.concatenate(all_test_target_Bz, axis=0)\n",
    "\n",
    "combined_output_Bx = np.concatenate((all_output_Bx, all_test_output_Bx), axis=0)\n",
    "combined_output_By = np.concatenate((all_output_By, all_test_output_By), axis=0)\n",
    "combined_output_Bz = np.concatenate((all_output_Bz, all_test_output_Bz), axis=0)\n",
    "\n",
    "combined_target_Bx = np.concatenate((all_target_Bx, all_test_target_Bx), axis=0)\n",
    "combined_target_By = np.concatenate((all_target_By, all_test_target_By), axis=0)\n",
    "combined_target_Bz = np.concatenate((all_target_Bz, all_test_target_Bz), axis=0)\n",
    "\n",
    "print(f'All Test Bx shape: {combined_output_Bx.shape}')\n",
    "print(f'All Test By shape: {combined_output_By.shape}')\n",
    "print(f'All Test Bz shape: {combined_output_Bz.shape}')\n",
    "\n",
    "print(f'All Test target By shape: {combined_target_By.shape}')"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "ae85aac2-8602-462d-882e-2056e1476ae7",
   "metadata": {},
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "\n",
    "class NewCustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        Bx_data, By_data, Bz_data, \n",
    "        Bx_targets, By_targets, Bz_targets, \n",
    "        x_lengths, y_lengths, z_lengths,\n",
    "        type_labels=None\n",
    "    ):\n",
    "        \n",
    "        self.Bx_data = Bx_data\n",
    "        self.By_data = By_data\n",
    "        self.Bz_data = Bz_data\n",
    "\n",
    "        self.Bx_targets = Bx_targets\n",
    "        self.By_targets = By_targets\n",
    "        self.Bz_targets = Bz_targets\n",
    "        \n",
    "        self.x_lengths = x_lengths\n",
    "        self.y_lengths = y_lengths\n",
    "        self.z_lengths = z_lengths\n",
    "\n",
    "        self.x_mean = np.mean(self.x_lengths)\n",
    "        self.x_std = np.std(self.x_lengths)\n",
    "\n",
    "        self.y_mean = np.mean(self.y_lengths)\n",
    "        self.y_std = np.std(self.y_lengths)\n",
    "\n",
    "        self.z_mean = np.mean(self.z_lengths)\n",
    "        self.z_std = np.std(self.z_lengths)\n",
    "\n",
    "        self.type_labels = type_labels  \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.Bx_data.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        input_Bx = self.Bx_data[idx]  \n",
    "        input_By = self.By_data[idx]\n",
    "        input_Bz = self.Bz_data[idx]  \n",
    "\n",
    "        input_data = torch.stack((input_Bx, input_By, input_Bz), dim=1)  \n",
    "\n",
    "        target_Bx = self.Bx_targets[idx]\n",
    "        target_By = self.By_targets[idx]\n",
    "        target_Bz = self.Bz_targets[idx]\n",
    "\n",
    "        target_data = torch.stack((target_Bx, target_By, target_Bz), dim=1)\n",
    "\n",
    "        x_length = self.x_lengths[idx]\n",
    "        y_length = self.y_lengths[idx]\n",
    "        z_length = self.z_lengths[idx]\n",
    "\n",
    "        x_length_normalized = (x_length - self.x_mean) / self.x_std\n",
    "        y_length_normalized = (y_length - self.y_mean) / self.y_std\n",
    "        z_length_normalized = (z_length - self.z_mean) / self.z_std\n",
    "\n",
    "        length_tensor = torch.tensor(\n",
    "            [x_length_normalized, y_length_normalized, z_length_normalized],\n",
    "            dtype=torch.float32\n",
    "        ).unsqueeze(0)\n",
    "\n",
    "        type_label = None\n",
    "        if self.type_labels is not None:\n",
    "            type_label = self.type_labels[idx]\n",
    "        \n",
    "        sample = {\n",
    "            'input': input_data,           \n",
    "            'lengths': length_tensor,\n",
    "            'target': target_data\n",
    "        }\n",
    "\n",
    "        if type_label is not None:\n",
    "            sample['type_label'] = type_label  \n",
    "\n",
    "        return sample\n",
    "\n",
    "x_lengths = np.load(\"NLFFF_data/x_height.npy\")\n",
    "y_lengths = np.load(\"NLFFF_data/y_height.npy\")\n",
    "z_lengths = np.load(\"NLFFF_data/z_height.npy\")\n",
    "\n",
    "combined_output_Bx = torch.tensor(combined_output_Bx).float()\n",
    "combined_output_By = torch.tensor(combined_output_By).float()\n",
    "combined_output_Bz = torch.tensor(combined_output_Bz).float()\n",
    "\n",
    "combined_target_Bx = torch.tensor(combined_target_Bx).float()\n",
    "combined_target_By = torch.tensor(combined_target_By).float()\n",
    "combined_target_Bz = torch.tensor(combined_target_Bz).float()\n",
    "\n",
    "df = pd.read_excel(\"NLFFF_data/NLFFF_datatype.xlsx\")\n",
    "type_labels_from_excel = df[\"type\"].values\n",
    "\n",
    "dataset = NewCustomDataset(combined_output_Bx, combined_output_By, combined_output_Bz, combined_target_Bx, combined_target_By, combined_target_Bz, x_lengths, y_lengths, z_lengths, type_labels_from_excel)\n",
    "\n",
    "train_size = 143\n",
    "test_size = 27\n",
    "\n",
    "train_indices = list(range(train_size))\n",
    "test_indices = list(range(train_size, train_size + test_size))\n",
    "\n",
    "train_dataset = torch.utils.data.Subset(dataset, train_indices)\n",
    "test_dataset = torch.utils.data.Subset(dataset, test_indices)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10, shuffle=True, num_workers=8, persistent_workers=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10, shuffle=False, num_workers=8, persistent_workers=False)\n",
    "\n",
    "for batch in train_loader:\n",
    "    print(batch['input'].shape)  \n",
    "    print(batch['lengths'].shape)\n",
    "    print(batch['target'].shape)\n",
    "    break\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "940a3852-2c3c-4efb-800a-4cf2b2c498e4",
   "metadata": {},
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class PhysicsInformedLoss(nn.Module):\n",
    "    def __init__(self, \n",
    "                 weight=1.0, \n",
    "                 beta=1.0,    \n",
    "                 alpha=1.0,   \n",
    "                 gamma=1.0,   \n",
    "                 delta=1.0,   \n",
    "                 ):\n",
    "        \n",
    "        super(PhysicsInformedLoss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.beta = beta       \n",
    "        self.gamma = gamma    \n",
    "        self.delta = delta     \n",
    "        self.alpha = alpha     \n",
    "\n",
    "    def forward(self, output, target):\n",
    "\n",
    "        divergence_loss = self.compute_divergence_loss(output)\n",
    "        force_free_loss = self.compute_force_free_loss(output)\n",
    "        grad_diff_loss = self.compute_gradient_difference(output, target)\n",
    "        free_energy_loss = self.compute_free_energy_loss(output, target)\n",
    "\n",
    "        total_loss = self.weight * (\n",
    "            self.beta * divergence_loss +\n",
    "            self.gamma * force_free_loss +\n",
    "            self.alpha * free_energy_loss\n",
    "        )\n",
    "        return total_loss\n",
    "\n",
    "    def compute_divergence_loss(self, output):\n",
    "    \n",
    "        batch_size, depth, components, height, width = output.shape\n",
    "        B = output.permute(0, 2, 1, 3, 4)  # [batch_size, 3, depth, height, width]\n",
    "        channels = components  \n",
    "\n",
    "        device = output.device\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "\n",
    "        kernel_dx = kernel_dx.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(channels, 1, 1, 1, 1)\n",
    "\n",
    "        dB_dx = F.conv3d(B, kernel_dx, padding=(0, 0, 1), groups=channels)\n",
    "        dB_dy = F.conv3d(B, kernel_dy, padding=(0, 1, 0), groups=channels)\n",
    "        dB_dz = F.conv3d(B, kernel_dz, padding=(1, 0, 0), groups=channels)\n",
    "\n",
    "        dB_x_dx = dB_dx[:, 0, :, :, :]\n",
    "        dB_y_dy = dB_dy[:, 1, :, :, :]\n",
    "        dB_z_dz = dB_dz[:, 2, :, :, :]\n",
    "\n",
    "        divergence = dB_x_dx + dB_y_dy + dB_z_dz\n",
    "        divergence_loss = torch.mean(divergence ** 2)\n",
    "\n",
    "        return divergence_loss\n",
    "\n",
    "    def compute_force_free_loss(self, output):\n",
    "        # output: [batch_size, z, 3, y, x]\n",
    "        batch_size, depth, components, height, width = output.shape\n",
    "        B = output.permute(0, 2, 1, 3, 4)  # [batch_size, 3, depth, height, width]\n",
    "        channels = components\n",
    "\n",
    "        device = output.device\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "\n",
    "        kernel_dx = kernel_dx.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(channels, 1, 1, 1, 1)\n",
    "\n",
    "        dB_dx = F.conv3d(B, kernel_dx, padding=(0, 0, 1), groups=channels)\n",
    "        dB_dy = F.conv3d(B, kernel_dy, padding=(0, 1, 0), groups=channels)\n",
    "        dB_dz = F.conv3d(B, kernel_dz, padding=(1, 0, 0), groups=channels)\n",
    "\n",
    "        dB_x_dy = dB_dy[:, 0, :, :, :]\n",
    "        dB_x_dz = dB_dz[:, 0, :, :, :]\n",
    "        dB_y_dx = dB_dx[:, 1, :, :, :]\n",
    "        dB_y_dz = dB_dz[:, 1, :, :, :]\n",
    "        dB_z_dx = dB_dx[:, 2, :, :, :]\n",
    "        dB_z_dy = dB_dy[:, 2, :, :, :]\n",
    "\n",
    "        rot_x = dB_z_dy - dB_y_dz\n",
    "        rot_y = dB_x_dz - dB_z_dx\n",
    "        rot_z = dB_y_dx - dB_x_dy\n",
    "\n",
    "        j = torch.stack([rot_x, rot_y, rot_z], dim=1)\n",
    "\n",
    "        jxb = torch.cross(j, B, dim=1)\n",
    "\n",
    "        B_magnitude_squared = torch.sum(B ** 2, dim=1, keepdim=True) + 1e-7\n",
    "\n",
    "        force_free_loss = torch.mean(torch.sum(jxb ** 2, dim=1) / B_magnitude_squared.squeeze(1))\n",
    "        return force_free_loss\n",
    "\n",
    "    def compute_gradient_difference(self, output, target):\n",
    "        if target.shape != output.shape:\n",
    "            return torch.tensor(0.0, device=output.device)\n",
    "\n",
    "        batch_size, depth, components, height, width = output.shape\n",
    "        B_pred = output.permute(0, 2, 1, 3, 4)   # [batch_size, 3, depth, height, width]\n",
    "        B_true = target.permute(0, 2, 1, 3, 4)\n",
    "        channels = components\n",
    "\n",
    "        device = output.device\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "\n",
    "        kernel_dx = kernel_dx.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(channels, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(channels, 1, 1, 1, 1)\n",
    "\n",
    "        dBp_dx = F.conv3d(B_pred, kernel_dx, padding=(0, 0, 1), groups=channels)\n",
    "        dBp_dy = F.conv3d(B_pred, kernel_dy, padding=(0, 1, 0), groups=channels)\n",
    "        dBp_dz = F.conv3d(B_pred, kernel_dz, padding=(1, 0, 0), groups=channels)\n",
    "\n",
    "        dBt_dx = F.conv3d(B_true, kernel_dx, padding=(0, 0, 1), groups=channels)\n",
    "        dBt_dy = F.conv3d(B_true, kernel_dy, padding=(0, 1, 0), groups=channels)\n",
    "        dBt_dz = F.conv3d(B_true, kernel_dz, padding=(1, 0, 0), groups=channels)\n",
    "\n",
    "        grad_diff = (dBp_dx - dBt_dx)**2 + \\\n",
    "                    (dBp_dy - dBt_dy)**2 + \\\n",
    "                    (dBp_dz - dBt_dz)**2\n",
    "\n",
    "        loss_val = torch.mean(grad_diff)\n",
    "        return loss_val\n",
    "\n",
    "    def compute_free_energy_loss(self, output, target):\n",
    "    \n",
    "        if output.shape != target.shape:\n",
    "            return torch.tensor(0.0, device=output.device)\n",
    "\n",
    "        B_pred = output.permute(0, 2, 1, 3, 4)\n",
    "        B_true = target.permute(0, 2, 1, 3, 4)\n",
    "\n",
    "        B_diff = B_pred - B_true \n",
    "\n",
    "        B_diff_sq = (B_diff ** 2).sum(dim=(1,2,3,4))     \n",
    "        E_diff = B_diff_sq / (8.0 * math.pi)          \n",
    "\n",
    "        free_energy_loss = torch.mean(E_diff)/1e5\n",
    "\n",
    "        return free_energy_loss\n",
    "\n",
    "class singlePhysicsInformedDivergence_Loss(nn.Module):\n",
    "    def __init__(self, weight=1.0, alpha=1.0, beta=1.0, gamma=1.0):\n",
    "        super(singlePhysicsInformedDivergence_Loss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.alpha = alpha  \n",
    "        self.beta = beta    \n",
    "        self.gamma = gamma  \n",
    "\n",
    "    def forward(self, output, target): \n",
    "        loss = self.compute_single_slice_physics_loss(output)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def compute_single_slice_physics_loss(self, output_slice):\n",
    "\n",
    "        batch_size, components, height, width = output_slice.shape\n",
    "        #print(output_slice.shape)\n",
    "        B = output_slice.unsqueeze(2)\n",
    "        device = output_slice.device\n",
    "\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "\n",
    "        kernel_dx = kernel_dx.repeat(components, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(components, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(components, 1, 1, 1, 1)\n",
    "\n",
    "        dB_dx = F.conv3d(B, kernel_dx, padding=(0, 0, 1), groups=components)\n",
    "        dB_dy = F.conv3d(B, kernel_dy, padding=(0, 1, 0), groups=components)\n",
    "        dB_dz = F.conv3d(B, kernel_dz, padding=(1, 0, 0), groups=components)\n",
    "\n",
    "        dB_x_dx = dB_dx[:, 0, :, :]\n",
    "        dB_y_dy = dB_dy[:, 1, :, :]\n",
    "        dB_z_dz = dB_dz[:, 2, :, :]\n",
    "\n",
    "        divergence = dB_x_dx + dB_y_dy + dB_z_dz\n",
    "        divergence_loss = torch.mean(divergence ** 2, dim=(1, 2, 3))\n",
    "\n",
    "        dB_x_dy = dB_dy[:, 0, :, :]\n",
    "        dB_x_dz = dB_dz[:, 0, :, :]\n",
    "\n",
    "        dB_y_dx = dB_dx[:, 1, :, :]\n",
    "        dB_y_dz = dB_dz[:, 1, :, :]\n",
    "\n",
    "        dB_z_dx = dB_dx[:, 2, :, :]\n",
    "        dB_z_dy = dB_dy[:, 2, :, :]\n",
    "\n",
    "        rot_x = dB_z_dy - dB_y_dz\n",
    "        rot_y = dB_x_dz - dB_z_dx\n",
    "        rot_z = dB_y_dx - dB_x_dy\n",
    "\n",
    "        j = torch.stack([rot_x, rot_y, rot_z], dim=1)  # [batch_size, 3, height, width]\n",
    "\n",
    "        jxb = torch.cross(j, B, dim=1)  # [batch_size, 3, height, width]\n",
    "        B_magnitude_squared = torch.sum(B ** 2, dim=1, keepdim=True) + 1e-7\n",
    "        force_free_loss = torch.mean(torch.sum(jxb ** 2, dim=1) / B_magnitude_squared.squeeze(1), dim=(1, 2, 3))\n",
    "\n",
    "        physics_loss = divergence_loss\n",
    "\n",
    "        return physics_loss\n",
    "\n",
    "class singlePhysicsInformedForce_Free_Loss(nn.Module):\n",
    "    def __init__(self, weight=1.0, alpha=1.0, beta=1.0, gamma=1.0):\n",
    "        super(singlePhysicsInformedForce_Free_Loss, self).__init__()\n",
    "        self.weight = weight\n",
    "        self.alpha = alpha  \n",
    "        self.beta = beta    \n",
    "        self.gamma = gamma  \n",
    "\n",
    "    def forward(self, output, target): \n",
    "        loss = self.compute_single_slice_physics_loss(output)\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def compute_single_slice_physics_loss(self, output_slice):\n",
    "\n",
    "        batch_size, components, height, width = output_slice.shape\n",
    "        #print(output_slice.shape)\n",
    "        B = output_slice.unsqueeze(2)\n",
    "        device = output_slice.device\n",
    "\n",
    "        kernel_dx = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 1, 3)\n",
    "        kernel_dy = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 1, 3, 1)\n",
    "        kernel_dz = torch.tensor([-0.5, 0, 0.5], device=device).reshape(1, 1, 3, 1, 1)\n",
    "\n",
    "        kernel_dx = kernel_dx.repeat(components, 1, 1, 1, 1)\n",
    "        kernel_dy = kernel_dy.repeat(components, 1, 1, 1, 1)\n",
    "        kernel_dz = kernel_dz.repeat(components, 1, 1, 1, 1)\n",
    "\n",
    "        dB_dx = F.conv3d(B, kernel_dx, padding=(0, 0, 1), groups=components)\n",
    "        dB_dy = F.conv3d(B, kernel_dy, padding=(0, 1, 0), groups=components)\n",
    "        dB_dz = F.conv3d(B, kernel_dz, padding=(1, 0, 0), groups=components)\n",
    "\n",
    "        dB_x_dx = dB_dx[:, 0, :, :]\n",
    "\n",
    "        dB_y_dy = dB_dy[:, 1, :, :]\n",
    "\n",
    "        dB_z_dz = dB_dz[:, 2, :, :]\n",
    "\n",
    "        divergence = dB_x_dx + dB_y_dy + dB_z_dz\n",
    "        divergence_loss = torch.mean(divergence ** 2, dim=(1, 2, 3))\n",
    "\n",
    "        dB_x_dy = dB_dy[:, 0, :, :]\n",
    "        dB_x_dz = dB_dz[:, 0, :, :]\n",
    "\n",
    "        dB_y_dx = dB_dx[:, 1, :, :]\n",
    "        dB_y_dz = dB_dz[:, 1, :, :]\n",
    "\n",
    "        dB_z_dx = dB_dx[:, 2, :, :]\n",
    "        dB_z_dy = dB_dy[:, 2, :, :]\n",
    "\n",
    "        rot_x = dB_z_dy - dB_y_dz\n",
    "        rot_y = dB_x_dz - dB_z_dx\n",
    "        rot_z = dB_y_dx - dB_x_dy\n",
    "\n",
    "        j = torch.stack([rot_x, rot_y, rot_z], dim=1)  # [batch_size, 3, height, width]\n",
    "\n",
    "        jxb = torch.cross(j, B, dim=1)  # [batch_size, 3, height, width]\n",
    "        B_magnitude_squared = torch.sum(B ** 2, dim=1, keepdim=True) + 1e-7\n",
    "        force_free_loss = torch.mean(torch.sum(jxb ** 2, dim=1) / B_magnitude_squared.squeeze(1), dim=(1, 2, 3))\n",
    "\n",
    "        physics_loss = force_free_loss\n",
    "\n",
    "        return physics_loss\n",
    "\n",
    "\n",
    "class ECA3DLayer(nn.Module):\n",
    "    def __init__(self, channel, k_size=3):\n",
    "        super(ECA3DLayer, self).__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool3d(1)\n",
    "        self.conv = nn.Conv1d(1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: [batch_size, channels, seq_len, height, width]\n",
    "        \n",
    "        # Global average pooling across seq_len, height, width\n",
    "        y = self.avg_pool(x)  # Shape: [batch_size, channels, 1, 1, 1]\n",
    "\n",
    "        # Apply 1D convolution across the channel dimension\n",
    "        y = self.conv(y.squeeze(-1).squeeze(-1).transpose(-1, -2))  # Shape: [batch_size, 1, channels]\n",
    "        y = y.transpose(-1, -2).unsqueeze(-1).unsqueeze(-1)  # Shape: [batch_size, channels, 1, 1, 1]\n",
    "\n",
    "        # Apply attention to input\n",
    "        return x * self.sigmoid(y).expand_as(x)\n",
    "\n",
    "\n",
    "class DilatedConvYWithECA(nn.Module):\n",
    "    def __init__(self, channels, dilation_y=2, k_size=3):\n",
    "        super(DilatedConvYWithECA, self).__init__()\n",
    "        # Dilated convolution in y dimension\n",
    "        self.conv = nn.Conv3d(\n",
    "            in_channels=channels,\n",
    "            out_channels=channels,\n",
    "            kernel_size=(1, 3, 1),  \n",
    "            padding=(0, dilation_y, 0),  \n",
    "            dilation=(1, dilation_y, 1),\n",
    "            bias=False\n",
    "        )\n",
    "        self.activation = nn.ReLU()\n",
    "\n",
    "        # ECA Attention layer\n",
    "        self.eca = ECA3DLayer(channel=channels, k_size=k_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Apply dilated convolution\n",
    "        x = self.conv(x)\n",
    "        x = self.activation(x)\n",
    "\n",
    "        # Apply ECA attention\n",
    "        x = self.eca(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class CustomFNOnew(nn.Module):\n",
    "    def __init__(self, n_modes, hidden_channels, in_channels=3, out_channels=1,\n",
    "                 lifting_channels=256, projection_channels=256, n_layers=4,\n",
    "                 output_scaling_factor=None, max_n_modes=None,\n",
    "                 fno_block_precision=\"full\", use_mlp=False, mlp_dropout=0,\n",
    "                 mlp_expansion=0.5, non_linearity=F.gelu, stabilizer=None,\n",
    "                 norm=None, preactivation=False, fno_skip=\"linear\",\n",
    "                 mlp_skip=\"soft-gating\", separable=False, factorization=None,\n",
    "                 rank=1.0, joint_factorization=False, fixed_rank_modes=False,\n",
    "                 implementation=\"factorized\", decomposition_kwargs=dict(),\n",
    "                 domain_padding=None, domain_padding_mode=\"one-sided\",\n",
    "                 fft_norm=\"forward\", SpectralConv=SpectralConv,\n",
    "                 **kwargs):\n",
    "        \n",
    "        super().__init__()\n",
    "        self.n_dim = len(n_modes)\n",
    "        self.n_layers = n_layers\n",
    "\n",
    "        # Define the ECA-Net block for lengths_lifted\n",
    "        self.DilatedConvYWithECA = DilatedConvYWithECA(hidden_channels, dilation_y=2).to(device0)\n",
    "\n",
    "        # Define the lifting layers for two inputs\n",
    "        self.lifting1 = MLP(\n",
    "            in_channels=3,\n",
    "            out_channels=hidden_channels,\n",
    "            hidden_channels=lifting_channels,\n",
    "            n_layers=1,\n",
    "            n_dim=self.n_dim,\n",
    "        ).to(device0)\n",
    "        \n",
    "        self.lifting_y = MLP(\n",
    "            in_channels=3,  \n",
    "            out_channels=hidden_channels,\n",
    "            hidden_channels=lifting_channels,\n",
    "            n_layers=2,\n",
    "            n_dim=1,\n",
    "        ).to(device0)\n",
    "        \n",
    "    \n",
    "        # Define the FNO blocks\n",
    "        self.fno_blocks = FNOBlocks(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=hidden_channels,\n",
    "            n_modes=n_modes,\n",
    "            output_scaling_factor=output_scaling_factor,\n",
    "            use_mlp=use_mlp,\n",
    "            mlp_dropout=mlp_dropout,\n",
    "            mlp_expansion=mlp_expansion,\n",
    "            non_linearity=non_linearity,\n",
    "            stabilizer=stabilizer,\n",
    "            norm=norm,\n",
    "            preactivation=preactivation,\n",
    "            fno_skip=fno_skip,\n",
    "            mlp_skip=mlp_skip,\n",
    "            max_n_modes=max_n_modes,\n",
    "            fno_block_precision=fno_block_precision,\n",
    "            rank=rank,\n",
    "            fft_norm=fft_norm,\n",
    "            fixed_rank_modes=fixed_rank_modes,\n",
    "            implementation=implementation,\n",
    "            separable=separable,\n",
    "            factorization=factorization,\n",
    "            decomposition_kwargs=decomposition_kwargs,\n",
    "            joint_factorization=joint_factorization,\n",
    "            SpectralConv=SpectralConv,\n",
    "            n_layers=n_layers,\n",
    "            **kwargs\n",
    "        ).to(device0)\n",
    "\n",
    "        self.projection = MLP(\n",
    "            in_channels=hidden_channels,\n",
    "            out_channels=out_channels,\n",
    "            hidden_channels=projection_channels,\n",
    "            n_layers=2,\n",
    "            n_dim=self.n_dim,\n",
    "            non_linearity=non_linearity,\n",
    "        ).to(device0)\n",
    "\n",
    "    \n",
    "    def forward(self, x, lengths):\n",
    "\n",
    "        x_orig = x.clone()\n",
    "        \n",
    "        lengths = lengths.view(-1, 3, 1)  \n",
    "\n",
    "        lengths_lifted = self.lifting_y(lengths)  \n",
    "\n",
    "        lengths_lifted = lengths_lifted.unsqueeze(-1).unsqueeze(-1)\n",
    "\n",
    "        lengths_lifted = self.DilatedConvYWithECA(lengths_lifted)\n",
    "        \n",
    "        x = x + lengths_lifted\n",
    "\n",
    "        for layer_idx in range(self.n_layers):\n",
    "            x = self.fno_blocks(x, layer_idx)\n",
    "\n",
    "        x = self.projection(x)\n",
    "\n",
    "        x[:, 0, :, :, :] = x_orig[:, 0, :, :, :]\n",
    "\n",
    "        return x\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "59d3c1de-9bc4-4a56-a56f-c4354a3c1f14",
   "metadata": {},
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "\n",
    "newmodel = CustomFNOnew(n_modes = (32, 32, 32), in_channels=1, out_channels=25, n_layers = 6,\n",
    "               hidden_channels=25, use_mlp=True, factorization='tucker', rank=0.2)\n",
    "\n",
    "newmodel = newmodel.to(device0)\n",
    "\n",
    "n_params = count_model_params(newmodel)\n",
    "print(f'\\nYour model has {n_params} parameters.')\n",
    "\n",
    "optimizer = torch.optim.Adam(newmodel.parameters(), lr=1e-3, weight_decay=1e-4) \n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.8, patience=1, verbose=True)\n",
    "\n",
    "h1loss = H1Loss(d=2)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d4683b82-4531-443f-b006-71921902ec32",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from skimage.metrics import peak_signal_noise_ratio as psnr, structural_similarity as ssim\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_epochs = 150\n",
    "print_frequency = 40\n",
    "save_checkpoint_start_epoch = 20\n",
    "save_checkpoint_interval = 10\n",
    "checkpoint_dir = \"result/NLFFF_Cube2Step/step2\"\n",
    "results_file = os.path.join(checkpoint_dir, \"result.csv\")\n",
    "\n",
    "physics_loss_fn = PhysicsInformedLoss(weight=0.35, alpha=1, beta=1, gamma=1, delta = 0)\n",
    "single_physics_loss_DIV_fn = singlePhysicsInformedDivergence_Loss(weight=1, alpha=1.0, beta=1, gamma=1)\n",
    "single_physics_loss_FF_fn = singlePhysicsInformedForce_Free_Loss(weight=1, alpha=1.0, beta=1, gamma=1)\n",
    "\n",
    "with open(results_file, mode='w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['epoch', 'comp', 'r2', 'relative_error', 'mse', 'mae', 'psnr', 'ssim'])\n",
    "\n",
    "train_losses_Bx = []\n",
    "train_losses_By = []\n",
    "train_losses_Bz = []\n",
    "test_losses_Bx = []\n",
    "test_losses_By = []\n",
    "test_losses_Bz = []\n",
    "physics_losses_epoch = []\n",
    "epoch_durations = []\n",
    "\n",
    "#z_df = pd.read_csv(z_csv_path)\n",
    "#z_values = z_df['z'].values\n",
    "#assert len(z_values) == 25\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start_time = time.time()\n",
    "\n",
    "    model.train()\n",
    "    epoch_loss_Bx = 0.0\n",
    "    epoch_loss_By = 0.0\n",
    "    epoch_loss_Bz = 0.0\n",
    "    epoch_physics_loss = 0.0\n",
    "    \n",
    "    \n",
    "    time_step_DIV_losses_accum = None\n",
    "    time_step_FF_losses_accum = None\n",
    "\n",
    "    train_loader_tqdm = tqdm(enumerate(train_loader), total=len(train_loader), desc=f'Train Epoch {epoch+1}/{num_epochs}')\n",
    "    for batch_idx, (batch_i, sample) in enumerate(train_loader_tqdm):\n",
    "        optimizer.zero_grad()\n",
    "        data, target = sample['input'].to(device0), sample['target'].to(device0)\n",
    "        lengths = sample['lengths'].to(device0)  \n",
    "\n",
    "        output = newmodel(data, lengths)\n",
    "\n",
    "        #print(output.shape)\n",
    "\n",
    "        loss_Bx = h1loss(output[:, :, 0, :, :], target[:, :, 0, :, :]).mean()\n",
    "        loss_By = h1loss(output[:, :, 1, :, :], target[:, :, 1, :, :]).mean()\n",
    "        loss_Bz = h1loss(output[:, :, 2, :, :], target[:, :, 2, :, :]).mean()\n",
    "\n",
    "        physics_loss = physics_loss_fn(output, target)\n",
    "\n",
    "        num_time_steps = output.size(1)\n",
    "\n",
    "        if time_step_DIV_losses_accum is None:\n",
    "            time_step_DIV_losses_accum = np.zeros(num_time_steps, dtype=np.float32)\n",
    "\n",
    "        if time_step_FF_losses_accum is None:\n",
    "            time_step_FF_losses_accum = np.zeros(num_time_steps, dtype=np.float32)\n",
    "\n",
    "        for i in range(num_time_steps):\n",
    "            DIV_losses_step = single_physics_loss_DIV_fn(output[:, i, :, :, :], target[:, i, :, :, :])\n",
    "            DIV_losses_step_scalar = DIV_losses_step.mean().item()\n",
    "\n",
    "            time_step_DIV_losses_accum[i] += DIV_losses_step_scalar\n",
    "\n",
    "        for i in range(num_time_steps):\n",
    "            FF_losses_step = single_physics_loss_FF_fn(output[:, i, :, :, :], target[:, i, :, :, :])\n",
    "            FF_losses_step_scalar = FF_losses_step.mean().item()\n",
    "\n",
    "            time_step_FF_losses_accum[i] += FF_losses_step_scalar        \n",
    "\n",
    "        total_loss = loss_Bx + loss_By + loss_Bz + physics_loss\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss_Bx += loss_Bx.item()\n",
    "        epoch_loss_By += loss_By.item()\n",
    "        epoch_loss_Bz += loss_Bz.item()\n",
    "        epoch_physics_loss += physics_loss.item()\n",
    "\n",
    "        if batch_idx % print_frequency == 0:\n",
    "            train_loader_tqdm.set_postfix(\n",
    "                loss_Bx=loss_Bx.item(),\n",
    "                loss_By=loss_By.item(),\n",
    "                loss_Bz=loss_Bz.item(),\n",
    "                physics_loss=physics_loss.item()\n",
    "            )\n",
    "\n",
    "    avg_loss_Bx = epoch_loss_Bx / len(train_loader)\n",
    "    avg_loss_By = epoch_loss_By / len(train_loader)\n",
    "    avg_loss_Bz = epoch_loss_Bz / len(train_loader)\n",
    "    avg_physics_loss = epoch_physics_loss / len(train_loader)\n",
    "\n",
    "    train_losses_Bx.append(avg_loss_Bx)\n",
    "    train_losses_By.append(avg_loss_By)\n",
    "    train_losses_Bz.append(avg_loss_Bz)\n",
    "    physics_losses_epoch.append(avg_physics_loss)\n",
    "\n",
    "    all_E_pred = []\n",
    "    all_E_true = []\n",
    "\n",
    "    model.eval()\n",
    "    epoch_r2_Bx = []\n",
    "    epoch_r2_By = []\n",
    "    epoch_r2_Bz = []\n",
    "    test_loader_tqdm = tqdm(test_loader, total=len(test_loader), desc=f'Test Epoch {epoch+1}/{num_epochs}')\n",
    "    with torch.no_grad():\n",
    "        for sample in test_loader_tqdm:\n",
    "            x = sample['input'].to(device0)\n",
    "            lengths = sample['lengths'].to(device0)  \n",
    "            target = sample['target'].cpu().numpy()\n",
    "            output = newmodel(x, lengths).cpu().numpy()\n",
    "\n",
    "            for true_sample, pred_sample in zip(target, output):\n",
    "                r2_Bx = r2_score(true_sample[:, 0].flatten(), pred_sample[:, 0].flatten())\n",
    "                r2_By = r2_score(true_sample[:, 1].flatten(), pred_sample[:, 1].flatten())\n",
    "                r2_Bz = r2_score(true_sample[:, 2].flatten(), pred_sample[:, 2].flatten())\n",
    "\n",
    "                epoch_r2_Bx.append(r2_Bx)\n",
    "                epoch_r2_By.append(r2_By)\n",
    "                epoch_r2_Bz.append(r2_Bz)\n",
    "\n",
    "\n",
    "    avg_r2_Bx = np.mean(epoch_r2_Bx)\n",
    "    avg_r2_By = np.mean(epoch_r2_By)\n",
    "    avg_r2_Bz = np.mean(epoch_r2_Bz)\n",
    "\n",
    "    test_losses_Bx.append(avg_r2_Bx)\n",
    "    test_losses_By.append(avg_r2_By)\n",
    "    test_losses_Bz.append(avg_r2_Bz)\n",
    "\n",
    "    end_time = time.time()\n",
    "    epoch_duration = end_time - start_time\n",
    "    epoch_durations.append(epoch_duration)\n",
    "\n",
    "    avg_train_loss_combined = (avg_loss_Bx + avg_loss_By + avg_loss_Bz + avg_physics_loss) / 3\n",
    "    scheduler.step(avg_train_loss_combined)\n",
    "\n",
    "    avg_epoch_duration = np.mean(epoch_durations)\n",
    "    remaining_epochs = num_epochs - (epoch + 1)\n",
    "    remaining_time = remaining_epochs * avg_epoch_duration\n",
    "    hours, rem = divmod(remaining_time, 3600)\n",
    "    minutes, seconds = divmod(rem, 60)\n",
    "\n",
    "    print(f'Epoch: {epoch+1}/{num_epochs}, Duration: {epoch_duration:.2f}s, '\n",
    "          f'Train Loss - Bx: {avg_loss_Bx:.4f}, By: {avg_loss_By:.4f}, Bz: {avg_loss_Bz:.4f}, Physics Loss: {avg_physics_loss:.4f}, '\n",
    "          f'Test R2 - Bx: {avg_r2_Bx:.4f}, By: {avg_r2_By:.4f}, Bz: {avg_r2_Bz:.4f}')\n",
    "\n",
    "    print(f'Estimated Remaining Time: {int(hours)}h {int(minutes)}m {int(seconds)}s')\n",
    "\n",
    "    if (epoch + 1) >= save_checkpoint_start_epoch and (epoch + 1) % save_checkpoint_interval == 0:\n",
    "        checkpoint_path = os.path.join(checkpoint_dir, f\"checkpoint_epoch_{epoch+1}.pt\")\n",
    "        torch.save(newmodel.state_dict(), checkpoint_path)\n",
    "        print(f\"Checkpoint saved at epoch {epoch+1}: {checkpoint_path}\")\n",
    "\n",
    "        min_val = float('inf')\n",
    "        max_val = float('-inf')\n",
    "\n",
    "        for sample in test_loader:\n",
    "            y_true_batch = sample['target'].numpy()\n",
    "            batch_min = y_true_batch.min()\n",
    "            batch_max = y_true_batch.max()\n",
    "            min_val = min(min_val, batch_min)\n",
    "            max_val = max(max_val, batch_max)\n",
    "\n",
    "        data_range = max_val - min_val\n",
    "\n",
    "        sample_r2_scores = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_relative_errors = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_mses = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_maes = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_psnr_values = {'bx': [], 'by': [], 'bz': []}\n",
    "        sample_ssim_values = {'bx': [], 'by': [], 'bz': []}\n",
    "        mean_std = {comp: {'mean': None, 'std': None} for comp in ['bx', 'by', 'bz']}\n",
    "        true_values_by_component = {comp: [] for comp in ['bx', 'by', 'bz']}\n",
    "\n",
    "        for sample in train_loader: \n",
    "            y_true_batch = sample['target'].cpu().numpy()\n",
    "            for true_sample in y_true_batch:\n",
    "                for i, comp in enumerate(['bx', 'by', 'bz']):\n",
    "                    true_sample_component = true_sample[:, i]\n",
    "                    true_sample_flat = true_sample_component.flatten()\n",
    "                    true_values_by_component[comp].extend(true_sample_flat)\n",
    "\n",
    "        for comp in ['bx', 'by', 'bz']:\n",
    "            true_values = np.array(true_values_by_component[comp])\n",
    "            mean_std[comp]['mean'] = np.mean(true_values)\n",
    "            mean_std[comp]['std'] = np.std(true_values)\n",
    "\n",
    "        for comp in mean_std:\n",
    "            print(f\"{comp} - Mean: {mean_std[comp]['mean']}, Std: {mean_std[comp]['std']}\")\n",
    "\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for sample in test_loader:\n",
    "                x = sample['input'].to(device0)\n",
    "                lengths = sample['lengths'].to(device0)  \n",
    "                y_true_batch = sample['target'].cpu().numpy()\n",
    "                y_pred_batch = newmodel(x, lengths).cpu().numpy()\n",
    "\n",
    "                for true_sample, pred_sample in zip(y_true_batch, y_pred_batch):\n",
    "                    for i, comp in enumerate(['bx', 'by', 'bz']):\n",
    "                        true_sample_component = true_sample[:, i]\n",
    "                        pred_sample_component = pred_sample[:, i]\n",
    "\n",
    "                        true_sample_flat = true_sample_component.flatten()\n",
    "                        pred_sample_flat = pred_sample_component.flatten()\n",
    "\n",
    "                        r2 = r2_score(true_sample_flat, pred_sample_flat)\n",
    "                        sample_r2_scores[comp].append(r2)\n",
    "\n",
    "                        mean = mean_std[comp]['mean']\n",
    "                        std = mean_std[comp]['std']\n",
    "                        true_sample_original = true_sample_flat * std + mean\n",
    "                        pred_sample_original = pred_sample_flat * std + mean\n",
    "\n",
    "                        absolute_error = np.linalg.norm(true_sample_original - pred_sample_original, 1)\n",
    "\n",
    "                        relative_error = absolute_error / np.linalg.norm(true_sample_original, 1)\n",
    "                        sample_relative_errors[comp].append(relative_error)\n",
    "\n",
    "                        mse = mean_squared_error(true_sample_flat, pred_sample_flat)\n",
    "                        sample_mses[comp].append(mse)\n",
    "\n",
    "                        mae = mean_absolute_error(true_sample_flat, pred_sample_flat)\n",
    "                        sample_maes[comp].append(mae)\n",
    "\n",
    "                        psnr_value = psnr(true_sample_component, pred_sample_component, data_range=data_range)\n",
    "                        sample_psnr_values[comp].append(psnr_value)\n",
    "\n",
    "                        ssim_value = ssim(true_sample_component, pred_sample_component, data_range=data_range)\n",
    "                        sample_ssim_values[comp].append(ssim_value)\n",
    "\n",
    "        with open(results_file, mode='a', newline='') as file:\n",
    "            writer = csv.writer(file)\n",
    "            for comp in ['bx', 'by', 'bz']:\n",
    "                writer.writerow([epoch+1, comp,\n",
    "                                 np.mean(sample_r2_scores[comp]),\n",
    "                                 np.mean(sample_relative_errors[comp]),\n",
    "                                 np.mean(sample_mses[comp]),\n",
    "                                 np.mean(sample_maes[comp]),\n",
    "                                 np.mean(sample_psnr_values[comp]),\n",
    "                                 np.mean(sample_ssim_values[comp])])\n",
    "\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses_Bx.npy'), np.array(train_losses_Bx))\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses_By.npy'), np.array(train_losses_By))\n",
    "np.save(os.path.join(checkpoint_dir, 'train_losses_Bz.npy'), np.array(train_losses_Bz))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses_Bx.npy'), np.array(test_losses_Bx))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses_By.npy'), np.array(test_losses_By))\n",
    "np.save(os.path.join(checkpoint_dir, 'test_losses_Bz.npy'), np.array(test_losses_Bz))\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train_losses_Bx, label='Training Loss Bx', color='red')\n",
    "plt.plot(train_losses_By, label='Training Loss By', color='green')\n",
    "plt.plot(train_losses_Bz, label='Training Loss Bz', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Losses for Bx, By, Bz')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(test_losses_Bx, label='Testing R2 Bx', color='red')\n",
    "plt.plot(test_losses_By, label='Testing R2 By', color='green')\n",
    "plt.plot(test_losses_Bz, label='Testing R2 Bz', color='blue')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.title('Testing R2 Scores for Bx, By, Bz')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "dbf689ce-8f08-41c8-9f0d-200caa033083",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "newmodel.load_state_dict(torch.load(\"result/NLFFF_Cube2Step/step2/checkpoint_epoch_140.pt\"))\n",
    "newmodel.eval() "
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f0b44dd9-0c60-4817-b81f-28fef4d0ce41",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "def fig_to_rgb_array(fig):\n",
    "    fig.canvas.draw()                               # 必须先绘制\n",
    "    w, h = fig.canvas.get_width_height()\n",
    "    buf = np.frombuffer(fig.canvas.buffer_rgba(), dtype=np.uint8)\n",
    "    img = buf.reshape(h, w, 4)[..., :3]             # 去掉 Alpha 通道\n",
    "    return img\n",
    "\n",
    "output_dir = \"result/NLFFF_Cube2Step/step2Test/visualizations\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "fps         = 3\n",
    "frame_size  = (1024, 512)                           # (W, H) for VideoWriter\n",
    "channel_ids = [\"Bx\", \"By\", \"Bz\"]\n",
    "\n",
    "device0 = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "for sample_idx, sample in enumerate(test_dataset):\n",
    "\n",
    "    input_data = sample[\"input\"]                    # (T, 3, H, W)\n",
    "    true_data  = sample[\"target\"]                   # (T, 3, H, W)\n",
    "    lengths    = sample[\"lengths\"]\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_batch = newmodel(\n",
    "            input_data.unsqueeze(0).to(device0),    # (1, T, 3, H, W)\n",
    "            lengths.to(device0)\n",
    "        )\n",
    "    pred_data = pred_batch.cpu().numpy()[0]         # (T, 3, H, W)\n",
    "\n",
    "    time_length = pred_data.shape[0]\n",
    "\n",
    "    for ch_idx, ch_name in enumerate(channel_ids):\n",
    "\n",
    "        gt_path   = os.path.join(output_dir, f\"gt_{ch_name}_sample_{sample_idx}.mp4\")\n",
    "        pred_path = os.path.join(output_dir, f\"pred_{ch_name}_sample_{sample_idx}.mp4\")\n",
    "\n",
    "        gt_writer   = cv2.VideoWriter(gt_path,   cv2.VideoWriter_fourcc(*\"mp4v\"), fps, frame_size)\n",
    "        pred_writer = cv2.VideoWriter(pred_path, cv2.VideoWriter_fourcc(*\"mp4v\"), fps, frame_size)\n",
    "\n",
    "        for t in range(time_length):\n",
    "\n",
    "            true_frame = true_data[t, ch_idx]       # (H, W)\n",
    "            pred_frame = pred_data[t, ch_idx]       # (H, W)\n",
    "\n",
    "            vmin, vmax = true_frame.min(), true_frame.max()\n",
    "            vmin = min(vmin, pred_frame.min())\n",
    "            vmax = max(vmax, pred_frame.max())\n",
    "\n",
    "            # ===== Ground Truth =====\n",
    "            fig_gt, ax_gt = plt.subplots(figsize=(14, 7))\n",
    "            plt.subplots_adjust(top=0.95, bottom=0.05, left=0.05, right=0.95)\n",
    "            ax_gt.imshow(true_frame, cmap=\"RdBu\", origin=\"lower\", vmin=vmin, vmax=vmax)\n",
    "            ax_gt.axis(\"off\")\n",
    "\n",
    "            gt_img = fig_to_rgb_array(fig_gt)\n",
    "            gt_img = cv2.resize(gt_img, frame_size)\n",
    "            gt_writer.write(cv2.cvtColor(gt_img, cv2.COLOR_RGB2BGR))\n",
    "            plt.close(fig_gt)\n",
    "\n",
    "            fig_pred, ax_pred = plt.subplots(figsize=(14, 7))\n",
    "            plt.subplots_adjust(top=0.95, bottom=0.05, left=0.05, right=0.95)\n",
    "            ax_pred.imshow(pred_frame, cmap=\"RdBu\", origin=\"lower\", vmin=vmin, vmax=vmax)\n",
    "            ax_pred.axis(\"off\")\n",
    "\n",
    "            pred_img = fig_to_rgb_array(fig_pred)\n",
    "            pred_img = cv2.resize(pred_img, frame_size)\n",
    "            pred_writer.write(cv2.cvtColor(pred_img, cv2.COLOR_RGB2BGR))\n",
    "            plt.close(fig_pred)\n",
    "\n",
    "        gt_writer.release()\n",
    "        pred_writer.release()\n",
    "        print(f\"[✓] sample {sample_idx} | {ch_name}: GT & Pred videos saved.\")\n",
    "\n",
    "print(\"✅ All videos have been generated.\")\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "11c9c9b8-ac38-4357-a929-28a0c1e90997",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "output_dir = \"result/NLFFF_Cube2Step/step2Test/cube\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "npy_dir = os.path.join(output_dir, \"npy_data\")\n",
    "os.makedirs(npy_dir, exist_ok=True)\n",
    "\n",
    "csv_path = os.path.join(output_dir, \"cube_metrics.csv\")\n",
    "\n",
    "def mean_relative_error(y_true, y_pred, zeroarr):\n",
    "\n",
    "    return mean_absolute_error(y_true, y_pred) / mean_absolute_error(y_true,zeroarr)\n",
    "\n",
    "def compute_psnr(y_true, y_pred):\n",
    "    mse = np.mean((y_true - y_pred) ** 2)\n",
    "    if mse == 0:\n",
    "        return float(\"inf\")\n",
    "    data_range = np.max(y_true) - np.min(y_true)\n",
    "    data_range = data_range if data_range > 0 else 1.0\n",
    "    return 20 * np.log10(data_range / np.sqrt(mse))\n",
    "\n",
    "def compute_ssim_cube(true_cube, pred_cube):\n",
    "    ssim_vals = []\n",
    "    for i in range(true_cube.shape[0]):\n",
    "        data_range = true_cube[i].max() - true_cube[i].min()\n",
    "        data_range = data_range if data_range > 0 else 1.0\n",
    "        ssim_vals.append(\n",
    "            ssim(true_cube[i], pred_cube[i], data_range=data_range)\n",
    "        )\n",
    "    return float(np.mean(ssim_vals))\n",
    "\n",
    "rows = []\n",
    "\n",
    "for sample_idx, sample in enumerate(test_dataset):\n",
    "\n",
    "    input_data = sample[\"input\"]          # (T, 3, H, W)  torch.Tensor\n",
    "    true_data  = sample[\"target\"]         # (T, 3, H, W)  torch.Tensor\n",
    "    lengths    = sample[\"lengths\"]        # (1,)          torch.Tensor\n",
    "\n",
    "    print(true_data.shape)\n",
    "\n",
    "    # 2) 推理\n",
    "    with torch.no_grad():\n",
    "        pred_batch = newmodel(\n",
    "            input_data.unsqueeze(0).to(device0),  # (1, T, 3, H, W)\n",
    "            lengths.to(device0)\n",
    "        )\n",
    "    pred_data = pred_batch.cpu().numpy()[0]       # (T, 3, H, W)\n",
    "    true_data_np = true_data.cpu().numpy()        # (T, 3, H, W)\n",
    "\n",
    "    for channel_idx, channel_name in enumerate([\"Bx\", \"By\", \"Bz\"]):\n",
    "        pred_cube  = pred_data[:, channel_idx, :, :]    # (T, H, W)\n",
    "        true_cube  = true_data_np[:, channel_idx, :, :]\n",
    "\n",
    "        np.save(\n",
    "            os.path.join(npy_dir, f\"sample_{sample_idx}_{channel_name}_pred.npy\"),\n",
    "            pred_cube\n",
    "        )\n",
    "\n",
    "        y_true = true_cube.flatten()\n",
    "        y_pred = pred_cube.flatten()\n",
    "        \n",
    "\n",
    "        r2_val   = r2_score(y_true, y_pred)\n",
    "        mse_val  = mean_squared_error(y_true, y_pred)\n",
    "        mae_val  = mean_absolute_error(y_true, y_pred)\n",
    "        zeroarr = np.zeros(y_true.shape)\n",
    "        re_val   = mean_relative_error(y_true, y_pred, zeroarr)\n",
    "        psnr_val = compute_psnr(true_cube, pred_cube)\n",
    "        ssim_val = compute_ssim_cube(true_cube, pred_cube)\n",
    "\n",
    "        rows.append({\n",
    "            \"sample\":  sample_idx,\n",
    "            \"channel\": channel_name,\n",
    "            \"R2\":      r2_val,\n",
    "            \"MSE\":     mse_val,\n",
    "            \"MAE\":     mae_val,\n",
    "            \"RE\":      re_val,\n",
    "            \"PSNR\":    psnr_val,\n",
    "            \"SSIM\":    ssim_val\n",
    "        })\n",
    "\n",
    "        print(f\"[Sample {sample_idx} - {channel_name}] \"\n",
    "              f\"R2={r2_val:.4f}, MSE={mse_val:.3e}, MAE={mae_val:.3e}, \"\n",
    "              f\"RE={re_val:.4f}, PSNR={psnr_val:.2f}, SSIM={ssim_val:.4f}\")\n",
    "\n",
    "# 4) 保存 CSV\n",
    "metrics_df = pd.DataFrame(rows)\n",
    "metrics_df.to_csv(csv_path, index=False)\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "673539a6-8cbb-4fe7-a0c6-c64bbd90d9ac",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
